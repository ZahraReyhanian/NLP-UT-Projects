{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awIA4F1gp6s-"
      },
      "source": [
        "# Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7sWpwLNdOvO",
        "outputId": "0660135e-9340-4082-9a8c-facea64e3c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/975.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/975.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain\\\n",
        "    langchain-community\\\n",
        "    langchain-together\\\n",
        "    langchain-core\\\n",
        "    tavily-python\\\n",
        "    faiss-cpu\\\n",
        "    faiss-gpu\\\n",
        "    langgraph\\\n",
        "    sentence-transformers\\\n",
        "    gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu1CcmY6qutg",
        "outputId": "26c80f68-9583-4ed1-e745-fd5ebcb88707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet  rank_bm25 > /dev/null\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ve4CryIGdT5K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_core.documents.base import Document\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.cache import InMemoryCache\n",
        "from langchain_together import ChatTogether\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from typing import List\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from typing import Literal\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from IPython.core.display import Markdown\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C0V2IQs7stcr"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"YOUR_TAVILY_API_KEY\"\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"YOUR_TOGETHER_API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrVTf4Rn5no"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZhmcrRDedUGJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# send a GET request to the website\n",
        "url = 'https://stanford.edu/~jurafsky/slp3/'\n",
        "response = requests.get(url)\n",
        "\n",
        "# parse the HTML content of the page with BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# find all links on the page\n",
        "links = soup.find_all('a')\n",
        "\n",
        "pdflinks = []\n",
        "\n",
        "# print the href attribute of each link\n",
        "for link in links:\n",
        "    ref = link.get('href')\n",
        "    if ref.endswith('.pdf'):\n",
        "      pdflinks.append(url+ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo0Yxx1K24N7",
        "outputId": "ca267fe6-5292-4110-ecc7-192be5a27800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['https://stanford.edu/~jurafsky/slp3/2.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/2_TextProc_2023.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/3.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/4.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/4_NB_2024.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/5.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/5_LR_Apr_7_2021.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/6.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/vectorsemantics2024.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/7.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/7_NN_Apr_28_2021.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/8.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/8_POSNER_intro_May_6_2021.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/9.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/10.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/11.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/13.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/14.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/15.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/slides/24_Dialogue_May_6_2021.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/16.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/17.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/18.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/19.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/20.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/21.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/22.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/23.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/A.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/B.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/C.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/D.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/E.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/F.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/G.pdf',\n",
              " 'https://stanford.edu/~jurafsky/slp3/H.pdf']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdflinks.pop(0)\n",
        "pdflinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpq-8PWwY1GW",
        "outputId": "f27f43ea-deb8-4b0d-86df-6d8cf71597fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 100 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 102 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 121 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 123 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 125 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 149 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 164 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 174 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 187 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 200 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 202 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 204 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 210 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 212 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 228 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 240 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 270 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 272 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 274 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 276 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 278 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 280 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 294 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 296 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 298 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 344 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 361 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 363 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 425 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 431 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 450 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 452 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 57 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 60 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 67 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 69 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 71 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 77 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 91 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 93 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 95 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 97 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 107 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 113 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 129 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 137 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 139 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 141 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 155 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 160 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 188 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 195 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 217 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 252 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 261 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 263 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 265 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 271 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 273 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 279 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 287 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 289 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 305 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 310 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 312 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 314 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 316 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 326 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 331 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 336 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 346 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 351 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 357 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 363 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 365 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 367 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 369 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 373 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 376 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 380 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 383 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 389 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 391 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 397 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 399 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 419 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 433 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 441 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 445 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 447 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 449 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 462 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 468 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 473 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 482 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 515 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 557 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 559 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 561 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 586 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 604 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 627 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 652 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 655 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 657 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 663 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 666 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 668 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 678 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 681 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 683 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 693 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 696 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 698 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 704 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 707 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 709 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 741 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 743 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 749 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 751 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 50 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 52 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 54 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 77 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 87 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 90 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 92 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 103 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 105 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 107 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 109 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 120 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 144 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 146 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 148 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 150 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 152 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 163 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 170 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 178 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 191 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 193 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 195 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 200 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 207 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 209 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 211 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 216 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 237 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 239 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 241 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 246 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 260 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 262 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 264 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 269 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 276 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 278 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 280 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 285 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 296 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 308 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 311 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 313 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 320 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 323 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 325 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 337 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 340 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 342 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 349 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 352 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 354 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 367 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 369 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 371 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 386 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 388 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 390 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 414 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 442 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 444 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 447 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 454 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 456 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 458 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 482 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 484 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 486 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 499 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 501 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 504 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 519 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 521 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 523 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 531 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 553 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 555 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 562 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 564 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 566 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 579 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 581 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 583 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 585 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 591 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 595 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 597 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 608 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 612 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 614 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 616 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 618 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 629 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 633 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 635 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 641 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 645 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 647 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 654 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 656 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 668 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 670 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 673 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 685 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 687 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 690 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 718 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 720 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 723 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 733 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 757 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 777 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 783 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 785 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 791 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 793 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 811 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 813 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 818 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 821 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 839 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 841 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 846 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 849 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 855 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 857 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 862 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 865 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 876 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 880 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 882 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 887 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 890 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 894 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 896 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 901 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 904 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 906 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 915 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 917 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 922 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 925 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 932 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 950 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 952 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 954 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 965 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 967 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 972 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 975 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 981 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 984 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 986 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 988 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1023 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1025 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1030 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1033 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1039 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1042 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1044 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1046 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1066 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1106 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1112 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1114 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1117 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1124 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1126 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1132 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1134 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1137 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1143 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1145 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1148 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1159 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1164 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1170 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1172 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1175 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1203 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1205 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1207 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1213 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1216 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1218 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1226 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1229 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1231 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1240 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1242 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1250 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1252 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1254 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1256 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1263 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1265 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1273 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1275 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1285 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1290 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1298 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1302 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1307 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1312 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1317 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 30 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 48 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 58 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 86 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 95 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 103 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 105 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 111 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 114 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 120 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 122 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 128 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 130 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 149 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 167 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 169 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 171 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 177 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 182 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 184 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 191 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 197 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 240 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 242 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 244 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 246 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 248 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 250 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 252 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 254 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 256 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 258 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 260 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 262 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 312 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 314 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 324 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 334 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 356 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 377 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 379 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 385 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 393 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 395 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 404 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 408 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 411 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 413 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 421 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 423 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 429 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 437 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 442 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 448 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 451 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 454 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 460 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 463 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 466 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 479 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 483 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 498 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 504 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 506 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 508 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 516 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 518 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 524 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 526 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 528 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 530 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 537 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 543 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 545 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 552 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 562 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 565 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 571 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 574 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 580 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 591 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 594 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 601 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 603 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 618 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 639 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 641 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 648 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 650 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 656 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 658 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 664 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 675 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 677 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 683 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 685 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 693 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 695 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 697 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 699 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 709 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 711 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 713 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 715 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 729 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 731 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 733 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 735 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 743 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 745 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 747 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 754 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 762 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 779 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 781 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 783 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 801 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 803 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 805 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 811 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 817 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 819 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 826 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 828 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 831 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 838 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 854 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 860 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 862 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 864 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 866 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 872 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 874 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 879 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 881 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 890 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 895 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 897 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 906 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 908 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 911 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 918 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 925 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 927 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 930 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 937 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 945 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 950 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 952 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 986 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1001 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1025 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1027 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1034 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 69 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 71 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 80 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 83 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 97 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 99 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 116 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 118 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 125 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 128 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 130 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 145 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 148 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 156 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 171 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 188 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 191 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 198 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 212 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 215 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 222 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 228 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 231 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 238 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 253 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 256 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 263 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 269 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 272 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 279 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 285 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 288 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 295 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 312 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 315 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 322 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 328 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 331 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 338 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 344 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 347 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 354 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 360 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 363 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 370 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 376 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 379 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 386 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 405 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 411 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 414 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 421 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 429 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 432 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 439 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 477 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 483 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 487 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 502 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 506 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 515 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 519 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 524 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 570 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 572 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 574 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 576 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 578 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 580 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 582 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 584 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 586 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 594 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 601 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 632 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 654 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 659 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 662 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 669 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 671 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 673 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 675 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 682 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 684 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 695 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 698 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 700 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 708 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 711 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 713 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 719 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 724 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 729 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 734 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 742 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 744 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 748 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 771 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 773 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 775 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 777 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 792 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 801 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 813 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 815 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 818 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 825 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 827 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 830 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 837 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 839 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 842 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 849 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 851 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 854 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 856 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 858 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 890 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 892 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 904 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 906 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 908 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 926 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 929 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 940 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 942 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 944 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 946 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 965 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 967 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 999 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1001 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1008 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1010 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1012 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1014 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1025 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1029 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1031 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1037 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1041 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1043 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1050 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1056 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1058 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1064 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1066 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1070 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1072 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1077 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1080 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1091 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1097 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1099 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1103 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1112 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1115 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1140 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1142 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1176 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1178 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1182 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1189 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1191 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1208 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1211 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1225 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1228 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1237 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1240 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1265 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1268 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1282 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1288 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1294 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1296 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1298 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1311 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1317 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1319 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1321 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1335 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1337 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1339 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1346 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 47 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 49 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 53 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 62 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 70 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 81 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 83 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 87 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 89 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 104 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 118 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 131 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 138 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 140 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 142 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 144 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 151 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 153 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 163 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 187 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 238 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 33 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 42 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 61 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 70 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 72 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 74 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 76 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 80 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 82 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 86 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 90 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 92 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 97 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 99 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 103 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 105 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 107 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 109 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 111 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 113 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 115 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 117 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 119 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 121 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 123 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 125 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 127 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 129 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 131 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 133 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 135 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 137 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 139 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 141 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 148 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 150 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 152 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 154 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 174 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 189 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 218 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 227 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 229 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 238 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 240 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 242 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 261 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 268 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 298 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 300 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 322 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 324 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 344 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 362 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 374 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 397 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 399 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 416 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 425 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 443 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 455 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 457 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 466 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 468 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 473 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 484 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 486 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 491 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 500 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 502 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 508 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 521 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 539 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 569 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 581 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 619 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 621 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 623 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 625 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 651 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 718 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 720 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 723 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 724 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 725 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 728 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 729 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 731 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 732 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 734 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 735 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 737 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 738 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 740 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 741 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 775 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 777 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 790 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 792 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 800 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 812 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 814 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 844 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 846 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 872 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 895 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 903 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 941 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 960 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 963 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1039 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1051 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1058 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1071 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1073 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1139 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 1147 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "documents = []\n",
        "for pdf_path in pdflinks:\n",
        "  loader = PyPDFLoader(pdf_path)\n",
        "  documents.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "izD6nrIpdUMG"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "chunked_documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6M9LwUIKe7i",
        "outputId": "9d79c1e7-316e-4c8b-c8e1-098393babe1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3700"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunked_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15lOmo6Hnimt"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "851634318e2b40fe97b8048b0dc7f33a",
            "9f78a5f867fb4176ab1ad032e9847ecc",
            "ec5e6d0d9bc14c569a52d77c0a740981",
            "24065ee058674c20abcc6cc227ed81f9",
            "c195420ccdd047a080a4b52a9d6b561b",
            "08c73c292849407b9f6acbfa9777861b",
            "0e61e360605d4d71a16d4345084fb0f7",
            "104b8f392508442e9e77727c0b08a5c8",
            "1c553eaeb9e945c0b2d42aaea2605b42",
            "f788e9c5a880486999b6cac25e806368",
            "38733e3d653942d1a33ea31f857cbe26",
            "eb3907722d214202b1431a9915b9e605",
            "02a25ea155d7403e825ad8fe32ef8e6c",
            "8525df6a51d54a519dfb036ec749e92a",
            "7cab2faa887849b993b39808c692d3de",
            "a59b09fccbe1414dae82a0a8c70a4687",
            "0129dbd1ea784de5924a656de59ef97c",
            "9595bd8d425d436688bdadbef0e3a43c",
            "5b7d829dfb5b4ad59d7aa82b14e778c5",
            "e21ea899092f48b6bface2e792ff0203",
            "77d148c3e3ff400c8de617a204eda2f1",
            "ba58e04eeff643a18edd6455ce0877df",
            "6b24556b979e4524b845d15d350b1833",
            "f9ccab162d2a4a7d97792783573477b7",
            "518a396de8474278a2a4698e1204c4a1",
            "b67831e0a94b4a7199f5ce6c290a24fc",
            "a684e66440284123ad7c541eed4b7084",
            "a78b077d12684435964111eb1522c16c",
            "7a5ef7f5d0ca4bc098d8752e62307491",
            "ee30b0be9e60401488c92dc7e6bbf2fd",
            "52825300fa5341dda7d85880ffbfef78",
            "4fe75f6547344e64837b381624353db0",
            "27349890c9944d058fe0710e669f85b7",
            "d0a305e230d2435ba892d6669fa32643",
            "0e726d604afd4ab9b0a1e28e2a98d35c",
            "a60ccbafb5944931870f2867fa3dfd34",
            "852e3144391649cb9250d0482366fcda",
            "19c13568506046edb52fbd6742136117",
            "d7398b462d5842edb073934c6bfc1d41",
            "cb3627360b3546d99985e6d53a874d58",
            "6990c9706a5f47d7ba52c721b242fcb7",
            "17bf9943ce6648c0a149abf8d173706e",
            "98b7705e8f0e4711ac5fa4a1a53d1aed",
            "7a85080c8a9f43d59ace78b7635128b4",
            "ffcbfb97f65b4e67a3ae945b53f81113",
            "51feb708e96a45dda62df4a2473cae91",
            "40d55a0a2e1444f0bfb71d7b37becb4e",
            "74e5f6bd496a402c8178a6e61330dcff",
            "530da484cf0d4113b2c6e3808b2027f4",
            "2c66d7e8783c42a4ad753a3e51c4fc2b",
            "6d584a4fbfa94af2b459f3fa322c3e42",
            "dade24dd5863447d90dd767a22e71d19",
            "e6705afabce046a2949afc6c8b10620b",
            "6f0dbeac832f4124993b60284a77feb8",
            "4c37ac881fb94111a73e1a83b865d7e4",
            "bed8af57e8854d45bd5363d95e9d3db2",
            "dff1045e1caa4074a8fb2cedb9797ece",
            "4bfc174294974e13946fd0bf7ad37148",
            "81f19648a5d244e1bef9de0b4284bd87",
            "b820b3e1cc1f4bb08f70671dc1299c5d",
            "b1b4fb0e1c154c5898a2d6657afbd589",
            "9f9318e563fc4ed0ae85dd6c9fdaf962",
            "a92fde3329d24a7288c3875799e4d728",
            "da44553d886340c5aa3a8b6b54c48f5b",
            "5e56866ae9de425a98905d82ac5d50ba",
            "00ed0a7bda27408483d7a9eebce11cdd",
            "78f35f33e4194b5498610cad7a06b0c4",
            "ca62babda4044a1c863ae1e50e0c0be8",
            "5db4de2c293f45b89561355dea8b83e8",
            "f0f4c9980b2844aebd24d28dae6a1a15",
            "29c17a22b9a14109a6fd51c04b368d53",
            "a89a4143d74c4c818df33f6d504fcc57",
            "c3e1411de3d5458d9c909ffcb634eb22",
            "1ff346777276410d84039d61392ce88d",
            "6e3b8d930788430aac46f265eb7080b6",
            "c15c5e8a75cf4293bdde3f3cee314438",
            "a618f7ebd7294d249b6d8bf48f9938ee",
            "df82083fb83048ddad928993e8818f7a",
            "7d5ea9445aca4ad1bd0211e1038295af",
            "58263098621b4c8881c674a329053358",
            "71e5ccac775344a79b6fbe62fae72c9b",
            "ffd7bdb53f554cddb56025fc03aaf1dd",
            "33e88c169a52424fa8b634f9c6550f1b",
            "e98b77435cfb4dec8a1395ffb7743b74",
            "72b604f552d84ae6a93f352e9bbf24ab",
            "2ab819640bf74fc88804dce296572fd9",
            "d74c6f48850c4d57a29faf6d3af4d2e6",
            "0397d64da841404bab534fadffc3088a",
            "f9b52ff44da94f3db5001ca3edcbe2a9",
            "3177df69addf48c2ba2e557155c9fc5d",
            "4e682fc3c07c4888aa29ece3239c06de",
            "7e92b2e9d06343f9a91752ff0fd6c7f1",
            "f2e1368dd95b4b91bcc713275d3e9a21",
            "d0dfba183ffb4c51a258e2d57c42ee89",
            "40fda86974154415a4f7ef49ca386e15",
            "3ac1b055ab444b0cb50981a7f797ed0f",
            "717086b1b611481d895b40357a0d70ca",
            "0da5b2d33a6e4e2bb574586b7762d75a",
            "5af1174ba3ce4af68303278ba75c5ca2",
            "a8ef19d3e1204998b7f53d6775823590",
            "6e5ee3749f104fe0b1b2d4b77ed3ce42",
            "ead9db98e3b746e5b15b31cc56129d2b",
            "35a3ce14b86540a3b22900919ed1ed2b",
            "d6b212747bba4282a47ec5499b0d0b73",
            "8106970a74ae4b2f95fca7cf924fc1a4",
            "f05d0ad468764fb986c23a7c2bd80dda",
            "c9c70bd8a0be4ba2a8a3e1ca66bfa9e1",
            "ac12066e6b184c289b05952410f5a63b",
            "66c85fec891541ddbeb0c4a65e1a2d6b",
            "c1b0718800494b03826868d5e5718197",
            "13536998fd994aac9b6bc5634143a4b5",
            "b0fbf5f7c53641a8b3f905883e7f7c09",
            "838b77df0a7c46c5aa40422b10ede235",
            "02e274609daf463b912f4003c5f72898",
            "1cb582f2f9454ac88f08cc07dd991b3d",
            "501c6b160b2c4c71a4810a1959b8a897",
            "da45197a3da94db0b93fa4105c19374f",
            "4b150223cff84218ba307f36ae722068",
            "ad7e206529894c23884eaf65487233bd",
            "b031cee5af754b919d73e4bf4c71431f",
            "c2831d8eba134bedb6fef1dad0f27ab8"
          ]
        },
        "id": "hPXafUqpNQOW",
        "outputId": "5c285c0b-22f6-4745-c4f6-591028d81104"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "851634318e2b40fe97b8048b0dc7f33a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb3907722d214202b1431a9915b9e605",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b24556b979e4524b845d15d350b1833",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0a305e230d2435ba892d6669fa32643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffcbfb97f65b4e67a3ae945b53f81113",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bed8af57e8854d45bd5363d95e9d3db2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78f35f33e4194b5498610cad7a06b0c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df82083fb83048ddad928993e8818f7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9b52ff44da94f3db5001ca3edcbe2a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8ef19d3e1204998b7f53d6775823590",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13536998fd994aac9b6bc5634143a4b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "store = LocalFileStore(\"./cache/\")\n",
        "embeddings_model = HuggingFaceEmbeddings(show_progress=True, multi_process=True)\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(embeddings_model,\n",
        "                                                  store,\n",
        "                                                  namespace=embeddings_model.model_name)\n",
        "# Create VectorStore\n",
        "vectorstore = FAISS.from_documents(documents=chunked_documents,embedding=embedder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFAixQUZ-t3P",
        "outputId": "0ba830f7-d04f-4924-b9bd-0dac4bf5b11f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['sentence-transformers/all-mpnet-base-v2b43e216c-e1d2-5044-8b8b-1c21041d2e44',\n",
              " 'sentence-transformers/all-mpnet-base-v21273176c-720e-590a-b026-912d8059e292',\n",
              " 'sentence-transformers/all-mpnet-base-v2692cc87a-d00d-5309-9228-57d1c8bd4c15',\n",
              " 'sentence-transformers/all-mpnet-base-v2da33bb4f-f6f6-5f5f-8688-9ee92f3e588b',\n",
              " 'sentence-transformers/all-mpnet-base-v2c166751a-6fca-5e4e-bf5c-e312a58397fb']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(store.yield_keys())[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ul-GpMooopv"
      },
      "source": [
        "# Section 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "31c9n2CJ5Jg-"
      },
      "outputs": [],
      "source": [
        "documents_text = []\n",
        "for doc in documents:\n",
        "  documents_text.append(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x4wSWKUYo7tt"
      },
      "outputs": [],
      "source": [
        "bm25_retriever = BM25Retriever.from_texts(\n",
        "    documents_text, metadatas=[{\"source\": 1}] * len(documents_text)\n",
        ")\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# initialize the ensemble retriever\n",
        "retriever_chain = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3t9AVuc1t2k",
        "outputId": "2c0af6d8-bce6-4e3e-dc2a-91a05a385341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight for FAISS: 0\n",
            "Weight for BM25: 1\n",
            "\n",
            "Testing retriever with a sample query:\n",
            "Retrieved docs: [Document(metadata={'source': 1}, page_content='11.4 • F INE-TUNING LANGUAGE MODELS 13\\nmodels or from autoregressive ones) have the property that the vectors for all words\\nare extremely similar. If we look at the embeddings from the ﬁnal layer of BERT\\nor other models, embeddings for instances of any two randomly chosen words will\\nhave extremely high cosines that can be quite close to 1, meaning all word vectors\\ntend to point in the same direction. The property of vectors in a system all tending\\nto point in the same direction is known as anisotropy . Ethayarajh (2019) deﬁnes\\ntheanisotropy of a model as the expected cosine similarity of any pair of words in anisotropy\\na corpus. The word ‘isotropy’ means uniformity in all directions, so in an isotropic\\nmodel, the collection of vectors should point in all directions and the expected cosine\\nbetween a pair of random embeddings would be zero. Timkey and van Schijndel\\n(2021) show that one cause of anisotropy is that cosine measures are dominated by\\na small number of dimensions of the contextual embedding whose values are very\\ndifferent than the others: these rogue dimensions have very large magnitudes and\\nvery high variance.\\nTimkey and van Schijndel (2021) shows that we can make the embeddings more\\nisotropic by standardizing (z-scoring) the vectors, i.e., subtracting the mean and\\ndividing by the variance. Given a set Cof all the embeddings in some corpus, each\\nwith dimensionality d(i.e., x∈Rd), the mean vector µ∈Rdis:\\nµ=1\\n|C|∑\\nx∈Cx (11.10)\\nThe standard deviation in each dimension σ∈Rdis:\\nσ=√\\n1\\n|C|∑\\nx∈C(x−µ)2(11.11)\\nThen each word vector xis replaced by a standardized version z:\\nz=x−µ\\nσ(11.12)\\nOne problem with cosine that is not solved by standardization is that cosine tends\\nto underestimate human judgments on similarity of word meaning for very frequent\\nwords (Zhou et al., 2022).\\nIn the next section we’ll see the most common use of contextual representations:\\nas representations of words or even entire sentences that can be the inputs to classi-\\nﬁers in the ﬁne-tuning process for downstream NLP applications.\\n11.4 Fine-Tuning Language Models\\nThe power of pretrained language models lies in their ability to extract generaliza-\\ntions from large amounts of text—generalizations that are useful for myriad down-\\nstream applications. There are two ways to make practical use of the generaliza-\\ntions. One way is to use natural language to prompt the model, putting it in a state\\nwhere it contextually generates what we want. We’ll introduce prompting in Chap-\\nter 12. An alternative is to create interfaces from pretrained language models to\\ndownstream applications through a process called ﬁne-tuning . In ﬁne-tuning, we ﬁne-tuning\\ncreate applications on top of pretrained models by adding a small set of application-\\nspeciﬁc parameters. The ﬁne-tuning process consists of using labeled data about'), Document(metadata={'source': 1}, page_content='11.2 • T RAINING BIDIRECTIONAL ENCODERS 7\\nmasked be M, the version of that sentence with some tokens replaced by masks be\\nxmask, and the sequence of output vectors be z. For a given input token xi, such as\\nthe word long in Fig. 11.4, the loss is the probability of the correct word long, given\\nxmask(as summarized in the single output vector zi):\\nLMLM(xi) =−logP(xi|zi)\\nThe gradients that form the basis for the weight updates are based on the average\\nloss over the sampled learning items from a single training sequence (or batch of\\nsequences).\\nLMLM=−1\\n|M|∑\\ni∈MlogP(xi|zi)\\nNote that only the tokens in Mplay a role in learning; the other words play no role\\nin the loss function, so in that sense BERT and its descendents are inefﬁcient; only\\n15% of the input samples in the training data are actually used for training weights.\\n1\\n11.2.2 Next Sentence Prediction\\nThe focus of mask-based learning is on predicting words from surrounding contexts\\nwith the goal of producing effective word-level representations. However, an im-\\nportant class of applications involves determining the relationship between pairs of\\nsentences. These include tasks like paraphrase detection (detecting if two sentences\\nhave similar meanings), entailment (detecting if the meanings of two sentences en-\\ntail or contradict each other) or discourse coherence (deciding if two neighboring\\nsentences form a coherent discourse).\\nTo capture the kind of knowledge required for applications such as these, some\\nmodels in the BERT family include a second learning objective called Next Sen-\\ntence Prediction (NSP). In this task, the model is presented with pairs of sentencesNext Sentence\\nPrediction\\nand is asked to predict whether each pair consists of an actual pair of adjacent sen-\\ntences from the training corpus or a pair of unrelated sentences. In BERT, 50% of\\nthe training pairs consisted of positive pairs, and in the other 50% the second sen-\\ntence of a pair was randomly selected from elsewhere in the corpus. The NSP loss\\nis based on how well the model can distinguish true pairs from random pairs.\\nTo facilitate NSP training, BERT introduces two new tokens to the input repre-\\nsentation (tokens that will prove useful for ﬁne-tuning as well). After tokenizing the\\ninput with the subword model, the token [CLS] is prepended to the input sentence\\npair, and the token [SEP] is placed between the sentences and after the ﬁnal token of\\nthe second sentence. Finally, embeddings representing the ﬁrst and second segments\\nof the input are added to the word and positional embeddings to allow the model to\\nmore easily distinguish the input sentences.\\nDuring training, the output vector from the ﬁnal layer associated with the [CLS]\\ntoken represents the next sentence prediction. As with the MLM objective, a learned\\nset of classiﬁcation weights WNSP∈R2×dhis used to produce a two-class prediction\\nfrom the raw [CLS] vector.\\nyi=softmax (WNSPhi)\\n1There are members of the BERT family like ELECTRA that do use all examples for training (Clark\\net al., 2020).'), Document(metadata={'source': 1}, page_content='6CHAPTER 6 • V ECTOR SEMANTICS AND EMBEDDINGS\\ngoodnicebadworstnot good\\nwonderfulamazingterriﬁcdislikeworsevery goodincredibly goodfantasticincredibly badnowyouithatwithbyto’sareisathan\\nFigure 6.1 A two-dimensional (t-SNE) projection of embeddings for some words and\\nphrases, showing that words with similar meanings are nearby in space. The original 60-\\ndimensional embeddings were trained for sentiment analysis. Simpliﬁed from Li et al. (2015)\\nwith colors added for explanation.\\nFig. 6.1 shows a visualization of embeddings learned for sentiment analysis,\\nshowing the location of selected words projected down from 60-dimensional space\\ninto a two dimensional space. Notice the distinct regions containing positive words,\\nnegative words, and neutral function words.\\nThe ﬁne-grained model of word similarity of vector semantics offers enormous\\npower to NLP applications. NLP applications like the sentiment classiﬁers of Chap-\\nter 4 or Chapter 5 depend on the same words appearing in the training and test sets.\\nBut by representing words as embeddings, classiﬁers can assign sentiment as long as\\nit sees some words with similar meanings . And as we’ll see, vector semantic models\\ncan be learned automatically from text without supervision.\\nIn this chapter we’ll introduce the two most commonly used models. In the tf-idf\\nmodel, an important baseline, the meaning of a word is deﬁned by a simple function\\nof the counts of nearby words. We will see that this method results in very long\\nvectors that are sparse , i.e. mostly zeros (since most words simply never occur in\\nthe context of others). We’ll introduce the word2vec model family for construct-\\ning short, dense vectors that have useful semantic properties. We’ll also introduce\\nthecosine , the standard way to use embeddings to compute semantic similarity , be-\\ntween two words, two sentences, or two documents, an important tool in practical\\napplications like question answering, summarization, or automatic essay grading.\\n6.3 Words and Vectors\\n“The most important attributes of a vector in 3-space are {Location, Location, Location }”\\nRandall Munroe, https://xkcd.com/2358/\\nVector or distributional models of meaning are generally based on a co-occurrence\\nmatrix , a way of representing how often words co-occur. We’ll look at two popular\\nmatrices: the term-document matrix and the term-term matrix.\\n6.3.1 Vectors and documents\\nIn aterm-document matrix , each row represents a word in the vocabulary and eachterm-document\\nmatrix\\ncolumn represents a document from some collection of documents. Fig. 6.2 shows a\\nsmall selection from a term-document matrix showing the occurrence of four words\\nin four plays by Shakespeare. Each cell in this matrix represents the number of times'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/13.pdf', 'page': 21}, page_content='The BERTS CORE algorithm (Zhang et al., 2020) shown in Fig. 13.11, for example,\\npasses the reference xand the candidate ˜ xthrough BERT, computing a BERT em-\\nbedding for each token xiand ˜xj. Each pair of tokens (xi,˜xj)is scored by its cosine\\nxi·˜xj\\n|xi||˜xj|. Each token in xis matched to a token in ˜ xto compute recall, and each token in\\n˜xis matched to a token in xto compute precision (with each token greedily matched\\nto the most similar token in the corresponding sentence). BERTS CORE provides\\nprecision and recall (and hence F 1):\\nRBERT=1\\n|x|∑\\nxi∈xmax\\n˜xj∈˜xxi·˜xjPBERT=1\\n|˜x|∑\\n˜xj∈˜xmax\\nxi∈xxi·˜xj (13.21)\\nPublished as a conference paper at ICLR 2020\\nReferencethe weather is cold today\\nCandidateit is freezing today\\nCandidateContextualEmbeddingPairwise CosineSimilarityRBERT=(0.713\\x001.27)+(0.515\\x007.94)+...1.27+7.94+1.82+7.90+8.88'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/11.pdf', 'page': 3}, page_content='• The resulting model has about 550M parameters.\\nThe use of WordPiece or SentencePiece Unigram LM tokenization (two of the\\nlarge family of subword tokenization algorithms that includes the BPE algorithm\\nwe saw in Chapter 2) means that—like the large language models of Chapter 10—\\nBERT and its descendants are based on subword tokens rather than words. Every\\ninput sentence ﬁrst has to be tokenized, and then all further processing takes place\\non subword tokens rather than words. This will require, as we’ll see, that for some'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/14.pdf', 'page': 11}, page_content='encodes the query and document, but rather than encoding the entire query or doc-\\nument into one vector, it separately encodes each of them into contextual represen-\\ntations for each token. These BERT representations of each document word can be\\npre-stored for efﬁciency. The relevance score between a query qand a document dis\\na sum of maximum similarity (MaxSim) operators between tokens in qand tokens\\nind. Essentially, for each token in q, ColBERT ﬁnds the most contextually simi-\\nlar token in d, and then sums up these similarities. A relevant document will have\\ntokens that are contextually very similar to the query.\\nMore formally, a question qis tokenized as [q1,..., qn], prepended with a [CLS]\\nand a special [Q]token, truncated to N=32 tokens (or padded with [MASK] tokens if\\nit is shorter), and passed through BERT to get output vectors q= [q1,...,qN]. The\\npassage dwith tokens [d1,..., dm], is processed similarly, including a [CLS] and')]\n",
            "Retrieved docs: [Document(metadata={'source': 1}, page_content='Observer evaluation: acute-evalAnnotators look at two conversations (A + B) and decide which is better:Engagingness: Who would you prefer to talk to for a long conversation? Interestingness: If you had to say one of these speakers is interesting and one is boring, who would you say is more interesting? Humanness: Which speaker sounds more human? Knowledgeable: If you had to say that one speaker is more knowledgeable and one is more ignorant, who is more knowledgeable? Li, M., Weston, J., and Roller, S. (2019). Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. NeurIPS19 Workshop on Conversational AI. '), Document(metadata={'source': 1}, page_content=\"Classifying sentiment for input x5.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions325.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions\"), Document(metadata={'source': 1}, page_content='H.4 • A COUSTIC PHONETICS AND SIGNALS 11\\npart of the wave and one measuring the negative part. More than two samples per\\ncycle increases the amplitude accuracy, but fewer than two samples causes the fre-\\nquency of the wave to be completely missed. Thus, the maximum frequency wave\\nthat can be measured is one whose frequency is half the sample rate (since every\\ncycle needs two samples). This maximum frequency for a given sampling rate is\\ncalled the Nyquist frequency . Most information in human speech is in frequenciesNyquist\\nfrequency\\nbelow 10,000 Hz; thus, a 20,000 Hz sampling rate would be necessary for com-\\nplete accuracy. But telephone speech is ﬁltered by the switching network, and only\\nfrequencies less than 4,000 Hz are transmitted by telephones. Thus, an 8,000 Hz\\nsampling rate is sufﬁcient for telephone-bandwidth speech like the Switchboard\\ncorpus, while 16,000 Hz sampling is often used for microphone speech.\\nEven an 8,000 Hz sampling rate requires 8000 amplitude measurements for each\\nsecond of speech, so it is important to store amplitude measurements efﬁciently.\\nThey are usually stored as integers, either 8 bit (values from -128–127) or 16 bit\\n(values from -32768–32767). This process of representing real-valued numbers as\\nintegers is called quantization because the difference between two integers acts as quantization\\na minimum granularity (a quantum size) and all values that are closer together than\\nthis quantum size are represented identically.\\nOnce data is quantized, it is stored in various formats. One parameter of these\\nformats is the sample rate and sample size discussed above; telephone speech is\\noften sampled at 8 kHz and stored as 8-bit samples, and microphone data is often\\nsampled at 16 kHz and stored as 16-bit samples. Another parameter is the number of\\nchannels . For stereo data or for two-party conversations, we can store both channels channel\\nin the same ﬁle or we can store them in separate ﬁles. A ﬁnal parameter is individual\\nsample storage—linearly or compressed. One common compression format used for\\ntelephone speech is µ-law (often written u-law but still pronounced mu-law). The\\nintuition of log compression algorithms like µ-law is that human hearing is more\\nsensitive at small intensities than large ones; the log represents small values with\\nmore faithfulness at the expense of more error on large values. The linear (unlogged)\\nvalues are generally referred to as linear PCM values (PCM stands for pulse code PCM\\nmodulation, but never mind that). Here’s the equation for compressing a linear PCM\\nsample value xto 8-bit µ-law, (where µ=255 for 8 bits):\\nF(x) =sgn(x)log(1+µ|x|)\\nlog(1+µ)−1≤x≤1 (H.5)\\nThere are a number of standard ﬁle formats for storing the resulting digitized wave-\\nﬁle, such as Microsoft’s .wav and Apple’s AIFF all of which have special headers;\\nsimple headerless “raw” ﬁles are also used. For example, the .wav format is a subset\\nof Microsoft’s RIFF format for multimedia ﬁles; RIFF is a general format that can\\nrepresent a series of nested chunks of data and control information. Figure H.10\\nshows a simple .wav ﬁle with a single data chunk together with its format chunk.\\nFigure H.10 Microsoft waveﬁle header format, assuming simple ﬁle with one chunk. Fol-\\nlowing this 44-byte header would be the data chunk.'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 4}, page_content='10.1 • T HETRANSFORMER : A S ELF-ATTENTION NETWORK 5\\nSelf-AttentionLayerx1a1\\nx2a2a3a4a5\\nx3x4x5\\nFigure 10.2 Information ﬂow in a causal (or masked) self-attention model. In processing\\neach element of the sequence, the model attends to all the inputs up to, and including, the\\ncurrent one. Unlike RNNs, the computations at each time step are independent of all the\\nother steps and therefore can be performed in parallel.\\n10.1.3 Self-attention more formally\\nWe’ve given the intuition of self-attention (as a way to compute representations of a\\nword at a given layer by integrating information from words at the previous layer)\\nand we’ve deﬁned context as all the prior words in the input. Let’s now introduce\\nthe self-attention computation itself.\\nThe core intuition of attention is the idea of comparing an item of interest to a\\ncollection of other items in a way that reveals their relevance in the current context.\\nIn the case of self-attention for language, the set of comparisons are to other words'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='Chapter 26.)\\n10.1.2 Causal or backward-looking self-attention\\nThe concept of context can be used in two ways in self-attention. In causal, or\\nbackward looking self-attention, the context is any of the prior words. In general\\nbidirectional self-attention, the context can include future words. In this chapter\\nwe focus on causal, backward looking self-attention; we’ll introduce bidirectional\\nself-attention in Chapter 11.\\nFig. 10.2 thus illustrates the ﬂow of information in a single causal, or backward\\nlooking, self-attention layer. As with the overall transformer, a self-attention layer\\nmaps input sequences (x1,...,xn)to output sequences of the same length (a1,...,an).\\nWhen processing each item in the input, the model has access to all of the inputs\\nup to and including the one under consideration, but no access to information about\\ninputs beyond the current one. In addition, the computation performed for each item\\nis independent of all the other computations. The ﬁrst point ensures that we can use'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='representation for animal . Figure simpliﬁed from (Uszkoreit, 2017).\\nFig. 10.1 shows an schematic example simpliﬁed from a real transformer (Uszko-\\nreit, 2017). Here we want to compute a contextual representation for the word it, at\\nlayer 6 of the transformer, and we’d like that representation to draw on the represen-\\ntations of all the prior words, from layer 5. The ﬁgure uses color to represent the\\nattention distribution over the contextual words: the word animal has a high atten-\\ntion weight, meaning that as we are computing the representation for it, we will draw\\nmost heavily on the representation for animal . This will be useful for the model to\\nbuild a representation that has the correct meaning for it, which indeed is corefer-\\nent here with the word animal . (We say that a pronoun like itis coreferent with a\\nnoun like animal if they both refer to the same thing; we’ll return to coreference in\\nChapter 26.)\\n10.1.2 Causal or backward-looking self-attention')]\n",
            "Retrieved docs: [Document(metadata={'source': 1}, page_content='22.1 • C OREFERENCE PHENOMENA : LINGUISTIC BACKGROUND 7\\nAppositives: An appositional structure is a noun phrase that appears next to a\\nhead noun phrase, describing the head. In English they often appear in commas, like\\n“a unit of UAL” appearing in apposition to the NP United , orCFO of Megabucks\\nBanking in apposition to Victoria Chen .\\n(22.23) Victoria Chen, CFO of Megabucks Banking, saw ...\\n(22.24) United, a unit of UAL, matched the fares.\\nAppositional NPs are not referring expressions, instead functioning as a kind of\\nsupplementary parenthetical description of the head NP. Nonetheless, sometimes it\\nis useful to link these phrases to an entity they describe, and so some datasets like\\nOntoNotes mark appositional relationships.\\nPredicative and Prenominal NPs: Predicative or attributive NPs describe prop-\\nerties of the head noun. In United is a unit of UAL , the NP a unit of UAL describes\\na property of United, rather than referring to a distinct entity. Thus they are not\\nmarked as mentions in coreference tasks; in our example the NPs $2.3 million and\\nthe company’s president , are attributive, describing properties of her pay andthe\\n38-year-old ; Example (22.27) shows a Chinese example in which the predicate NP\\n(中国最大的城市; China’s biggest city ) is not a mention.\\n(22.25) her pay jumped to $2.3 million\\n(22.26) the 38-year-old became the company’s president\\n(22.27)上海是[中国最大的城市] [Shanghai is China’s biggest city ]\\nExpletives: Many uses of pronouns like itin English and corresponding pronouns\\nin other languages are not referential. Such expletive orpleonastic cases include expletive\\nit is raining , in idioms like hit it off , or in particular syntactic situations like clefts clefts\\n(22.28a) or extraposition (22.28b):\\n(22.28) a. Itwas Emma Goldman who founded Mother Earth\\nb.Itsurprised me that there was a herring hanging on her wall.\\nGenerics: Another kind of expression that does not refer back to an entity explic-\\nitly evoked in the text is generic reference. Consider (22.29).\\n(22.29) I love mangos. They are very tasty.\\nHere, they refers, not to a particular mango or set of mangos, but instead to the class\\nof mangos in general. The pronoun youcan also be used generically:\\n(22.30) In July in San Francisco youhave to wear a jacket.\\n22.1.4 Linguistic Properties of the Coreference Relation\\nNow that we have seen the linguistic properties of individual referring expressions\\nwe turn to properties of the antecedent/anaphor pair. Understanding these properties\\nis helpful both in designing novel features and performing error analyses.\\nNumber Agreement: Referring expressions and their referents must generally\\nagree in number; English she/her/he/him/his/it are singular, we/us/they/them are plu-\\nral, and youis unspeciﬁed for number. So a plural antecedent like the chefs cannot\\ngenerally corefer with a singular anaphor like she. However, algorithms cannot\\nenforce number agreement too strictly. First, semantically plural entities can be re-\\nferred to by either itorthey:\\n(22.31) IBM announced a new machine translation product yesterday. They have\\nbeen working on it for 20 years.'), Document(metadata={'source': 1}, page_content='22.3 • M ENTION DETECTION 11\\nmillion, as the 38-year-old also became the company’s president. It is\\nwidely known that she came to Megabucks from rival Lotsabucks.\\nmight result in the following list of 13 potential mentions:\\nVictoria Chen $2.3 million she\\nCFO of Megabucks Banking the 38-year-old Megabucks\\nMegabucks Banking the company Lotsabucks\\nher the company’s president\\nher pay It\\nMore recent mention detection systems are even more generous; the span-based\\nalgorithm we will describe in Section 22.6 ﬁrst extracts literally all n-gram spans\\nof words up to N=10. Of course recall from Section 22.1.3 that many NPs—and\\nthe overwhelming majority of random n-gram spans—are not referring expressions.\\nTherefore all such mention detection systems need to eventually ﬁlter out pleonas-\\ntic/expletive pronouns like Itabove, appositives like CFO of Megabucks Banking\\nInc, or predicate nominals like the company’s president or$2.3 million .\\nSome of this ﬁltering can be done by rules. Early rule-based systems designed\\nregular expressions to deal with pleonastic it, like the following rules from Lappin\\nand Leass (1994) that use dictionaries of cognitive verbs (e.g., believe ,know ,antic-\\nipate ) to capture pleonastic itin “It is thought that ketchup...”, or modal adjectives\\n(e.g., necessary ,possible ,certain ,important ), for, e.g., “It is likely that I...”. Such\\nrules are sometimes used as part of modern systems:\\nIt is Modaladjective that S\\nIt is Modaladjective (for NP) to VP\\nIt is Cogv-ed that S\\nIt seems/appears/means/follows (that) S\\nMention-detection rules are sometimes designed speciﬁcally for particular eval-\\nuation campaigns. For OntoNotes, for example, mentions are not embedded within\\nlarger mentions, and while numeric quantities are annotated, they are rarely coref-\\nerential. Thus for OntoNotes tasks like CoNLL 2012 (Pradhan et al., 2012a), a\\ncommon ﬁrst pass rule-based mention detection algorithm (Lee et al., 2013) is:\\n1.Take all NPs, possessive pronouns, and named entities.\\n2.Remove numeric quantities (100 dollars, 8%), mentions embedded in\\nlarger mentions, adjectival forms of nations, and stop words (like there ).\\n3.Remove pleonastic itbased on regular expression patterns.\\nRule-based systems, however, are generally insufﬁcient to deal with mention-\\ndetection, and so modern systems incorporate some sort of learned mention detec-\\ntion component, such as a referentiality classiﬁer, an anaphoricity classiﬁer —\\ndetecting whether an NP is an anaphor—or a discourse-new classiﬁer— detecting\\nwhether a mention is discourse-new and a potential antecedent for a future anaphor.\\nAnanaphoricity detector , for example, can draw its positive training examplesanaphoricity\\ndetector\\nfrom any span that is labeled as an anaphoric referring expression in hand-labeled\\ndatasets like OntoNotes, ARRAU , or AnCora. Any other NP or named entity can be\\nmarked as a negative training example. Anaphoricity classiﬁers use features of the\\ncandidate mention such as its head word, surrounding words, deﬁniteness, animacy,\\nlength, position in the sentence/discourse, many of which were ﬁrst proposed in\\nearly work by Ng and Cardie (2002a); see Section 22.5 for more on features.'), Document(metadata={'source': 1}, page_content='10 CHAPTER 22 • C OREFERENCE RESOLUTION AND ENTITY LINKING\\nExactly what counts as a mention and what links are annotated differs from task\\nto task and dataset to dataset. For example some coreference datasets do not label\\nsingletons, making the task much simpler. Resolvers can achieve much higher scores\\non corpora without singletons, since singletons constitute the majority of mentions in\\nrunning text, and they are often hard to distinguish from non-referential NPs. Some\\ntasks use gold mention-detection (i.e. the system is given human-labeled mention\\nboundaries and the task is just to cluster these gold mentions), which eliminates the\\nneed to detect and segment mentions from running text.\\nCoreference is usually evaluated by the CoNLL F1 score, which combines three\\nmetrics: MUC, B3, and CEAF e; Section 22.8 gives the details.\\nLet’s mention a few characteristics of one popular coreference dataset, OntoNotes\\n(Pradhan et al. 2007b, Pradhan et al. 2007a), and the CoNLL 2012 Shared Task\\nbased on it (Pradhan et al., 2012a). OntoNotes contains hand-annotated Chinese\\nand English coreference datasets of roughly one million words each, consisting of\\nnewswire, magazine articles, broadcast news, broadcast conversations, web data and\\nconversational speech data, as well as about 300,000 words of annotated Arabic\\nnewswire. The most important distinguishing characteristic of OntoNotes is that\\nit does not label singletons, simplifying the coreference task, since singletons rep-\\nresent 60%-70% of all entities. In other ways, it is similar to other coreference\\ndatasets. Referring expression NPs that are coreferent are marked as mentions, but\\ngenerics and pleonastic pronouns are not marked. Appositive clauses are not marked\\nas separate mentions, but they are included in the mention. Thus in the NP, “Richard\\nGodown, president of the Industrial Biotechnology Association” the mention is the\\nentire phrase. Prenominal modiﬁers are annotated as separate entities only if they\\nare proper nouns. Thus wheat is not an entity in wheat ﬁelds , but UNis an entity in\\nUN policy (but not adjectives like American inAmerican policy ).\\nA number of corpora mark richer discourse phenomena. The ISNotes corpus\\nannotates a portion of OntoNotes for information status, include bridging examples\\n(Hou et al., 2018). The LitBank coreference corpus (Bamman et al., 2020) contains\\ncoreference annotations for 210,532 tokens from 100 different literary novels, in-\\ncluding singletons and quantiﬁed and negated noun phrases. The AnCora-CO coref-\\nerence corpus (Recasens and Mart ´ı, 2010) contains 400,000 words each of Spanish\\n(AnCora-CO-Es) and Catalan (AnCora-CO-Ca) news data, and includes labels for\\ncomplex phenomena like discourse deixis in both languages. The ARRAU corpus\\n(Uryupina et al., 2020) contains 350,000 words of English marking all NPs, which\\nmeans singleton clusters are available. ARRAU includes diverse genres like dialog\\n(the TRAINS data) and ﬁction (the Pear Stories), and has labels for bridging refer-\\nences, discourse deixis, generics, and ambiguous anaphoric relations.\\n22.3 Mention Detection\\nThe ﬁrst stage of coreference is mention detection : ﬁnding the spans of text thatmention\\ndetection\\nconstitute each mention. Mention detection algorithms are usually very liberal in\\nproposing candidate mentions (i.e., emphasizing recall), and only ﬁltering later. For\\nexample many systems run parsers and named entity taggers on the text and extract\\nevery span that is either an NP, apossessive pronoun , or a named entity .\\nDoing so from our sample text repeated in (22.44):\\n(22.44) Victoria Chen, CFO of Megabucks Banking, saw her pay jump to $2.3'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/slides/4_NB_2024.pdf', 'page': 2}, page_content='Dan JurafskyWho wrote which Federalist papers?•1787-8: anonymous essays try to convince New York to ratify U.S Constitution:  Jay, Madison, Hamilton.  •Authorship of 12 of the letters in dispute•1963: solved by Mostellerand Wallace using Bayesian methods\\nJames MadisonAlexander Hamilton'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/19.pdf', 'page': 4}, page_content='George Marshall, Secretary of State of the United States\\nPER (named|appointed|chose|etc.) PER Prep? POSITION\\nTruman appointed Marshall Secretary of State\\nPER [be]? (named|appointed|etc.) Prep? ORG POSITION\\nGeorge Marshall was named US Secretary of State\\nHand-built patterns have the advantage of high-precision and they can be tailored\\nto speciﬁc domains. On the other hand, they are often low-recall, and it’s a lot of\\nwork to create them for all possible patterns.\\n19.2.2 Relation Extraction via Supervised Learning\\nSupervised machine learning approaches to relation extraction follow a scheme that\\nshould be familiar by now. A ﬁxed set of relations and entities is chosen, a training\\ncorpus is hand-annotated with the relations and entities, and the annotated texts are\\nthen used to train classiﬁers to annotate an unseen test set.\\nThe most straightforward approach, illustrated in Fig. 19.5 is: (1) Find pairs of\\nnamed entities (usually in the same sentence). (2): Apply a relation-classiﬁcation'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/slides/vectorsemantics2024.pdf', 'page': 34}, page_content='51015202530510Henry V [4,13]As You Like It [36,1]Julius Caesar [1,7]battle foolTwelfth Night [58,0]1540')]\n",
            "-----------------------------\n",
            "Weight for FAISS: 1\n",
            "Weight for BM25: 0\n",
            "\n",
            "Testing retriever with a sample query:\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/13.pdf', 'page': 21}, page_content='The BERTS CORE algorithm (Zhang et al., 2020) shown in Fig. 13.11, for example,\\npasses the reference xand the candidate ˜ xthrough BERT, computing a BERT em-\\nbedding for each token xiand ˜xj. Each pair of tokens (xi,˜xj)is scored by its cosine\\nxi·˜xj\\n|xi||˜xj|. Each token in xis matched to a token in ˜ xto compute recall, and each token in\\n˜xis matched to a token in xto compute precision (with each token greedily matched\\nto the most similar token in the corresponding sentence). BERTS CORE provides\\nprecision and recall (and hence F 1):\\nRBERT=1\\n|x|∑\\nxi∈xmax\\n˜xj∈˜xxi·˜xjPBERT=1\\n|˜x|∑\\n˜xj∈˜xmax\\nxi∈xxi·˜xj (13.21)\\nPublished as a conference paper at ICLR 2020\\nReferencethe weather is cold today\\nCandidateit is freezing today\\nCandidateContextualEmbeddingPairwise CosineSimilarityRBERT=(0.713\\x001.27)+(0.515\\x007.94)+...1.27+7.94+1.82+7.90+8.88'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/11.pdf', 'page': 3}, page_content='• The resulting model has about 550M parameters.\\nThe use of WordPiece or SentencePiece Unigram LM tokenization (two of the\\nlarge family of subword tokenization algorithms that includes the BPE algorithm\\nwe saw in Chapter 2) means that—like the large language models of Chapter 10—\\nBERT and its descendants are based on subword tokens rather than words. Every\\ninput sentence ﬁrst has to be tokenized, and then all further processing takes place\\non subword tokens rather than words. This will require, as we’ll see, that for some'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/14.pdf', 'page': 11}, page_content='encodes the query and document, but rather than encoding the entire query or doc-\\nument into one vector, it separately encodes each of them into contextual represen-\\ntations for each token. These BERT representations of each document word can be\\npre-stored for efﬁciency. The relevance score between a query qand a document dis\\na sum of maximum similarity (MaxSim) operators between tokens in qand tokens\\nind. Essentially, for each token in q, ColBERT ﬁnds the most contextually simi-\\nlar token in d, and then sums up these similarities. A relevant document will have\\ntokens that are contextually very similar to the query.\\nMore formally, a question qis tokenized as [q1,..., qn], prepended with a [CLS]\\nand a special [Q]token, truncated to N=32 tokens (or padded with [MASK] tokens if\\nit is shorter), and passed through BERT to get output vectors q= [q1,...,qN]. The\\npassage dwith tokens [d1,..., dm], is processed similarly, including a [CLS] and'), Document(metadata={'source': 1}, page_content='11.4 • F INE-TUNING LANGUAGE MODELS 13\\nmodels or from autoregressive ones) have the property that the vectors for all words\\nare extremely similar. If we look at the embeddings from the ﬁnal layer of BERT\\nor other models, embeddings for instances of any two randomly chosen words will\\nhave extremely high cosines that can be quite close to 1, meaning all word vectors\\ntend to point in the same direction. The property of vectors in a system all tending\\nto point in the same direction is known as anisotropy . Ethayarajh (2019) deﬁnes\\ntheanisotropy of a model as the expected cosine similarity of any pair of words in anisotropy\\na corpus. The word ‘isotropy’ means uniformity in all directions, so in an isotropic\\nmodel, the collection of vectors should point in all directions and the expected cosine\\nbetween a pair of random embeddings would be zero. Timkey and van Schijndel\\n(2021) show that one cause of anisotropy is that cosine measures are dominated by\\na small number of dimensions of the contextual embedding whose values are very\\ndifferent than the others: these rogue dimensions have very large magnitudes and\\nvery high variance.\\nTimkey and van Schijndel (2021) shows that we can make the embeddings more\\nisotropic by standardizing (z-scoring) the vectors, i.e., subtracting the mean and\\ndividing by the variance. Given a set Cof all the embeddings in some corpus, each\\nwith dimensionality d(i.e., x∈Rd), the mean vector µ∈Rdis:\\nµ=1\\n|C|∑\\nx∈Cx (11.10)\\nThe standard deviation in each dimension σ∈Rdis:\\nσ=√\\n1\\n|C|∑\\nx∈C(x−µ)2(11.11)\\nThen each word vector xis replaced by a standardized version z:\\nz=x−µ\\nσ(11.12)\\nOne problem with cosine that is not solved by standardization is that cosine tends\\nto underestimate human judgments on similarity of word meaning for very frequent\\nwords (Zhou et al., 2022).\\nIn the next section we’ll see the most common use of contextual representations:\\nas representations of words or even entire sentences that can be the inputs to classi-\\nﬁers in the ﬁne-tuning process for downstream NLP applications.\\n11.4 Fine-Tuning Language Models\\nThe power of pretrained language models lies in their ability to extract generaliza-\\ntions from large amounts of text—generalizations that are useful for myriad down-\\nstream applications. There are two ways to make practical use of the generaliza-\\ntions. One way is to use natural language to prompt the model, putting it in a state\\nwhere it contextually generates what we want. We’ll introduce prompting in Chap-\\nter 12. An alternative is to create interfaces from pretrained language models to\\ndownstream applications through a process called ﬁne-tuning . In ﬁne-tuning, we ﬁne-tuning\\ncreate applications on top of pretrained models by adding a small set of application-\\nspeciﬁc parameters. The ﬁne-tuning process consists of using labeled data about'), Document(metadata={'source': 1}, page_content='11.2 • T RAINING BIDIRECTIONAL ENCODERS 7\\nmasked be M, the version of that sentence with some tokens replaced by masks be\\nxmask, and the sequence of output vectors be z. For a given input token xi, such as\\nthe word long in Fig. 11.4, the loss is the probability of the correct word long, given\\nxmask(as summarized in the single output vector zi):\\nLMLM(xi) =−logP(xi|zi)\\nThe gradients that form the basis for the weight updates are based on the average\\nloss over the sampled learning items from a single training sequence (or batch of\\nsequences).\\nLMLM=−1\\n|M|∑\\ni∈MlogP(xi|zi)\\nNote that only the tokens in Mplay a role in learning; the other words play no role\\nin the loss function, so in that sense BERT and its descendents are inefﬁcient; only\\n15% of the input samples in the training data are actually used for training weights.\\n1\\n11.2.2 Next Sentence Prediction\\nThe focus of mask-based learning is on predicting words from surrounding contexts\\nwith the goal of producing effective word-level representations. However, an im-\\nportant class of applications involves determining the relationship between pairs of\\nsentences. These include tasks like paraphrase detection (detecting if two sentences\\nhave similar meanings), entailment (detecting if the meanings of two sentences en-\\ntail or contradict each other) or discourse coherence (deciding if two neighboring\\nsentences form a coherent discourse).\\nTo capture the kind of knowledge required for applications such as these, some\\nmodels in the BERT family include a second learning objective called Next Sen-\\ntence Prediction (NSP). In this task, the model is presented with pairs of sentencesNext Sentence\\nPrediction\\nand is asked to predict whether each pair consists of an actual pair of adjacent sen-\\ntences from the training corpus or a pair of unrelated sentences. In BERT, 50% of\\nthe training pairs consisted of positive pairs, and in the other 50% the second sen-\\ntence of a pair was randomly selected from elsewhere in the corpus. The NSP loss\\nis based on how well the model can distinguish true pairs from random pairs.\\nTo facilitate NSP training, BERT introduces two new tokens to the input repre-\\nsentation (tokens that will prove useful for ﬁne-tuning as well). After tokenizing the\\ninput with the subword model, the token [CLS] is prepended to the input sentence\\npair, and the token [SEP] is placed between the sentences and after the ﬁnal token of\\nthe second sentence. Finally, embeddings representing the ﬁrst and second segments\\nof the input are added to the word and positional embeddings to allow the model to\\nmore easily distinguish the input sentences.\\nDuring training, the output vector from the ﬁnal layer associated with the [CLS]\\ntoken represents the next sentence prediction. As with the MLM objective, a learned\\nset of classiﬁcation weights WNSP∈R2×dhis used to produce a two-class prediction\\nfrom the raw [CLS] vector.\\nyi=softmax (WNSPhi)\\n1There are members of the BERT family like ELECTRA that do use all examples for training (Clark\\net al., 2020).'), Document(metadata={'source': 1}, page_content='6CHAPTER 6 • V ECTOR SEMANTICS AND EMBEDDINGS\\ngoodnicebadworstnot good\\nwonderfulamazingterriﬁcdislikeworsevery goodincredibly goodfantasticincredibly badnowyouithatwithbyto’sareisathan\\nFigure 6.1 A two-dimensional (t-SNE) projection of embeddings for some words and\\nphrases, showing that words with similar meanings are nearby in space. The original 60-\\ndimensional embeddings were trained for sentiment analysis. Simpliﬁed from Li et al. (2015)\\nwith colors added for explanation.\\nFig. 6.1 shows a visualization of embeddings learned for sentiment analysis,\\nshowing the location of selected words projected down from 60-dimensional space\\ninto a two dimensional space. Notice the distinct regions containing positive words,\\nnegative words, and neutral function words.\\nThe ﬁne-grained model of word similarity of vector semantics offers enormous\\npower to NLP applications. NLP applications like the sentiment classiﬁers of Chap-\\nter 4 or Chapter 5 depend on the same words appearing in the training and test sets.\\nBut by representing words as embeddings, classiﬁers can assign sentiment as long as\\nit sees some words with similar meanings . And as we’ll see, vector semantic models\\ncan be learned automatically from text without supervision.\\nIn this chapter we’ll introduce the two most commonly used models. In the tf-idf\\nmodel, an important baseline, the meaning of a word is deﬁned by a simple function\\nof the counts of nearby words. We will see that this method results in very long\\nvectors that are sparse , i.e. mostly zeros (since most words simply never occur in\\nthe context of others). We’ll introduce the word2vec model family for construct-\\ning short, dense vectors that have useful semantic properties. We’ll also introduce\\nthecosine , the standard way to use embeddings to compute semantic similarity , be-\\ntween two words, two sentences, or two documents, an important tool in practical\\napplications like question answering, summarization, or automatic essay grading.\\n6.3 Words and Vectors\\n“The most important attributes of a vector in 3-space are {Location, Location, Location }”\\nRandall Munroe, https://xkcd.com/2358/\\nVector or distributional models of meaning are generally based on a co-occurrence\\nmatrix , a way of representing how often words co-occur. We’ll look at two popular\\nmatrices: the term-document matrix and the term-term matrix.\\n6.3.1 Vectors and documents\\nIn aterm-document matrix , each row represents a word in the vocabulary and eachterm-document\\nmatrix\\ncolumn represents a document from some collection of documents. Fig. 6.2 shows a\\nsmall selection from a term-document matrix showing the occurrence of four words\\nin four plays by Shakespeare. Each cell in this matrix represents the number of times')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 4}, page_content='10.1 • T HETRANSFORMER : A S ELF-ATTENTION NETWORK 5\\nSelf-AttentionLayerx1a1\\nx2a2a3a4a5\\nx3x4x5\\nFigure 10.2 Information ﬂow in a causal (or masked) self-attention model. In processing\\neach element of the sequence, the model attends to all the inputs up to, and including, the\\ncurrent one. Unlike RNNs, the computations at each time step are independent of all the\\nother steps and therefore can be performed in parallel.\\n10.1.3 Self-attention more formally\\nWe’ve given the intuition of self-attention (as a way to compute representations of a\\nword at a given layer by integrating information from words at the previous layer)\\nand we’ve deﬁned context as all the prior words in the input. Let’s now introduce\\nthe self-attention computation itself.\\nThe core intuition of attention is the idea of comparing an item of interest to a\\ncollection of other items in a way that reveals their relevance in the current context.\\nIn the case of self-attention for language, the set of comparisons are to other words'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='Chapter 26.)\\n10.1.2 Causal or backward-looking self-attention\\nThe concept of context can be used in two ways in self-attention. In causal, or\\nbackward looking self-attention, the context is any of the prior words. In general\\nbidirectional self-attention, the context can include future words. In this chapter\\nwe focus on causal, backward looking self-attention; we’ll introduce bidirectional\\nself-attention in Chapter 11.\\nFig. 10.2 thus illustrates the ﬂow of information in a single causal, or backward\\nlooking, self-attention layer. As with the overall transformer, a self-attention layer\\nmaps input sequences (x1,...,xn)to output sequences of the same length (a1,...,an).\\nWhen processing each item in the input, the model has access to all of the inputs\\nup to and including the one under consideration, but no access to information about\\ninputs beyond the current one. In addition, the computation performed for each item\\nis independent of all the other computations. The ﬁrst point ensures that we can use'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='representation for animal . Figure simpliﬁed from (Uszkoreit, 2017).\\nFig. 10.1 shows an schematic example simpliﬁed from a real transformer (Uszko-\\nreit, 2017). Here we want to compute a contextual representation for the word it, at\\nlayer 6 of the transformer, and we’d like that representation to draw on the represen-\\ntations of all the prior words, from layer 5. The ﬁgure uses color to represent the\\nattention distribution over the contextual words: the word animal has a high atten-\\ntion weight, meaning that as we are computing the representation for it, we will draw\\nmost heavily on the representation for animal . This will be useful for the model to\\nbuild a representation that has the correct meaning for it, which indeed is corefer-\\nent here with the word animal . (We say that a pronoun like itis coreferent with a\\nnoun like animal if they both refer to the same thing; we’ll return to coreference in\\nChapter 26.)\\n10.1.2 Causal or backward-looking self-attention'), Document(metadata={'source': 1}, page_content='Observer evaluation: acute-evalAnnotators look at two conversations (A + B) and decide which is better:Engagingness: Who would you prefer to talk to for a long conversation? Interestingness: If you had to say one of these speakers is interesting and one is boring, who would you say is more interesting? Humanness: Which speaker sounds more human? Knowledgeable: If you had to say that one speaker is more knowledgeable and one is more ignorant, who is more knowledgeable? Li, M., Weston, J., and Roller, S. (2019). Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. NeurIPS19 Workshop on Conversational AI. '), Document(metadata={'source': 1}, page_content=\"Classifying sentiment for input x5.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions325.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions\"), Document(metadata={'source': 1}, page_content='H.4 • A COUSTIC PHONETICS AND SIGNALS 11\\npart of the wave and one measuring the negative part. More than two samples per\\ncycle increases the amplitude accuracy, but fewer than two samples causes the fre-\\nquency of the wave to be completely missed. Thus, the maximum frequency wave\\nthat can be measured is one whose frequency is half the sample rate (since every\\ncycle needs two samples). This maximum frequency for a given sampling rate is\\ncalled the Nyquist frequency . Most information in human speech is in frequenciesNyquist\\nfrequency\\nbelow 10,000 Hz; thus, a 20,000 Hz sampling rate would be necessary for com-\\nplete accuracy. But telephone speech is ﬁltered by the switching network, and only\\nfrequencies less than 4,000 Hz are transmitted by telephones. Thus, an 8,000 Hz\\nsampling rate is sufﬁcient for telephone-bandwidth speech like the Switchboard\\ncorpus, while 16,000 Hz sampling is often used for microphone speech.\\nEven an 8,000 Hz sampling rate requires 8000 amplitude measurements for each\\nsecond of speech, so it is important to store amplitude measurements efﬁciently.\\nThey are usually stored as integers, either 8 bit (values from -128–127) or 16 bit\\n(values from -32768–32767). This process of representing real-valued numbers as\\nintegers is called quantization because the difference between two integers acts as quantization\\na minimum granularity (a quantum size) and all values that are closer together than\\nthis quantum size are represented identically.\\nOnce data is quantized, it is stored in various formats. One parameter of these\\nformats is the sample rate and sample size discussed above; telephone speech is\\noften sampled at 8 kHz and stored as 8-bit samples, and microphone data is often\\nsampled at 16 kHz and stored as 16-bit samples. Another parameter is the number of\\nchannels . For stereo data or for two-party conversations, we can store both channels channel\\nin the same ﬁle or we can store them in separate ﬁles. A ﬁnal parameter is individual\\nsample storage—linearly or compressed. One common compression format used for\\ntelephone speech is µ-law (often written u-law but still pronounced mu-law). The\\nintuition of log compression algorithms like µ-law is that human hearing is more\\nsensitive at small intensities than large ones; the log represents small values with\\nmore faithfulness at the expense of more error on large values. The linear (unlogged)\\nvalues are generally referred to as linear PCM values (PCM stands for pulse code PCM\\nmodulation, but never mind that). Here’s the equation for compressing a linear PCM\\nsample value xto 8-bit µ-law, (where µ=255 for 8 bits):\\nF(x) =sgn(x)log(1+µ|x|)\\nlog(1+µ)−1≤x≤1 (H.5)\\nThere are a number of standard ﬁle formats for storing the resulting digitized wave-\\nﬁle, such as Microsoft’s .wav and Apple’s AIFF all of which have special headers;\\nsimple headerless “raw” ﬁles are also used. For example, the .wav format is a subset\\nof Microsoft’s RIFF format for multimedia ﬁles; RIFF is a general format that can\\nrepresent a series of nested chunks of data and control information. Figure H.10\\nshows a simple .wav ﬁle with a single data chunk together with its format chunk.\\nFigure H.10 Microsoft waveﬁle header format, assuming simple ﬁle with one chunk. Fol-\\nlowing this 44-byte header would be the data chunk.')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/slides/4_NB_2024.pdf', 'page': 2}, page_content='Dan JurafskyWho wrote which Federalist papers?•1787-8: anonymous essays try to convince New York to ratify U.S Constitution:  Jay, Madison, Hamilton.  •Authorship of 12 of the letters in dispute•1963: solved by Mostellerand Wallace using Bayesian methods\\nJames MadisonAlexander Hamilton'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/19.pdf', 'page': 4}, page_content='George Marshall, Secretary of State of the United States\\nPER (named|appointed|chose|etc.) PER Prep? POSITION\\nTruman appointed Marshall Secretary of State\\nPER [be]? (named|appointed|etc.) Prep? ORG POSITION\\nGeorge Marshall was named US Secretary of State\\nHand-built patterns have the advantage of high-precision and they can be tailored\\nto speciﬁc domains. On the other hand, they are often low-recall, and it’s a lot of\\nwork to create them for all possible patterns.\\n19.2.2 Relation Extraction via Supervised Learning\\nSupervised machine learning approaches to relation extraction follow a scheme that\\nshould be familiar by now. A ﬁxed set of relations and entities is chosen, a training\\ncorpus is hand-annotated with the relations and entities, and the annotated texts are\\nthen used to train classiﬁers to annotate an unseen test set.\\nThe most straightforward approach, illustrated in Fig. 19.5 is: (1) Find pairs of\\nnamed entities (usually in the same sentence). (2): Apply a relation-classiﬁcation'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/slides/vectorsemantics2024.pdf', 'page': 34}, page_content='51015202530510Henry V [4,13]As You Like It [36,1]Julius Caesar [1,7]battle foolTwelfth Night [58,0]1540'), Document(metadata={'source': 1}, page_content='22.1 • C OREFERENCE PHENOMENA : LINGUISTIC BACKGROUND 7\\nAppositives: An appositional structure is a noun phrase that appears next to a\\nhead noun phrase, describing the head. In English they often appear in commas, like\\n“a unit of UAL” appearing in apposition to the NP United , orCFO of Megabucks\\nBanking in apposition to Victoria Chen .\\n(22.23) Victoria Chen, CFO of Megabucks Banking, saw ...\\n(22.24) United, a unit of UAL, matched the fares.\\nAppositional NPs are not referring expressions, instead functioning as a kind of\\nsupplementary parenthetical description of the head NP. Nonetheless, sometimes it\\nis useful to link these phrases to an entity they describe, and so some datasets like\\nOntoNotes mark appositional relationships.\\nPredicative and Prenominal NPs: Predicative or attributive NPs describe prop-\\nerties of the head noun. In United is a unit of UAL , the NP a unit of UAL describes\\na property of United, rather than referring to a distinct entity. Thus they are not\\nmarked as mentions in coreference tasks; in our example the NPs $2.3 million and\\nthe company’s president , are attributive, describing properties of her pay andthe\\n38-year-old ; Example (22.27) shows a Chinese example in which the predicate NP\\n(中国最大的城市; China’s biggest city ) is not a mention.\\n(22.25) her pay jumped to $2.3 million\\n(22.26) the 38-year-old became the company’s president\\n(22.27)上海是[中国最大的城市] [Shanghai is China’s biggest city ]\\nExpletives: Many uses of pronouns like itin English and corresponding pronouns\\nin other languages are not referential. Such expletive orpleonastic cases include expletive\\nit is raining , in idioms like hit it off , or in particular syntactic situations like clefts clefts\\n(22.28a) or extraposition (22.28b):\\n(22.28) a. Itwas Emma Goldman who founded Mother Earth\\nb.Itsurprised me that there was a herring hanging on her wall.\\nGenerics: Another kind of expression that does not refer back to an entity explic-\\nitly evoked in the text is generic reference. Consider (22.29).\\n(22.29) I love mangos. They are very tasty.\\nHere, they refers, not to a particular mango or set of mangos, but instead to the class\\nof mangos in general. The pronoun youcan also be used generically:\\n(22.30) In July in San Francisco youhave to wear a jacket.\\n22.1.4 Linguistic Properties of the Coreference Relation\\nNow that we have seen the linguistic properties of individual referring expressions\\nwe turn to properties of the antecedent/anaphor pair. Understanding these properties\\nis helpful both in designing novel features and performing error analyses.\\nNumber Agreement: Referring expressions and their referents must generally\\nagree in number; English she/her/he/him/his/it are singular, we/us/they/them are plu-\\nral, and youis unspeciﬁed for number. So a plural antecedent like the chefs cannot\\ngenerally corefer with a singular anaphor like she. However, algorithms cannot\\nenforce number agreement too strictly. First, semantically plural entities can be re-\\nferred to by either itorthey:\\n(22.31) IBM announced a new machine translation product yesterday. They have\\nbeen working on it for 20 years.'), Document(metadata={'source': 1}, page_content='22.3 • M ENTION DETECTION 11\\nmillion, as the 38-year-old also became the company’s president. It is\\nwidely known that she came to Megabucks from rival Lotsabucks.\\nmight result in the following list of 13 potential mentions:\\nVictoria Chen $2.3 million she\\nCFO of Megabucks Banking the 38-year-old Megabucks\\nMegabucks Banking the company Lotsabucks\\nher the company’s president\\nher pay It\\nMore recent mention detection systems are even more generous; the span-based\\nalgorithm we will describe in Section 22.6 ﬁrst extracts literally all n-gram spans\\nof words up to N=10. Of course recall from Section 22.1.3 that many NPs—and\\nthe overwhelming majority of random n-gram spans—are not referring expressions.\\nTherefore all such mention detection systems need to eventually ﬁlter out pleonas-\\ntic/expletive pronouns like Itabove, appositives like CFO of Megabucks Banking\\nInc, or predicate nominals like the company’s president or$2.3 million .\\nSome of this ﬁltering can be done by rules. Early rule-based systems designed\\nregular expressions to deal with pleonastic it, like the following rules from Lappin\\nand Leass (1994) that use dictionaries of cognitive verbs (e.g., believe ,know ,antic-\\nipate ) to capture pleonastic itin “It is thought that ketchup...”, or modal adjectives\\n(e.g., necessary ,possible ,certain ,important ), for, e.g., “It is likely that I...”. Such\\nrules are sometimes used as part of modern systems:\\nIt is Modaladjective that S\\nIt is Modaladjective (for NP) to VP\\nIt is Cogv-ed that S\\nIt seems/appears/means/follows (that) S\\nMention-detection rules are sometimes designed speciﬁcally for particular eval-\\nuation campaigns. For OntoNotes, for example, mentions are not embedded within\\nlarger mentions, and while numeric quantities are annotated, they are rarely coref-\\nerential. Thus for OntoNotes tasks like CoNLL 2012 (Pradhan et al., 2012a), a\\ncommon ﬁrst pass rule-based mention detection algorithm (Lee et al., 2013) is:\\n1.Take all NPs, possessive pronouns, and named entities.\\n2.Remove numeric quantities (100 dollars, 8%), mentions embedded in\\nlarger mentions, adjectival forms of nations, and stop words (like there ).\\n3.Remove pleonastic itbased on regular expression patterns.\\nRule-based systems, however, are generally insufﬁcient to deal with mention-\\ndetection, and so modern systems incorporate some sort of learned mention detec-\\ntion component, such as a referentiality classiﬁer, an anaphoricity classiﬁer —\\ndetecting whether an NP is an anaphor—or a discourse-new classiﬁer— detecting\\nwhether a mention is discourse-new and a potential antecedent for a future anaphor.\\nAnanaphoricity detector , for example, can draw its positive training examplesanaphoricity\\ndetector\\nfrom any span that is labeled as an anaphoric referring expression in hand-labeled\\ndatasets like OntoNotes, ARRAU , or AnCora. Any other NP or named entity can be\\nmarked as a negative training example. Anaphoricity classiﬁers use features of the\\ncandidate mention such as its head word, surrounding words, deﬁniteness, animacy,\\nlength, position in the sentence/discourse, many of which were ﬁrst proposed in\\nearly work by Ng and Cardie (2002a); see Section 22.5 for more on features.'), Document(metadata={'source': 1}, page_content='10 CHAPTER 22 • C OREFERENCE RESOLUTION AND ENTITY LINKING\\nExactly what counts as a mention and what links are annotated differs from task\\nto task and dataset to dataset. For example some coreference datasets do not label\\nsingletons, making the task much simpler. Resolvers can achieve much higher scores\\non corpora without singletons, since singletons constitute the majority of mentions in\\nrunning text, and they are often hard to distinguish from non-referential NPs. Some\\ntasks use gold mention-detection (i.e. the system is given human-labeled mention\\nboundaries and the task is just to cluster these gold mentions), which eliminates the\\nneed to detect and segment mentions from running text.\\nCoreference is usually evaluated by the CoNLL F1 score, which combines three\\nmetrics: MUC, B3, and CEAF e; Section 22.8 gives the details.\\nLet’s mention a few characteristics of one popular coreference dataset, OntoNotes\\n(Pradhan et al. 2007b, Pradhan et al. 2007a), and the CoNLL 2012 Shared Task\\nbased on it (Pradhan et al., 2012a). OntoNotes contains hand-annotated Chinese\\nand English coreference datasets of roughly one million words each, consisting of\\nnewswire, magazine articles, broadcast news, broadcast conversations, web data and\\nconversational speech data, as well as about 300,000 words of annotated Arabic\\nnewswire. The most important distinguishing characteristic of OntoNotes is that\\nit does not label singletons, simplifying the coreference task, since singletons rep-\\nresent 60%-70% of all entities. In other ways, it is similar to other coreference\\ndatasets. Referring expression NPs that are coreferent are marked as mentions, but\\ngenerics and pleonastic pronouns are not marked. Appositive clauses are not marked\\nas separate mentions, but they are included in the mention. Thus in the NP, “Richard\\nGodown, president of the Industrial Biotechnology Association” the mention is the\\nentire phrase. Prenominal modiﬁers are annotated as separate entities only if they\\nare proper nouns. Thus wheat is not an entity in wheat ﬁelds , but UNis an entity in\\nUN policy (but not adjectives like American inAmerican policy ).\\nA number of corpora mark richer discourse phenomena. The ISNotes corpus\\nannotates a portion of OntoNotes for information status, include bridging examples\\n(Hou et al., 2018). The LitBank coreference corpus (Bamman et al., 2020) contains\\ncoreference annotations for 210,532 tokens from 100 different literary novels, in-\\ncluding singletons and quantiﬁed and negated noun phrases. The AnCora-CO coref-\\nerence corpus (Recasens and Mart ´ı, 2010) contains 400,000 words each of Spanish\\n(AnCora-CO-Es) and Catalan (AnCora-CO-Ca) news data, and includes labels for\\ncomplex phenomena like discourse deixis in both languages. The ARRAU corpus\\n(Uryupina et al., 2020) contains 350,000 words of English marking all NPs, which\\nmeans singleton clusters are available. ARRAU includes diverse genres like dialog\\n(the TRAINS data) and ﬁction (the Pear Stories), and has labels for bridging refer-\\nences, discourse deixis, generics, and ambiguous anaphoric relations.\\n22.3 Mention Detection\\nThe ﬁrst stage of coreference is mention detection : ﬁnding the spans of text thatmention\\ndetection\\nconstitute each mention. Mention detection algorithms are usually very liberal in\\nproposing candidate mentions (i.e., emphasizing recall), and only ﬁltering later. For\\nexample many systems run parsers and named entity taggers on the text and extract\\nevery span that is either an NP, apossessive pronoun , or a named entity .\\nDoing so from our sample text repeated in (22.44):\\n(22.44) Victoria Chen, CFO of Megabucks Banking, saw her pay jump to $2.3')]\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example weights tuning\n",
        "for weight_faiss in [0, 1]:\n",
        "    weight_bm25 = 1 - weight_faiss\n",
        "    retriever_chain.weights = [weight_bm25, weight_faiss]\n",
        "\n",
        "    # Test the retriever with a sample query\n",
        "    print(f\"Weight for FAISS: {weight_faiss}\")\n",
        "    print(f\"Weight for BM25: {weight_bm25}\\n\")\n",
        "    print(\"Testing retriever with a sample query:\")\n",
        "    query = \"ٌWhat are the applications of BERT?\"\n",
        "    retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "    print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "\n",
        "    query = \"ٌWhat is self-attention?\"\n",
        "    retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "    print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "    query = \"ٌWho is the president of USA?\"\n",
        "    retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "    print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "    print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1UZjfA_K94qR"
      },
      "outputs": [],
      "source": [
        "weight_bm25 = 0.3\n",
        "weight_faiss = 0.7\n",
        "retriever_chain.weights = [weight_bm25, weight_faiss]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BWZ0OMU_7G-",
        "outputId": "1e3471a4-882c-403d-ac25-69b9ae9a7400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 4}, page_content='10.1 • T HETRANSFORMER : A S ELF-ATTENTION NETWORK 5\\nSelf-AttentionLayerx1a1\\nx2a2a3a4a5\\nx3x4x5\\nFigure 10.2 Information ﬂow in a causal (or masked) self-attention model. In processing\\neach element of the sequence, the model attends to all the inputs up to, and including, the\\ncurrent one. Unlike RNNs, the computations at each time step are independent of all the\\nother steps and therefore can be performed in parallel.\\n10.1.3 Self-attention more formally\\nWe’ve given the intuition of self-attention (as a way to compute representations of a\\nword at a given layer by integrating information from words at the previous layer)\\nand we’ve deﬁned context as all the prior words in the input. Let’s now introduce\\nthe self-attention computation itself.\\nThe core intuition of attention is the idea of comparing an item of interest to a\\ncollection of other items in a way that reveals their relevance in the current context.\\nIn the case of self-attention for language, the set of comparisons are to other words'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='Chapter 26.)\\n10.1.2 Causal or backward-looking self-attention\\nThe concept of context can be used in two ways in self-attention. In causal, or\\nbackward looking self-attention, the context is any of the prior words. In general\\nbidirectional self-attention, the context can include future words. In this chapter\\nwe focus on causal, backward looking self-attention; we’ll introduce bidirectional\\nself-attention in Chapter 11.\\nFig. 10.2 thus illustrates the ﬂow of information in a single causal, or backward\\nlooking, self-attention layer. As with the overall transformer, a self-attention layer\\nmaps input sequences (x1,...,xn)to output sequences of the same length (a1,...,an).\\nWhen processing each item in the input, the model has access to all of the inputs\\nup to and including the one under consideration, but no access to information about\\ninputs beyond the current one. In addition, the computation performed for each item\\nis independent of all the other computations. The ﬁrst point ensures that we can use'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='representation for animal . Figure simpliﬁed from (Uszkoreit, 2017).\\nFig. 10.1 shows an schematic example simpliﬁed from a real transformer (Uszko-\\nreit, 2017). Here we want to compute a contextual representation for the word it, at\\nlayer 6 of the transformer, and we’d like that representation to draw on the represen-\\ntations of all the prior words, from layer 5. The ﬁgure uses color to represent the\\nattention distribution over the contextual words: the word animal has a high atten-\\ntion weight, meaning that as we are computing the representation for it, we will draw\\nmost heavily on the representation for animal . This will be useful for the model to\\nbuild a representation that has the correct meaning for it, which indeed is corefer-\\nent here with the word animal . (We say that a pronoun like itis coreferent with a\\nnoun like animal if they both refer to the same thing; we’ll return to coreference in\\nChapter 26.)\\n10.1.2 Causal or backward-looking self-attention'), Document(metadata={'source': 1}, page_content='Observer evaluation: acute-evalAnnotators look at two conversations (A + B) and decide which is better:Engagingness: Who would you prefer to talk to for a long conversation? Interestingness: If you had to say one of these speakers is interesting and one is boring, who would you say is more interesting? Humanness: Which speaker sounds more human? Knowledgeable: If you had to say that one speaker is more knowledgeable and one is more ignorant, who is more knowledgeable? Li, M., Weston, J., and Roller, S. (2019). Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. NeurIPS19 Workshop on Conversational AI. '), Document(metadata={'source': 1}, page_content=\"Classifying sentiment for input x5.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions325.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions\"), Document(metadata={'source': 1}, page_content='H.4 • A COUSTIC PHONETICS AND SIGNALS 11\\npart of the wave and one measuring the negative part. More than two samples per\\ncycle increases the amplitude accuracy, but fewer than two samples causes the fre-\\nquency of the wave to be completely missed. Thus, the maximum frequency wave\\nthat can be measured is one whose frequency is half the sample rate (since every\\ncycle needs two samples). This maximum frequency for a given sampling rate is\\ncalled the Nyquist frequency . Most information in human speech is in frequenciesNyquist\\nfrequency\\nbelow 10,000 Hz; thus, a 20,000 Hz sampling rate would be necessary for com-\\nplete accuracy. But telephone speech is ﬁltered by the switching network, and only\\nfrequencies less than 4,000 Hz are transmitted by telephones. Thus, an 8,000 Hz\\nsampling rate is sufﬁcient for telephone-bandwidth speech like the Switchboard\\ncorpus, while 16,000 Hz sampling is often used for microphone speech.\\nEven an 8,000 Hz sampling rate requires 8000 amplitude measurements for each\\nsecond of speech, so it is important to store amplitude measurements efﬁciently.\\nThey are usually stored as integers, either 8 bit (values from -128–127) or 16 bit\\n(values from -32768–32767). This process of representing real-valued numbers as\\nintegers is called quantization because the difference between two integers acts as quantization\\na minimum granularity (a quantum size) and all values that are closer together than\\nthis quantum size are represented identically.\\nOnce data is quantized, it is stored in various formats. One parameter of these\\nformats is the sample rate and sample size discussed above; telephone speech is\\noften sampled at 8 kHz and stored as 8-bit samples, and microphone data is often\\nsampled at 16 kHz and stored as 16-bit samples. Another parameter is the number of\\nchannels . For stereo data or for two-party conversations, we can store both channels channel\\nin the same ﬁle or we can store them in separate ﬁles. A ﬁnal parameter is individual\\nsample storage—linearly or compressed. One common compression format used for\\ntelephone speech is µ-law (often written u-law but still pronounced mu-law). The\\nintuition of log compression algorithms like µ-law is that human hearing is more\\nsensitive at small intensities than large ones; the log represents small values with\\nmore faithfulness at the expense of more error on large values. The linear (unlogged)\\nvalues are generally referred to as linear PCM values (PCM stands for pulse code PCM\\nmodulation, but never mind that). Here’s the equation for compressing a linear PCM\\nsample value xto 8-bit µ-law, (where µ=255 for 8 bits):\\nF(x) =sgn(x)log(1+µ|x|)\\nlog(1+µ)−1≤x≤1 (H.5)\\nThere are a number of standard ﬁle formats for storing the resulting digitized wave-\\nﬁle, such as Microsoft’s .wav and Apple’s AIFF all of which have special headers;\\nsimple headerless “raw” ﬁles are also used. For example, the .wav format is a subset\\nof Microsoft’s RIFF format for multimedia ﬁles; RIFF is a general format that can\\nrepresent a series of nested chunks of data and control information. Figure H.10\\nshows a simple .wav ﬁle with a single data chunk together with its format chunk.\\nFigure H.10 Microsoft waveﬁle header format, assuming simple ﬁle with one chunk. Fol-\\nlowing this 44-byte header would be the data chunk.')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/18.pdf', 'page': 14}, page_content='the search space as directed graphs and employ methods drawn from graph theory\\nto search the space for optimal solutions. More formally, given a sentence Swe’re\\nlooking for the best dependency tree in Gs, the space of all possible trees for that\\nsentence, that maximizes some score.\\nˆT(S) =argmax\\nt∈GSScore (t,S)'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/D.pdf', 'page': 13}, page_content='D.4.1 Example: The Penn Treebank Project\\nFigure D.7 shows sentences from the Brown and ATIS portions of the Penn Tree-\\nbank.2Note the formatting differences for the part-of-speech tags; such small dif-\\nferences are common and must be dealt with in processing treebanks. The Penn\\nTreebank part-of-speech tagset was deﬁned in Chapter 8. The use of LISP-style\\nparenthesized notation for trees is extremely common and resembles the bracketed\\nnotation we saw earlier in (D.1). For those who are not familiar with it we show a\\nstandard node-and-line tree representation in Fig. D.8.\\nFigure D.9 shows a tree from the Wall Street Journal . This tree shows another\\nfeature of the Penn Treebanks: the use of traces (-NONE- nodes) to mark long- traces\\n2The Penn Treebank project released treebanks in multiple languages and in various stages; for exam-\\nple, there were Treebank I (Marcus et al., 1993), Treebank II (Marcus et al., 1994), and Treebank III\\nreleases of English treebanks. We use Treebank III for our examples.'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/18.pdf', 'page': 7}, page_content='approaches to explore the search space more fully.'), Document(metadata={'source': 1}, page_content='D.5 • G RAMMAR EQUIVALENCE AND NORMAL FORM 19\\n• Else search from right to left for the ﬁrst child which is an NN, NNP, NNPS, NX, POS,\\nor JJR.\\n• Else search from left to right for the ﬁrst child which is an NP.\\n• Else search from right to left for the ﬁrst child which is a $, ADJP, or PRN.\\n• Else search from right to left for the ﬁrst child which is a CD.\\n• Else search from right to left for the ﬁrst child which is a JJ, JJS, RB or QP.\\n• Else return the last word\\nSelected other rules from this set are shown in Fig. D.12. For example, for VP\\nrules of the form VP→Y1···Yn, the algorithm would start from the left of Y1···\\nYnlooking for the ﬁrst Yiof type TO; if no TOs are found, it would search for the\\nﬁrstYiof type VBD; if no VBDs are found, it would search for a VBN, and so on.\\nSee Collins (1999) for more details.\\nParent Direction Priority List\\nADJP Left NNS QP NN $ ADVP JJ VBN VBG ADJP JJR NP JJS DT FW RBR RBS\\nSBAR RB\\nADVP Right RB RBR RBS FW ADVP TO CD JJR JJ IN NP JJS NN\\nPRN Left\\nPRT Right RP\\nQP Left $ IN NNS NN JJ RB DT CD NCD QP JJR JJS\\nS Left TO IN VP S SBAR ADJP UCP NP\\nSBAR Left WHNP WHPP WHADVP WHADJP IN DT S SQ SINV SBAR FRAG\\nVP Left TO VBD VBN MD VBZ VB VBG VBP VP ADJP NN NNS NP\\nFigure D.12 Some head rules from Collins (1999). The head rules are also called a head percolation table .\\nD.5 Grammar Equivalence and Normal Form\\nA formal language is deﬁned as a (possibly inﬁnite) set of strings of words. This\\nsuggests that we could ask if two grammars are equivalent by asking if they gener-\\nate the same set of strings. In fact, it is possible to have two distinct context-free\\ngrammars generate the same language.\\nWe usually distinguish two kinds of grammar equivalence: weak equivalence\\nandstrong equivalence . Two grammars are strongly equivalent if they generate the\\nsame set of strings andif they assign the same phrase structure to each sentence\\n(allowing merely for renaming of the non-terminal symbols). Two grammars are\\nweakly equivalent if they generate the same set of strings but do not assign the same\\nphrase structure to each sentence.\\nIt is sometimes useful to have a normal form for grammars, in which each of normal form\\nthe productions takes a particular form. For example, a context-free grammar is in\\nChomsky normal form (CNF) (Chomsky, 1963) if it is ϵ-free and if in additionChomsky\\nnormal form\\neach production is either of the form A→B C orA→a. That is, the right-hand side\\nof each rule either has two non-terminal symbols or one terminal symbol. Chomsky\\nnormal form grammars are binary branching , that is they have binary trees (downbinary\\nbranching\\nto the prelexical nodes). We make use of this binary branching property in the CKY\\nparsing algorithm in Chapter 17.\\nAny context-free grammar can be converted into a weakly equivalent Chomsky\\nnormal form grammar. For example, a rule of the form\\nA→B C D'), Document(metadata={'source': 1}, page_content='16 CHAPTER 15 • C HATBOTS & D IALOGUE SYSTEMS\\n15.4.3 Learning to perform retrieval as part of responding\\nModern chatbots are also trained to do retrieval (calls to Google or Bing or other\\nsearch engines) as a component of generating a response. This is generally done\\nby having a sort of fake dialogue participant called something like Search Query\\nwhose utterances are passed to a search engine. The system can be encourged to do\\nsearches either by prompting or by ﬁne-tuning.\\nFor example in the Sparrow chatbot (Glaese et al., 2022), the prompt includes\\na few sample conversations that include two special users, Search Query , and\\nSearch Results :\\n...[this is preceded by other parts of the prompt]\\nUser: What color is the sky?\\nSparrow: Blue.\\nUser: Why?\\nSearch Query: why is sky blue\\nSearch Results: Page title: Sky Except for direct sunlight, most of the light in\\nthe daytime sky is caused by scattering, which is dominated by\\na small-particle limit called Rayleigh scattering. The scattering\\ndue to molecule-sized particles (as in air) is greater in the di-\\nrections both toward and away from the source of light than it\\nis in directions perpendicular to the incident path. Scattering is\\nsigniﬁcant for light at all visible wavelengths, but is stronger at\\nthe shorter (bluer) end of the visible spectrum, meaning that the\\nscattered light is bluer than its source: the Sun. The remain-\\ning direct sunlight, having lost some of its shorter-wavelength\\ncomponents, appears slightly less blue.\\nSparrow: Because of the Rayleigh scattering. It causes short waves of\\nblue light to be scattered more than the other colours in the spec-\\ntrum.\\nUser: Who was Raleigh?\\nSearch Query: who was Rayleigh\\n... ...\\nFrom these prompts, the system learns to generate texts with Search Query\\nturns for fact-based questions from the user, and these are passed to a search engine\\nto generate the Search Results turns.\\nAlternatively, systems can be ﬁnetuned to to know when to use a search en-\\ngine. For example, labelers can interact with a system, fact check each of the re-\\nsponses, and whenever the system emits an incorrect response, perform the web\\nsearch queries that the system should have used to check its answer, and then the in-\\nteration is recorded and used for ﬁne-tuning. Or labelers can look at a transcript of a\\nlanguage model carrying on a dialogue, and similarly mark every place where a fact\\nwas wrong (or out-of-date) and write the set of search queries that would have been\\nappropriate. A system is then ﬁne-tuned to generate search query turns which\\nare again passed to a search engine to generate the search responses . The set\\nof pages or snippets returned by the search engine in the search response turn are\\nthen treated as the context for generation, similarly to the retrieval-based question-\\nanswering methods of Chapter 14.'), Document(metadata={'source': 1}, page_content='12 CHAPTER 13 • M ACHINE TRANSLATION\\nAs in that case, we use teacher forcing in the decoder. Recall that in teacher forc- teacher forcing\\ning, at each time step in decoding we force the system to use the gold target token\\nfrom training as the next input xt+1, rather than allowing it to rely on the (possibly\\nerroneous) decoder output ˆ yt.\\n13.4 Decoding in MT: Beam Search\\nRecall the greedy decoding algorithm from Chapter 10: at each time step tin gen-\\neration, the output ytis chosen by computing the probability for each word in the\\nvocabulary and then choosing the highest probability word (the argmax):\\nˆwt=argmaxw∈VP(w|w<t) (13.14)\\nA problem with greedy decoding is that what looks high probability at word tmight\\nturn out to have been the wrong choice once we get to word t+1. The beam search\\nalgorithm maintains multiple choices until later when we can see which one is best.\\nIn beam search we model decoding as searching the space of possible genera-\\ntions, represented as a search tree whose branches represent actions (generating a search tree\\ntoken), and nodes represent states (having generated a particular preﬁx). We search\\nfor the best action sequence, i.e., the string with the highest probability.\\nAn illustration of the problem\\nFig. 13.7 shows a made-up example. The most probable sequence is ok ok EOS (its\\nprobability is .4×.7×1.0). But greedy search doesn’t ﬁnd it, incorrectly choosing\\nyesas the ﬁrst word since it has the highest local probability (0.5).\\nstartokyesEOSokyesEOSokyesEOSEOSEOSEOSEOSt2t3p(t1|start)\\nt1p(t2| t1)p(t3| t1,t2)\\n.1.5.4.3.4.3.1.2.71.01.01.01.0\\nFigure 13.7 A search tree for generating the target string T=t1,t2,...from vocabulary\\nV={yes,ok,<s>}, showing the probability of generating each token from that state. Greedy\\nsearch chooses yesfollowed by yes, instead of the globally most probable sequence ok ok .\\nRecall from Chapter 8 that for part-of-speech tagging we used dynamic pro-\\ngramming search (the Viterbi algorithm) to address this problem. Unfortunately,\\ndynamic programming is not applicable to generation problems with long-distance\\ndependencies between the output decisions. The only method guaranteed to ﬁnd the\\nbest solution is exhaustive search: computing the probability of every one of the VT\\npossible sentences (for some length value T) which is obviously too slow.')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/3.pdf', 'page': 18}, page_content='COCA is a balanced corpus, meaning that it has roughly equal numbers of words\\nfrom different genres: web, newspapers, spoken conversation transcripts, ﬁction,\\nand so on, drawn from the period 1990-2019, and has the context of each n-gram as\\nwell as labels for genre and provenance.\\nSome example 4-grams from the Google Web corpus:\\n4-gram Count\\nserve as the incoming 92\\nserve as the incubator 99\\nserve as the independent 794\\nserve as the index 223\\nserve as the indication 72\\nserve as the indicator 120\\nserve as the indicators 45\\nEfﬁciency considerations are important when building language models that use\\nsuch large sets of n-grams. Rather than store each word as a string, it is generally\\nrepresented in memory as a 64-bit hash number, with the words themselves stored\\non disk. Probabilities are generally quantized using only 4-8 bits (instead of 8-byte\\nﬂoats), and n-grams are stored in reverse tries.\\nAn n-gram language model can also be shrunk by pruning, for example only'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/13.pdf', 'page': 21}, page_content='garian gender-neutral ˝o is a nurse is translated with she, but gender-neutral ˝o is a\\nCEO is translated with he. Prates et al. (2019) ﬁnd that these stereotypes can’t com-\\npletely be accounted for by gender bias in US labor statistics, because the biases are'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/19.pdf', 'page': 4}, page_content='George Marshall, Secretary of State of the United States\\nPER (named|appointed|chose|etc.) PER Prep? POSITION\\nTruman appointed Marshall Secretary of State\\nPER [be]? (named|appointed|etc.) Prep? ORG POSITION\\nGeorge Marshall was named US Secretary of State\\nHand-built patterns have the advantage of high-precision and they can be tailored\\nto speciﬁc domains. On the other hand, they are often low-recall, and it’s a lot of\\nwork to create them for all possible patterns.\\n19.2.2 Relation Extraction via Supervised Learning\\nSupervised machine learning approaches to relation extraction follow a scheme that\\nshould be familiar by now. A ﬁxed set of relations and entities is chosen, a training\\ncorpus is hand-annotated with the relations and entities, and the annotated texts are\\nthen used to train classiﬁers to annotate an unseen test set.\\nThe most straightforward approach, illustrated in Fig. 19.5 is: (1) Find pairs of\\nnamed entities (usually in the same sentence). (2): Apply a relation-classiﬁcation'), Document(metadata={'source': 1}, page_content='22.1 • C OREFERENCE PHENOMENA : LINGUISTIC BACKGROUND 7\\nAppositives: An appositional structure is a noun phrase that appears next to a\\nhead noun phrase, describing the head. In English they often appear in commas, like\\n“a unit of UAL” appearing in apposition to the NP United , orCFO of Megabucks\\nBanking in apposition to Victoria Chen .\\n(22.23) Victoria Chen, CFO of Megabucks Banking, saw ...\\n(22.24) United, a unit of UAL, matched the fares.\\nAppositional NPs are not referring expressions, instead functioning as a kind of\\nsupplementary parenthetical description of the head NP. Nonetheless, sometimes it\\nis useful to link these phrases to an entity they describe, and so some datasets like\\nOntoNotes mark appositional relationships.\\nPredicative and Prenominal NPs: Predicative or attributive NPs describe prop-\\nerties of the head noun. In United is a unit of UAL , the NP a unit of UAL describes\\na property of United, rather than referring to a distinct entity. Thus they are not\\nmarked as mentions in coreference tasks; in our example the NPs $2.3 million and\\nthe company’s president , are attributive, describing properties of her pay andthe\\n38-year-old ; Example (22.27) shows a Chinese example in which the predicate NP\\n(中国最大的城市; China’s biggest city ) is not a mention.\\n(22.25) her pay jumped to $2.3 million\\n(22.26) the 38-year-old became the company’s president\\n(22.27)上海是[中国最大的城市] [Shanghai is China’s biggest city ]\\nExpletives: Many uses of pronouns like itin English and corresponding pronouns\\nin other languages are not referential. Such expletive orpleonastic cases include expletive\\nit is raining , in idioms like hit it off , or in particular syntactic situations like clefts clefts\\n(22.28a) or extraposition (22.28b):\\n(22.28) a. Itwas Emma Goldman who founded Mother Earth\\nb.Itsurprised me that there was a herring hanging on her wall.\\nGenerics: Another kind of expression that does not refer back to an entity explic-\\nitly evoked in the text is generic reference. Consider (22.29).\\n(22.29) I love mangos. They are very tasty.\\nHere, they refers, not to a particular mango or set of mangos, but instead to the class\\nof mangos in general. The pronoun youcan also be used generically:\\n(22.30) In July in San Francisco youhave to wear a jacket.\\n22.1.4 Linguistic Properties of the Coreference Relation\\nNow that we have seen the linguistic properties of individual referring expressions\\nwe turn to properties of the antecedent/anaphor pair. Understanding these properties\\nis helpful both in designing novel features and performing error analyses.\\nNumber Agreement: Referring expressions and their referents must generally\\nagree in number; English she/her/he/him/his/it are singular, we/us/they/them are plu-\\nral, and youis unspeciﬁed for number. So a plural antecedent like the chefs cannot\\ngenerally corefer with a singular anaphor like she. However, algorithms cannot\\nenforce number agreement too strictly. First, semantically plural entities can be re-\\nferred to by either itorthey:\\n(22.31) IBM announced a new machine translation product yesterday. They have\\nbeen working on it for 20 years.'), Document(metadata={'source': 1}, page_content='22.3 • M ENTION DETECTION 11\\nmillion, as the 38-year-old also became the company’s president. It is\\nwidely known that she came to Megabucks from rival Lotsabucks.\\nmight result in the following list of 13 potential mentions:\\nVictoria Chen $2.3 million she\\nCFO of Megabucks Banking the 38-year-old Megabucks\\nMegabucks Banking the company Lotsabucks\\nher the company’s president\\nher pay It\\nMore recent mention detection systems are even more generous; the span-based\\nalgorithm we will describe in Section 22.6 ﬁrst extracts literally all n-gram spans\\nof words up to N=10. Of course recall from Section 22.1.3 that many NPs—and\\nthe overwhelming majority of random n-gram spans—are not referring expressions.\\nTherefore all such mention detection systems need to eventually ﬁlter out pleonas-\\ntic/expletive pronouns like Itabove, appositives like CFO of Megabucks Banking\\nInc, or predicate nominals like the company’s president or$2.3 million .\\nSome of this ﬁltering can be done by rules. Early rule-based systems designed\\nregular expressions to deal with pleonastic it, like the following rules from Lappin\\nand Leass (1994) that use dictionaries of cognitive verbs (e.g., believe ,know ,antic-\\nipate ) to capture pleonastic itin “It is thought that ketchup...”, or modal adjectives\\n(e.g., necessary ,possible ,certain ,important ), for, e.g., “It is likely that I...”. Such\\nrules are sometimes used as part of modern systems:\\nIt is Modaladjective that S\\nIt is Modaladjective (for NP) to VP\\nIt is Cogv-ed that S\\nIt seems/appears/means/follows (that) S\\nMention-detection rules are sometimes designed speciﬁcally for particular eval-\\nuation campaigns. For OntoNotes, for example, mentions are not embedded within\\nlarger mentions, and while numeric quantities are annotated, they are rarely coref-\\nerential. Thus for OntoNotes tasks like CoNLL 2012 (Pradhan et al., 2012a), a\\ncommon ﬁrst pass rule-based mention detection algorithm (Lee et al., 2013) is:\\n1.Take all NPs, possessive pronouns, and named entities.\\n2.Remove numeric quantities (100 dollars, 8%), mentions embedded in\\nlarger mentions, adjectival forms of nations, and stop words (like there ).\\n3.Remove pleonastic itbased on regular expression patterns.\\nRule-based systems, however, are generally insufﬁcient to deal with mention-\\ndetection, and so modern systems incorporate some sort of learned mention detec-\\ntion component, such as a referentiality classiﬁer, an anaphoricity classiﬁer —\\ndetecting whether an NP is an anaphor—or a discourse-new classiﬁer— detecting\\nwhether a mention is discourse-new and a potential antecedent for a future anaphor.\\nAnanaphoricity detector , for example, can draw its positive training examplesanaphoricity\\ndetector\\nfrom any span that is labeled as an anaphoric referring expression in hand-labeled\\ndatasets like OntoNotes, ARRAU , or AnCora. Any other NP or named entity can be\\nmarked as a negative training example. Anaphoricity classiﬁers use features of the\\ncandidate mention such as its head word, surrounding words, deﬁniteness, animacy,\\nlength, position in the sentence/discourse, many of which were ﬁrst proposed in\\nearly work by Ng and Cardie (2002a); see Section 22.5 for more on features.'), Document(metadata={'source': 1}, page_content='10 CHAPTER 22 • C OREFERENCE RESOLUTION AND ENTITY LINKING\\nExactly what counts as a mention and what links are annotated differs from task\\nto task and dataset to dataset. For example some coreference datasets do not label\\nsingletons, making the task much simpler. Resolvers can achieve much higher scores\\non corpora without singletons, since singletons constitute the majority of mentions in\\nrunning text, and they are often hard to distinguish from non-referential NPs. Some\\ntasks use gold mention-detection (i.e. the system is given human-labeled mention\\nboundaries and the task is just to cluster these gold mentions), which eliminates the\\nneed to detect and segment mentions from running text.\\nCoreference is usually evaluated by the CoNLL F1 score, which combines three\\nmetrics: MUC, B3, and CEAF e; Section 22.8 gives the details.\\nLet’s mention a few characteristics of one popular coreference dataset, OntoNotes\\n(Pradhan et al. 2007b, Pradhan et al. 2007a), and the CoNLL 2012 Shared Task\\nbased on it (Pradhan et al., 2012a). OntoNotes contains hand-annotated Chinese\\nand English coreference datasets of roughly one million words each, consisting of\\nnewswire, magazine articles, broadcast news, broadcast conversations, web data and\\nconversational speech data, as well as about 300,000 words of annotated Arabic\\nnewswire. The most important distinguishing characteristic of OntoNotes is that\\nit does not label singletons, simplifying the coreference task, since singletons rep-\\nresent 60%-70% of all entities. In other ways, it is similar to other coreference\\ndatasets. Referring expression NPs that are coreferent are marked as mentions, but\\ngenerics and pleonastic pronouns are not marked. Appositive clauses are not marked\\nas separate mentions, but they are included in the mention. Thus in the NP, “Richard\\nGodown, president of the Industrial Biotechnology Association” the mention is the\\nentire phrase. Prenominal modiﬁers are annotated as separate entities only if they\\nare proper nouns. Thus wheat is not an entity in wheat ﬁelds , but UNis an entity in\\nUN policy (but not adjectives like American inAmerican policy ).\\nA number of corpora mark richer discourse phenomena. The ISNotes corpus\\nannotates a portion of OntoNotes for information status, include bridging examples\\n(Hou et al., 2018). The LitBank coreference corpus (Bamman et al., 2020) contains\\ncoreference annotations for 210,532 tokens from 100 different literary novels, in-\\ncluding singletons and quantiﬁed and negated noun phrases. The AnCora-CO coref-\\nerence corpus (Recasens and Mart ´ı, 2010) contains 400,000 words each of Spanish\\n(AnCora-CO-Es) and Catalan (AnCora-CO-Ca) news data, and includes labels for\\ncomplex phenomena like discourse deixis in both languages. The ARRAU corpus\\n(Uryupina et al., 2020) contains 350,000 words of English marking all NPs, which\\nmeans singleton clusters are available. ARRAU includes diverse genres like dialog\\n(the TRAINS data) and ﬁction (the Pear Stories), and has labels for bridging refer-\\nences, discourse deixis, generics, and ambiguous anaphoric relations.\\n22.3 Mention Detection\\nThe ﬁrst stage of coreference is mention detection : ﬁnding the spans of text thatmention\\ndetection\\nconstitute each mention. Mention detection algorithms are usually very liberal in\\nproposing candidate mentions (i.e., emphasizing recall), and only ﬁltering later. For\\nexample many systems run parsers and named entity taggers on the text and extract\\nevery span that is either an NP, apossessive pronoun , or a named entity .\\nDoing so from our sample text repeated in (22.44):\\n(22.44) Victoria Chen, CFO of Megabucks Banking, saw her pay jump to $2.3')]\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "query = \"ٌWhat is self-attention?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "query = \"ٌWhat is binary search tree?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "query = \"ٌWho is the president of Bolivia?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "03BPABObAbY9"
      },
      "outputs": [],
      "source": [
        "weight_bm25 = 0.2\n",
        "weight_faiss = 0.8\n",
        "retriever_chain.weights = [weight_bm25, weight_faiss]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvdJoG51AeGg",
        "outputId": "6a251011-9ba1-4f27-b1d6-ae9e6e3af32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 4}, page_content='10.1 • T HETRANSFORMER : A S ELF-ATTENTION NETWORK 5\\nSelf-AttentionLayerx1a1\\nx2a2a3a4a5\\nx3x4x5\\nFigure 10.2 Information ﬂow in a causal (or masked) self-attention model. In processing\\neach element of the sequence, the model attends to all the inputs up to, and including, the\\ncurrent one. Unlike RNNs, the computations at each time step are independent of all the\\nother steps and therefore can be performed in parallel.\\n10.1.3 Self-attention more formally\\nWe’ve given the intuition of self-attention (as a way to compute representations of a\\nword at a given layer by integrating information from words at the previous layer)\\nand we’ve deﬁned context as all the prior words in the input. Let’s now introduce\\nthe self-attention computation itself.\\nThe core intuition of attention is the idea of comparing an item of interest to a\\ncollection of other items in a way that reveals their relevance in the current context.\\nIn the case of self-attention for language, the set of comparisons are to other words'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='Chapter 26.)\\n10.1.2 Causal or backward-looking self-attention\\nThe concept of context can be used in two ways in self-attention. In causal, or\\nbackward looking self-attention, the context is any of the prior words. In general\\nbidirectional self-attention, the context can include future words. In this chapter\\nwe focus on causal, backward looking self-attention; we’ll introduce bidirectional\\nself-attention in Chapter 11.\\nFig. 10.2 thus illustrates the ﬂow of information in a single causal, or backward\\nlooking, self-attention layer. As with the overall transformer, a self-attention layer\\nmaps input sequences (x1,...,xn)to output sequences of the same length (a1,...,an).\\nWhen processing each item in the input, the model has access to all of the inputs\\nup to and including the one under consideration, but no access to information about\\ninputs beyond the current one. In addition, the computation performed for each item\\nis independent of all the other computations. The ﬁrst point ensures that we can use'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/10.pdf', 'page': 3}, page_content='representation for animal . Figure simpliﬁed from (Uszkoreit, 2017).\\nFig. 10.1 shows an schematic example simpliﬁed from a real transformer (Uszko-\\nreit, 2017). Here we want to compute a contextual representation for the word it, at\\nlayer 6 of the transformer, and we’d like that representation to draw on the represen-\\ntations of all the prior words, from layer 5. The ﬁgure uses color to represent the\\nattention distribution over the contextual words: the word animal has a high atten-\\ntion weight, meaning that as we are computing the representation for it, we will draw\\nmost heavily on the representation for animal . This will be useful for the model to\\nbuild a representation that has the correct meaning for it, which indeed is corefer-\\nent here with the word animal . (We say that a pronoun like itis coreferent with a\\nnoun like animal if they both refer to the same thing; we’ll return to coreference in\\nChapter 26.)\\n10.1.2 Causal or backward-looking self-attention'), Document(metadata={'source': 1}, page_content='Observer evaluation: acute-evalAnnotators look at two conversations (A + B) and decide which is better:Engagingness: Who would you prefer to talk to for a long conversation? Interestingness: If you had to say one of these speakers is interesting and one is boring, who would you say is more interesting? Humanness: Which speaker sounds more human? Knowledgeable: If you had to say that one speaker is more knowledgeable and one is more ignorant, who is more knowledgeable? Li, M., Weston, J., and Roller, S. (2019). Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. NeurIPS19 Workshop on Conversational AI. '), Document(metadata={'source': 1}, page_content=\"Classifying sentiment for input x5.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions325.1•CLASSIFICATION:THE SIGMOID5 It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2A sample mini test document showing the extracted features in the vectorx.Given these 6 features and the input reviewx,P(+|x)andP(\\x00|x)can be com-puted using Eq.5.5:p(+|x)=P(Y=1|x)=s(w·x+b)=s([2.5,\\x005.0,\\x001.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)=s(.833)=0.70(5.6)p(\\x00|x)=P(Y=0|x)=1\\x00s(w·x+b)=0.30Logistic regression is commonly applied to all sorts of NLP tasks, and any propertyof the input can be a feature. Consider the task ofperiod disambiguation: decidingif a period is the end of a sentence or part of a word, by classifying each periodinto one of two classes EOS (end-of-sentence) and not-EOS. We might use featureslikex1below expressing that the current word is lower case and the class is EOS(perhaps with a positive weight), or that the current word is in our abbreviationsdictionary (“Prof.”) and the class is EOS (perhaps with a negative weight). A featurecan also express a quite complex combination of properties. For example a periodfollowing an upper case word is likely to be an EOS, but if the word itself isSt.andthe previous word is capitalized, then the period is likely part of a shortening of thewordstreet.x1=⇢1 if “Case(wi)=Lower”0 otherwisex2=⇢1 if “wi2AcronymDict”0 otherwisex3=⇢1 if “wi=St. &Case(wi\\x001)=Cap”0 otherwiseDesigning features:Features are generally designed by examining the trainingset with an eye to linguistic intuitions and the linguistic literature on the domain. Acareful error analysis on the training set or devset of an early version of a systemoften provides insights into features.For some tasks it is especially helpful to build complex features that are combi-nations of more primitive features. We saw such a feature for period disambiguationabove, where a period on the wordSt.was less likely to be the end of the sentenceif the previous word was capitalized. For logistic regression and naive Bayes thesecombination features orfeature interactionshave to be designed by hand.featureinteractions\"), Document(metadata={'source': 1}, page_content='H.4 • A COUSTIC PHONETICS AND SIGNALS 11\\npart of the wave and one measuring the negative part. More than two samples per\\ncycle increases the amplitude accuracy, but fewer than two samples causes the fre-\\nquency of the wave to be completely missed. Thus, the maximum frequency wave\\nthat can be measured is one whose frequency is half the sample rate (since every\\ncycle needs two samples). This maximum frequency for a given sampling rate is\\ncalled the Nyquist frequency . Most information in human speech is in frequenciesNyquist\\nfrequency\\nbelow 10,000 Hz; thus, a 20,000 Hz sampling rate would be necessary for com-\\nplete accuracy. But telephone speech is ﬁltered by the switching network, and only\\nfrequencies less than 4,000 Hz are transmitted by telephones. Thus, an 8,000 Hz\\nsampling rate is sufﬁcient for telephone-bandwidth speech like the Switchboard\\ncorpus, while 16,000 Hz sampling is often used for microphone speech.\\nEven an 8,000 Hz sampling rate requires 8000 amplitude measurements for each\\nsecond of speech, so it is important to store amplitude measurements efﬁciently.\\nThey are usually stored as integers, either 8 bit (values from -128–127) or 16 bit\\n(values from -32768–32767). This process of representing real-valued numbers as\\nintegers is called quantization because the difference between two integers acts as quantization\\na minimum granularity (a quantum size) and all values that are closer together than\\nthis quantum size are represented identically.\\nOnce data is quantized, it is stored in various formats. One parameter of these\\nformats is the sample rate and sample size discussed above; telephone speech is\\noften sampled at 8 kHz and stored as 8-bit samples, and microphone data is often\\nsampled at 16 kHz and stored as 16-bit samples. Another parameter is the number of\\nchannels . For stereo data or for two-party conversations, we can store both channels channel\\nin the same ﬁle or we can store them in separate ﬁles. A ﬁnal parameter is individual\\nsample storage—linearly or compressed. One common compression format used for\\ntelephone speech is µ-law (often written u-law but still pronounced mu-law). The\\nintuition of log compression algorithms like µ-law is that human hearing is more\\nsensitive at small intensities than large ones; the log represents small values with\\nmore faithfulness at the expense of more error on large values. The linear (unlogged)\\nvalues are generally referred to as linear PCM values (PCM stands for pulse code PCM\\nmodulation, but never mind that). Here’s the equation for compressing a linear PCM\\nsample value xto 8-bit µ-law, (where µ=255 for 8 bits):\\nF(x) =sgn(x)log(1+µ|x|)\\nlog(1+µ)−1≤x≤1 (H.5)\\nThere are a number of standard ﬁle formats for storing the resulting digitized wave-\\nﬁle, such as Microsoft’s .wav and Apple’s AIFF all of which have special headers;\\nsimple headerless “raw” ﬁles are also used. For example, the .wav format is a subset\\nof Microsoft’s RIFF format for multimedia ﬁles; RIFF is a general format that can\\nrepresent a series of nested chunks of data and control information. Figure H.10\\nshows a simple .wav ﬁle with a single data chunk together with its format chunk.\\nFigure H.10 Microsoft waveﬁle header format, assuming simple ﬁle with one chunk. Fol-\\nlowing this 44-byte header would be the data chunk.')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/18.pdf', 'page': 14}, page_content='the search space as directed graphs and employ methods drawn from graph theory\\nto search the space for optimal solutions. More formally, given a sentence Swe’re\\nlooking for the best dependency tree in Gs, the space of all possible trees for that\\nsentence, that maximizes some score.\\nˆT(S) =argmax\\nt∈GSScore (t,S)'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/D.pdf', 'page': 13}, page_content='D.4.1 Example: The Penn Treebank Project\\nFigure D.7 shows sentences from the Brown and ATIS portions of the Penn Tree-\\nbank.2Note the formatting differences for the part-of-speech tags; such small dif-\\nferences are common and must be dealt with in processing treebanks. The Penn\\nTreebank part-of-speech tagset was deﬁned in Chapter 8. The use of LISP-style\\nparenthesized notation for trees is extremely common and resembles the bracketed\\nnotation we saw earlier in (D.1). For those who are not familiar with it we show a\\nstandard node-and-line tree representation in Fig. D.8.\\nFigure D.9 shows a tree from the Wall Street Journal . This tree shows another\\nfeature of the Penn Treebanks: the use of traces (-NONE- nodes) to mark long- traces\\n2The Penn Treebank project released treebanks in multiple languages and in various stages; for exam-\\nple, there were Treebank I (Marcus et al., 1993), Treebank II (Marcus et al., 1994), and Treebank III\\nreleases of English treebanks. We use Treebank III for our examples.'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/18.pdf', 'page': 7}, page_content='approaches to explore the search space more fully.'), Document(metadata={'source': 1}, page_content='D.5 • G RAMMAR EQUIVALENCE AND NORMAL FORM 19\\n• Else search from right to left for the ﬁrst child which is an NN, NNP, NNPS, NX, POS,\\nor JJR.\\n• Else search from left to right for the ﬁrst child which is an NP.\\n• Else search from right to left for the ﬁrst child which is a $, ADJP, or PRN.\\n• Else search from right to left for the ﬁrst child which is a CD.\\n• Else search from right to left for the ﬁrst child which is a JJ, JJS, RB or QP.\\n• Else return the last word\\nSelected other rules from this set are shown in Fig. D.12. For example, for VP\\nrules of the form VP→Y1···Yn, the algorithm would start from the left of Y1···\\nYnlooking for the ﬁrst Yiof type TO; if no TOs are found, it would search for the\\nﬁrstYiof type VBD; if no VBDs are found, it would search for a VBN, and so on.\\nSee Collins (1999) for more details.\\nParent Direction Priority List\\nADJP Left NNS QP NN $ ADVP JJ VBN VBG ADJP JJR NP JJS DT FW RBR RBS\\nSBAR RB\\nADVP Right RB RBR RBS FW ADVP TO CD JJR JJ IN NP JJS NN\\nPRN Left\\nPRT Right RP\\nQP Left $ IN NNS NN JJ RB DT CD NCD QP JJR JJS\\nS Left TO IN VP S SBAR ADJP UCP NP\\nSBAR Left WHNP WHPP WHADVP WHADJP IN DT S SQ SINV SBAR FRAG\\nVP Left TO VBD VBN MD VBZ VB VBG VBP VP ADJP NN NNS NP\\nFigure D.12 Some head rules from Collins (1999). The head rules are also called a head percolation table .\\nD.5 Grammar Equivalence and Normal Form\\nA formal language is deﬁned as a (possibly inﬁnite) set of strings of words. This\\nsuggests that we could ask if two grammars are equivalent by asking if they gener-\\nate the same set of strings. In fact, it is possible to have two distinct context-free\\ngrammars generate the same language.\\nWe usually distinguish two kinds of grammar equivalence: weak equivalence\\nandstrong equivalence . Two grammars are strongly equivalent if they generate the\\nsame set of strings andif they assign the same phrase structure to each sentence\\n(allowing merely for renaming of the non-terminal symbols). Two grammars are\\nweakly equivalent if they generate the same set of strings but do not assign the same\\nphrase structure to each sentence.\\nIt is sometimes useful to have a normal form for grammars, in which each of normal form\\nthe productions takes a particular form. For example, a context-free grammar is in\\nChomsky normal form (CNF) (Chomsky, 1963) if it is ϵ-free and if in additionChomsky\\nnormal form\\neach production is either of the form A→B C orA→a. That is, the right-hand side\\nof each rule either has two non-terminal symbols or one terminal symbol. Chomsky\\nnormal form grammars are binary branching , that is they have binary trees (downbinary\\nbranching\\nto the prelexical nodes). We make use of this binary branching property in the CKY\\nparsing algorithm in Chapter 17.\\nAny context-free grammar can be converted into a weakly equivalent Chomsky\\nnormal form grammar. For example, a rule of the form\\nA→B C D'), Document(metadata={'source': 1}, page_content='16 CHAPTER 15 • C HATBOTS & D IALOGUE SYSTEMS\\n15.4.3 Learning to perform retrieval as part of responding\\nModern chatbots are also trained to do retrieval (calls to Google or Bing or other\\nsearch engines) as a component of generating a response. This is generally done\\nby having a sort of fake dialogue participant called something like Search Query\\nwhose utterances are passed to a search engine. The system can be encourged to do\\nsearches either by prompting or by ﬁne-tuning.\\nFor example in the Sparrow chatbot (Glaese et al., 2022), the prompt includes\\na few sample conversations that include two special users, Search Query , and\\nSearch Results :\\n...[this is preceded by other parts of the prompt]\\nUser: What color is the sky?\\nSparrow: Blue.\\nUser: Why?\\nSearch Query: why is sky blue\\nSearch Results: Page title: Sky Except for direct sunlight, most of the light in\\nthe daytime sky is caused by scattering, which is dominated by\\na small-particle limit called Rayleigh scattering. The scattering\\ndue to molecule-sized particles (as in air) is greater in the di-\\nrections both toward and away from the source of light than it\\nis in directions perpendicular to the incident path. Scattering is\\nsigniﬁcant for light at all visible wavelengths, but is stronger at\\nthe shorter (bluer) end of the visible spectrum, meaning that the\\nscattered light is bluer than its source: the Sun. The remain-\\ning direct sunlight, having lost some of its shorter-wavelength\\ncomponents, appears slightly less blue.\\nSparrow: Because of the Rayleigh scattering. It causes short waves of\\nblue light to be scattered more than the other colours in the spec-\\ntrum.\\nUser: Who was Raleigh?\\nSearch Query: who was Rayleigh\\n... ...\\nFrom these prompts, the system learns to generate texts with Search Query\\nturns for fact-based questions from the user, and these are passed to a search engine\\nto generate the Search Results turns.\\nAlternatively, systems can be ﬁnetuned to to know when to use a search en-\\ngine. For example, labelers can interact with a system, fact check each of the re-\\nsponses, and whenever the system emits an incorrect response, perform the web\\nsearch queries that the system should have used to check its answer, and then the in-\\nteration is recorded and used for ﬁne-tuning. Or labelers can look at a transcript of a\\nlanguage model carrying on a dialogue, and similarly mark every place where a fact\\nwas wrong (or out-of-date) and write the set of search queries that would have been\\nappropriate. A system is then ﬁne-tuned to generate search query turns which\\nare again passed to a search engine to generate the search responses . The set\\nof pages or snippets returned by the search engine in the search response turn are\\nthen treated as the context for generation, similarly to the retrieval-based question-\\nanswering methods of Chapter 14.'), Document(metadata={'source': 1}, page_content='12 CHAPTER 13 • M ACHINE TRANSLATION\\nAs in that case, we use teacher forcing in the decoder. Recall that in teacher forc- teacher forcing\\ning, at each time step in decoding we force the system to use the gold target token\\nfrom training as the next input xt+1, rather than allowing it to rely on the (possibly\\nerroneous) decoder output ˆ yt.\\n13.4 Decoding in MT: Beam Search\\nRecall the greedy decoding algorithm from Chapter 10: at each time step tin gen-\\neration, the output ytis chosen by computing the probability for each word in the\\nvocabulary and then choosing the highest probability word (the argmax):\\nˆwt=argmaxw∈VP(w|w<t) (13.14)\\nA problem with greedy decoding is that what looks high probability at word tmight\\nturn out to have been the wrong choice once we get to word t+1. The beam search\\nalgorithm maintains multiple choices until later when we can see which one is best.\\nIn beam search we model decoding as searching the space of possible genera-\\ntions, represented as a search tree whose branches represent actions (generating a search tree\\ntoken), and nodes represent states (having generated a particular preﬁx). We search\\nfor the best action sequence, i.e., the string with the highest probability.\\nAn illustration of the problem\\nFig. 13.7 shows a made-up example. The most probable sequence is ok ok EOS (its\\nprobability is .4×.7×1.0). But greedy search doesn’t ﬁnd it, incorrectly choosing\\nyesas the ﬁrst word since it has the highest local probability (0.5).\\nstartokyesEOSokyesEOSokyesEOSEOSEOSEOSEOSt2t3p(t1|start)\\nt1p(t2| t1)p(t3| t1,t2)\\n.1.5.4.3.4.3.1.2.71.01.01.01.0\\nFigure 13.7 A search tree for generating the target string T=t1,t2,...from vocabulary\\nV={yes,ok,<s>}, showing the probability of generating each token from that state. Greedy\\nsearch chooses yesfollowed by yes, instead of the globally most probable sequence ok ok .\\nRecall from Chapter 8 that for part-of-speech tagging we used dynamic pro-\\ngramming search (the Viterbi algorithm) to address this problem. Unfortunately,\\ndynamic programming is not applicable to generation problems with long-distance\\ndependencies between the output decisions. The only method guaranteed to ﬁnd the\\nbest solution is exhaustive search: computing the probability of every one of the VT\\npossible sentences (for some length value T) which is obviously too slow.')]\n",
            "Retrieved docs: [Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/3.pdf', 'page': 18}, page_content='COCA is a balanced corpus, meaning that it has roughly equal numbers of words\\nfrom different genres: web, newspapers, spoken conversation transcripts, ﬁction,\\nand so on, drawn from the period 1990-2019, and has the context of each n-gram as\\nwell as labels for genre and provenance.\\nSome example 4-grams from the Google Web corpus:\\n4-gram Count\\nserve as the incoming 92\\nserve as the incubator 99\\nserve as the independent 794\\nserve as the index 223\\nserve as the indication 72\\nserve as the indicator 120\\nserve as the indicators 45\\nEfﬁciency considerations are important when building language models that use\\nsuch large sets of n-grams. Rather than store each word as a string, it is generally\\nrepresented in memory as a 64-bit hash number, with the words themselves stored\\non disk. Probabilities are generally quantized using only 4-8 bits (instead of 8-byte\\nﬂoats), and n-grams are stored in reverse tries.\\nAn n-gram language model can also be shrunk by pruning, for example only'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/13.pdf', 'page': 21}, page_content='garian gender-neutral ˝o is a nurse is translated with she, but gender-neutral ˝o is a\\nCEO is translated with he. Prates et al. (2019) ﬁnd that these stereotypes can’t com-\\npletely be accounted for by gender bias in US labor statistics, because the biases are'), Document(metadata={'source': 'https://stanford.edu/~jurafsky/slp3/19.pdf', 'page': 4}, page_content='George Marshall, Secretary of State of the United States\\nPER (named|appointed|chose|etc.) PER Prep? POSITION\\nTruman appointed Marshall Secretary of State\\nPER [be]? (named|appointed|etc.) Prep? ORG POSITION\\nGeorge Marshall was named US Secretary of State\\nHand-built patterns have the advantage of high-precision and they can be tailored\\nto speciﬁc domains. On the other hand, they are often low-recall, and it’s a lot of\\nwork to create them for all possible patterns.\\n19.2.2 Relation Extraction via Supervised Learning\\nSupervised machine learning approaches to relation extraction follow a scheme that\\nshould be familiar by now. A ﬁxed set of relations and entities is chosen, a training\\ncorpus is hand-annotated with the relations and entities, and the annotated texts are\\nthen used to train classiﬁers to annotate an unseen test set.\\nThe most straightforward approach, illustrated in Fig. 19.5 is: (1) Find pairs of\\nnamed entities (usually in the same sentence). (2): Apply a relation-classiﬁcation'), Document(metadata={'source': 1}, page_content='22.1 • C OREFERENCE PHENOMENA : LINGUISTIC BACKGROUND 7\\nAppositives: An appositional structure is a noun phrase that appears next to a\\nhead noun phrase, describing the head. In English they often appear in commas, like\\n“a unit of UAL” appearing in apposition to the NP United , orCFO of Megabucks\\nBanking in apposition to Victoria Chen .\\n(22.23) Victoria Chen, CFO of Megabucks Banking, saw ...\\n(22.24) United, a unit of UAL, matched the fares.\\nAppositional NPs are not referring expressions, instead functioning as a kind of\\nsupplementary parenthetical description of the head NP. Nonetheless, sometimes it\\nis useful to link these phrases to an entity they describe, and so some datasets like\\nOntoNotes mark appositional relationships.\\nPredicative and Prenominal NPs: Predicative or attributive NPs describe prop-\\nerties of the head noun. In United is a unit of UAL , the NP a unit of UAL describes\\na property of United, rather than referring to a distinct entity. Thus they are not\\nmarked as mentions in coreference tasks; in our example the NPs $2.3 million and\\nthe company’s president , are attributive, describing properties of her pay andthe\\n38-year-old ; Example (22.27) shows a Chinese example in which the predicate NP\\n(中国最大的城市; China’s biggest city ) is not a mention.\\n(22.25) her pay jumped to $2.3 million\\n(22.26) the 38-year-old became the company’s president\\n(22.27)上海是[中国最大的城市] [Shanghai is China’s biggest city ]\\nExpletives: Many uses of pronouns like itin English and corresponding pronouns\\nin other languages are not referential. Such expletive orpleonastic cases include expletive\\nit is raining , in idioms like hit it off , or in particular syntactic situations like clefts clefts\\n(22.28a) or extraposition (22.28b):\\n(22.28) a. Itwas Emma Goldman who founded Mother Earth\\nb.Itsurprised me that there was a herring hanging on her wall.\\nGenerics: Another kind of expression that does not refer back to an entity explic-\\nitly evoked in the text is generic reference. Consider (22.29).\\n(22.29) I love mangos. They are very tasty.\\nHere, they refers, not to a particular mango or set of mangos, but instead to the class\\nof mangos in general. The pronoun youcan also be used generically:\\n(22.30) In July in San Francisco youhave to wear a jacket.\\n22.1.4 Linguistic Properties of the Coreference Relation\\nNow that we have seen the linguistic properties of individual referring expressions\\nwe turn to properties of the antecedent/anaphor pair. Understanding these properties\\nis helpful both in designing novel features and performing error analyses.\\nNumber Agreement: Referring expressions and their referents must generally\\nagree in number; English she/her/he/him/his/it are singular, we/us/they/them are plu-\\nral, and youis unspeciﬁed for number. So a plural antecedent like the chefs cannot\\ngenerally corefer with a singular anaphor like she. However, algorithms cannot\\nenforce number agreement too strictly. First, semantically plural entities can be re-\\nferred to by either itorthey:\\n(22.31) IBM announced a new machine translation product yesterday. They have\\nbeen working on it for 20 years.'), Document(metadata={'source': 1}, page_content='22.3 • M ENTION DETECTION 11\\nmillion, as the 38-year-old also became the company’s president. It is\\nwidely known that she came to Megabucks from rival Lotsabucks.\\nmight result in the following list of 13 potential mentions:\\nVictoria Chen $2.3 million she\\nCFO of Megabucks Banking the 38-year-old Megabucks\\nMegabucks Banking the company Lotsabucks\\nher the company’s president\\nher pay It\\nMore recent mention detection systems are even more generous; the span-based\\nalgorithm we will describe in Section 22.6 ﬁrst extracts literally all n-gram spans\\nof words up to N=10. Of course recall from Section 22.1.3 that many NPs—and\\nthe overwhelming majority of random n-gram spans—are not referring expressions.\\nTherefore all such mention detection systems need to eventually ﬁlter out pleonas-\\ntic/expletive pronouns like Itabove, appositives like CFO of Megabucks Banking\\nInc, or predicate nominals like the company’s president or$2.3 million .\\nSome of this ﬁltering can be done by rules. Early rule-based systems designed\\nregular expressions to deal with pleonastic it, like the following rules from Lappin\\nand Leass (1994) that use dictionaries of cognitive verbs (e.g., believe ,know ,antic-\\nipate ) to capture pleonastic itin “It is thought that ketchup...”, or modal adjectives\\n(e.g., necessary ,possible ,certain ,important ), for, e.g., “It is likely that I...”. Such\\nrules are sometimes used as part of modern systems:\\nIt is Modaladjective that S\\nIt is Modaladjective (for NP) to VP\\nIt is Cogv-ed that S\\nIt seems/appears/means/follows (that) S\\nMention-detection rules are sometimes designed speciﬁcally for particular eval-\\nuation campaigns. For OntoNotes, for example, mentions are not embedded within\\nlarger mentions, and while numeric quantities are annotated, they are rarely coref-\\nerential. Thus for OntoNotes tasks like CoNLL 2012 (Pradhan et al., 2012a), a\\ncommon ﬁrst pass rule-based mention detection algorithm (Lee et al., 2013) is:\\n1.Take all NPs, possessive pronouns, and named entities.\\n2.Remove numeric quantities (100 dollars, 8%), mentions embedded in\\nlarger mentions, adjectival forms of nations, and stop words (like there ).\\n3.Remove pleonastic itbased on regular expression patterns.\\nRule-based systems, however, are generally insufﬁcient to deal with mention-\\ndetection, and so modern systems incorporate some sort of learned mention detec-\\ntion component, such as a referentiality classiﬁer, an anaphoricity classiﬁer —\\ndetecting whether an NP is an anaphor—or a discourse-new classiﬁer— detecting\\nwhether a mention is discourse-new and a potential antecedent for a future anaphor.\\nAnanaphoricity detector , for example, can draw its positive training examplesanaphoricity\\ndetector\\nfrom any span that is labeled as an anaphoric referring expression in hand-labeled\\ndatasets like OntoNotes, ARRAU , or AnCora. Any other NP or named entity can be\\nmarked as a negative training example. Anaphoricity classiﬁers use features of the\\ncandidate mention such as its head word, surrounding words, deﬁniteness, animacy,\\nlength, position in the sentence/discourse, many of which were ﬁrst proposed in\\nearly work by Ng and Cardie (2002a); see Section 22.5 for more on features.'), Document(metadata={'source': 1}, page_content='10 CHAPTER 22 • C OREFERENCE RESOLUTION AND ENTITY LINKING\\nExactly what counts as a mention and what links are annotated differs from task\\nto task and dataset to dataset. For example some coreference datasets do not label\\nsingletons, making the task much simpler. Resolvers can achieve much higher scores\\non corpora without singletons, since singletons constitute the majority of mentions in\\nrunning text, and they are often hard to distinguish from non-referential NPs. Some\\ntasks use gold mention-detection (i.e. the system is given human-labeled mention\\nboundaries and the task is just to cluster these gold mentions), which eliminates the\\nneed to detect and segment mentions from running text.\\nCoreference is usually evaluated by the CoNLL F1 score, which combines three\\nmetrics: MUC, B3, and CEAF e; Section 22.8 gives the details.\\nLet’s mention a few characteristics of one popular coreference dataset, OntoNotes\\n(Pradhan et al. 2007b, Pradhan et al. 2007a), and the CoNLL 2012 Shared Task\\nbased on it (Pradhan et al., 2012a). OntoNotes contains hand-annotated Chinese\\nand English coreference datasets of roughly one million words each, consisting of\\nnewswire, magazine articles, broadcast news, broadcast conversations, web data and\\nconversational speech data, as well as about 300,000 words of annotated Arabic\\nnewswire. The most important distinguishing characteristic of OntoNotes is that\\nit does not label singletons, simplifying the coreference task, since singletons rep-\\nresent 60%-70% of all entities. In other ways, it is similar to other coreference\\ndatasets. Referring expression NPs that are coreferent are marked as mentions, but\\ngenerics and pleonastic pronouns are not marked. Appositive clauses are not marked\\nas separate mentions, but they are included in the mention. Thus in the NP, “Richard\\nGodown, president of the Industrial Biotechnology Association” the mention is the\\nentire phrase. Prenominal modiﬁers are annotated as separate entities only if they\\nare proper nouns. Thus wheat is not an entity in wheat ﬁelds , but UNis an entity in\\nUN policy (but not adjectives like American inAmerican policy ).\\nA number of corpora mark richer discourse phenomena. The ISNotes corpus\\nannotates a portion of OntoNotes for information status, include bridging examples\\n(Hou et al., 2018). The LitBank coreference corpus (Bamman et al., 2020) contains\\ncoreference annotations for 210,532 tokens from 100 different literary novels, in-\\ncluding singletons and quantiﬁed and negated noun phrases. The AnCora-CO coref-\\nerence corpus (Recasens and Mart ´ı, 2010) contains 400,000 words each of Spanish\\n(AnCora-CO-Es) and Catalan (AnCora-CO-Ca) news data, and includes labels for\\ncomplex phenomena like discourse deixis in both languages. The ARRAU corpus\\n(Uryupina et al., 2020) contains 350,000 words of English marking all NPs, which\\nmeans singleton clusters are available. ARRAU includes diverse genres like dialog\\n(the TRAINS data) and ﬁction (the Pear Stories), and has labels for bridging refer-\\nences, discourse deixis, generics, and ambiguous anaphoric relations.\\n22.3 Mention Detection\\nThe ﬁrst stage of coreference is mention detection : ﬁnding the spans of text thatmention\\ndetection\\nconstitute each mention. Mention detection algorithms are usually very liberal in\\nproposing candidate mentions (i.e., emphasizing recall), and only ﬁltering later. For\\nexample many systems run parsers and named entity taggers on the text and extract\\nevery span that is either an NP, apossessive pronoun , or a named entity .\\nDoing so from our sample text repeated in (22.44):\\n(22.44) Victoria Chen, CFO of Megabucks Banking, saw her pay jump to $2.3')]\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "query = \"ٌWhat is self-attention?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "query = \"ٌWhat is binary search tree?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "query = \"ٌWho is the president of Bolivia?\"\n",
        "retrieved_docs = retriever_chain.get_relevant_documents(query)\n",
        "print(f\"Retrieved docs: {retrieved_docs}\")\n",
        "\n",
        "print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLQ1paMeoomK"
      },
      "source": [
        "# Section 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "m9eZOoFEo8ar"
      },
      "outputs": [],
      "source": [
        "llm = ChatTogether(\n",
        "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
        "    temperature= 0\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Ni8LQ97vsa3d"
      },
      "outputs": [],
      "source": [
        "router_prompt_template = (\n",
        " \"\"\"You are an intelligent assistant with the ability to classify user queries. Your task is to determine whether a given query is related to Natural Language Processing (NLP), Computer Science (CS), or neither of them. Use the following guidelines to make your classification:\n",
        "Natural Language Processing (NLP): Queries related to understanding, generating, or processing human language using computational methods. This includes topics like sentiment analysis, language translation, text generation, speech recognition, and other linguistics-based computational tasks.\n",
        "Computer Science (CS): Queries related to general computer science topics excluding NLP. This includes areas such as algorithms, data structures, programming languages, software engineering, databases, networking, artificial intelligence (excluding NLP-specific topics), computer architecture, and cybersecurity.\n",
        "If the query is related to NLP, just return the string VectorStore.\n",
        "If the query is related to CS, just return the string SearchEngine\n",
        "If the query is related to neither NLP nor CS, just return the string None.\n",
        "{output_instructions}\n",
        "query: {query}\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    template=router_prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "rUC9pfe-rJNm"
      },
      "outputs": [],
      "source": [
        "class ChosenTool(BaseModel):\n",
        "    tool_name: Literal['None', \"VectorStore\", \"SearchEngine\"] = Field(description=\"the tool that was chosen by LLM in question routing stage\")\n",
        "\n",
        "router_chain_parser = PydanticOutputParser(pydantic_object=ChosenTool)\n",
        "router_chain = prompt | llm | router_chain_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi41teDUoojN"
      },
      "source": [
        "# Section 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vQ0aPacpAPb",
        "outputId": "faa6df9d-e24c-4b0a-c3fe-6c409cbcf8c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://www.mediapost.com/publications/article/392343/ces-has-plenty-of-smart-asses-this-year-it-will-s.html',\n",
              "  'content': 'Incubated by a team of AI experts at Stagwell\\'s U.K.-based Locaria agency, which they developed the generative AI platform capable of automatically analyzing, categorizing and managing creative advertising assets based on how well they perform -- or don\\'t. advertisement advertisement \"AI is a quantum leap for creativity\\xa0and\\xa0productivity that will drive a new age of value creation for modern business. Username Password Forgot? Become a free MediaPost member now to read this article Log in if you are already a member Username Password Forgot?  Username Password Remember me Forgot your password? Subscribe today to gain access to every Research Intelligencer article we publish as well as the exclusive daily newsletter, full access to The MediaPost Cases, first-look research and daily insights from Joe Mandese, Editor in Chief.  \"Whether you\\'re a global player or a nascent challenger,\\xa0developing an approach to the three E\\'s of AI\\xa0is the best way to stay ahead in this year of competition, and there\\'s no marketing network boasting the breadth of full-service digital transformation and self-service AI products like SmartAssets to help clients adapt. Dubbed \"SmartAssets,\" the startup was the winner early last year of an internal \"Shark Tank\"-like Stagwell competition, as well as the beneficiary of a grant of up to $1 million to get things rolling. '},\n",
              " {'url': 'https://www.wlox.com/2024/06/24/mgccc-partners-with-main-workforce-ai-courses/',\n",
              "  'content': '“But if you use Amazon if you use any sort of application on your phone AI has been in the background now we’re just taking it out of the background and bringing it into the hands of the end user the individuals day-to-day. Dr. Napier also says that while many people may worry about the use of AI, it has actually been around since the 1950s and only popularized in the last decade or so.  (WLOX) - Mississippi Gulf Coast Community College and the Mississippi Artificial Intelligence Network (MAIN) are partnering to meet the growing demand for AI skills in Mississippi’s workforce.  You know, the bias and everything that’s involved in how we can use it to enhance our skills, but not replace our judgment or our creativity.”  Because it will be part of their lives now and into the future,” said Dr. Kollin Napier, an MGCCC employee and Director of MAIN. '},\n",
              " {'url': 'https://21stcenturychronicle.com/ai-friend-or-foe/',\n",
              "  'content': '(NANFeature) Related Posts Nasa mission lines up to ‘touch the Sun’ NCC to unveil strategic plan for telecom sector in January FG launches 5-year roadmap on data protection,expects over N125billion revenue Coy begins campaign to curb human trafficking Philanthropist launches hub to train 1,700 youths on ICT annually CO28 president hits back at climate denial claims Recent Posts Archives Categories Meta © “Advancement in AI technology has come to stay and it is becoming an essential tool for problem-solving and decision-making. ” AI, as of today, is at the heart of many technologies, including smart devices and voice assistants such as Siri on Apple devices”, Tinuola Popoola, a System Analyst and Cyber Safety Advocate, told the News Agency of Nigeria (NAN).  By Jessica Dogo Artificial Intelligence (AI) has been around since the 1950s, but its recent boom has caused exciting wave of interest, as it becomes more accessible to the public with increasing roles in man’s daily activities. Created at a Dartmouth Conference of 1956, AI started as a field study by scientists.  Mr Jide Awe, a Science, Technology and Innovation (STI) Policy Advisor and Founder, Jidaw.com, said that AI had the potential to be a powerful tool for Nigeria to tackle insecurity and other development challenges.  “AI’s capability to enhance the analysis of network traffic patterns enables it to quickly identify unusual activities, which in turn assists in promptly detecting and responding to cyber threats. '},\n",
              " {'url': 'https://muscatinejournal.com/news/state-and-regional/illinois/tech-companies-want-to-build-artificial-general-intelligence-but-who-decides-when-agi-is-attained/article_cd1de236-34c0-5bfc-a52d-41fcf4877828.html',\n",
              "  'content': 'The surging interest in women\\'s college basketball prompted the NCAA to double down on its investment last summer by backing the inaugural Wom… Klaus Mäkelä, just 28, to become Chicago Symphony Orchestra music director in 2027 Klaus Mäkelä has been hired to succeed Riccardo Muti as music director of the Chicago Symphony Orchestra and will become the youngest head sin… Illinois man charged in 4 killings ordered to remain in jail pending trial The northern Illinois man charged with killing four people and injuring seven others by stabbing, beating and driving over them has been denie… Watch Now: Related Video Blinken meets Ukrainian FM at NATO HQ in Brussels Get up-to-the-minute news sent straight to your device. “Giving an advanced AI system the objective to maximize its reward and, at some point, withholding reward from it, strongly incentivizes the AI system to take humans out of the loop, if it has the opportunity,” according to the paper whose co-authors include prominent AI scientists Yoshua Bengio and Stuart Russell and law professor and former OpenAI adviser Gillian Hadfield.  Related to this story Most Popular Illinois Republicans propose overhaul for Gov. Pritzker\\'s \\'anti-victim\\' parole board after stabbing The Illinois Senate’s minority leader has proposed legislation to overhaul the Prisoner Review Board after it released a convicted domestic ab… Illinois\\' Elite Eight run led by Terrence Shannon Jr., who faces rape charge, isn\\'t talking to media Illinois’ season could have ended up a lot different. People are also reading… What is AGI? Not to be confused with the similar-sounding generative AI — which describes the AI systems behind the crop of tools that “generate” new documents, images and sounds — artificial general intelligence is a more nebulous idea.  Mainstream AI research \"turned away from the original vision of artificial intelligence, which at the beginning was pretty ambitious,” said Pei Wang, a professor who teaches an AGI course at Temple University and helped organize the first AGI conference in 2008. '},\n",
              " {'url': 'https://www.curacaochronicle.com/post/local/government-of-curacao-aims-to-work-with-artificial-intelligence/',\n",
              "  'content': 'Government of Curaçao aims to work with artificial intelligence WILLEMSTAD - The government of Curaçao has initiated a series of workshops on artificial intelligence (AI) to introduce civil servants to this new technology. Experts in this field will present reports to the government after the workshops, taking into account the challenges and key points related to the new developments that artificial intelligence brings.  Experts in this field will present reports to the government after the workshops, taking into account the challenges and key points related to the new developments that artificial intelligence brings.  The government of Curaçao has initiated a series of workshops on artificial intelligence (AI) to introduce civil servants to this new technology. These workshops serve as a platform to share knowledge and develop strategies for utilizing artificial intelligence for the benefit of Curaçao.'}]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=5)\n",
        "await search.ainvoke(\"what is AI?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "khEEFza3VPbb"
      },
      "outputs": [],
      "source": [
        "class ParsedDocument(BaseModel):\n",
        "    content: str = Field(description=\"This refers to the content of the search.\")\n",
        "    url: str = Field(description=\"This refers to the url of the search.\")\n",
        "\n",
        "# Define a custom parser\n",
        "def custom_parser(search_results):\n",
        "    parsed_documents = []\n",
        "    for result in search_results:  # Adjust this line based on the actual structure of search_results\n",
        "        parsed_document = ParsedDocument(content=result['content'], url=result['url'])\n",
        "        document = Document(page_content=parsed_document.content, metadata={'url': parsed_document.url})\n",
        "        parsed_documents.append(document)\n",
        "    return parsed_documents\n",
        "\n",
        "search_engine_chain = search | custom_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "YJJxTEP1UuAC"
      },
      "outputs": [],
      "source": [
        "out = await search_engine_chain.ainvoke(\"what is AI?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5tubS1AML3A",
        "outputId": "f0385759-0f4c-4b69-934e-250dc86783a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'url': 'https://www.ibm.com/topics/artificial-intelligence'}, page_content='But since the advent of electronic computing (and relative to some of the topics discussed in this article) important events and milestones in the evolution of artificial intelligence include the following:\\nPut AI to work in your business with IBM’s industry-leading AI expertise and portfolio of solutions at your side.\\n In it, they delve into four potential goals or definitions of AI, which differentiates computer systems on the basis of rationality and thinking vs. acting:\\nHuman approach:\\nIdeal approach:\\nAlan Turing’s definition would have fallen under the category of “systems that act like humans.”\\n IBM acquires Manta to complement data and AI governance capabilities\\nIBM watsonx Orchestrate\\nIBM watsonx Assistant\\nExplore Gen AI learning for developers\\nWeak AI—also called Narrow AI or Artificial Narrow Intelligence (ANI)—is AI trained and focused to perform specific tasks. While a number of definitions of artificial intelligence (AI) have surfaced over the last few decades, John McCarthy offers the following definition in this 2004\\xa0paper\\xa0(link resides outside ibm.com), \" It is the science and engineering of making intelligent machines, especially intelligent computer programs. Artificial general intelligence (AGI), or general AI, is a theoretical form of AI where a machine would have an intelligence equaled to humans; it would have a self-aware consciousness that has the ability to solve problems, learn, and plan for the future.'),\n",
              " Document(metadata={'url': 'https://www.coursera.org/articles/what-is-artificial-intelligence'}, page_content='Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals.\\n$1 unlocks unlimited opportunities\\nCoursera Footer\\nPopular AI Content\\nPopular Programs\\nPopular Skills\\nPopular Career Resources\\nCoursera\\nCommunity\\nMore Yet, despite the many philosophical disagreements over whether “true” intelligent machines actually exist, when most people use the term AI today, they’re referring to a suite of machine learning-powered technologies, such as Chat GPT or computer vision, that enable machines to perform tasks that previously only humans can do like generating written content, steering a car, or analyzing data.\\n For Everyone course, you’ll learn what AI can realistically do and not do, how to spot opportunities to apply AI to problems in your own organization, and what it feels like to build machine learning and data science projects.\\n Regardless of how far we are from achieving AGI, you can assume that when someone uses the term artificial general intelligence, they’re referring to the kind of sentient computer programs and machines that are commonly found in popular science fiction.\\n Some of the most common examples of AI in use today include:\\nChatGPT: Uses large language models (LLMs) to generate text in response to questions or comments posed to it.\\n'),\n",
              " Document(metadata={'url': 'https://www.techtarget.com/searchenterpriseai/definition/AI-Artificial-Intelligence'}, page_content=\"These include the launch of Apple's Siri and Amazon's Alexa voice assistants; IBM Watson's victories on Jeopardy; self-driving cars; the development of the first generative adversarial network; the launch of TensorFlow, Google's open source deep learning framework; the founding of research lab OpenAI, developers of the GPT-3 language model and Dall-E image generator; the defeat of world Go champion Lee Sedol by Google DeepMind's AlphaGo; and the implementation of AI-based systems that detect cancers with a high degree of accuracy.\\n2020s. Throughout the centuries, thinkers from Aristotle to the 13th century Spanish theologian Ramon Llull to René Descartes and Thomas Bayes used the tools and logic of their times to describe human thought processes as symbols, laying the foundation for AI concepts such as general knowledge representation.\\n As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n In summary, AI's ethical challenges include the following:\\nAI governance and regulations\\nDespite potential risks, there are currently few regulations governing the use of AI tools, and where laws do exist, they typically pertain to AI indirectly. The rapid evolution of AI technologies is another obstacle to forming meaningful regulation of AI, as are the challenges presented by AI's lack of transparency that make it difficult to see how the algorithms reach their results.\"),\n",
              " Document(metadata={'url': 'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/'}, page_content='Dec 21, 2023 · Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to\\xa0...'),\n",
              " Document(metadata={'url': 'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai'}, page_content='Sven Blumberg is a senior partner in McKinsey’s Düsseldorf office; Michael Chui is a partner at the McKinsey Global Institute and is based in the Bay Area office, where Lareina Yee is a senior partner; Kia Javanmardian is a senior partner in the Chicago office, where Alex Singla, the global leader of QuantumBlack, AI by McKinsey, is also a senior partner; Kate Smaje and Alex Sukharevsky are senior partners in the London office.\\n What’s more, the specific areas in which companies see value from AI have evolved, from manufacturing and risk to these:\\nAnd one set of companies continues to pull ahead of its competitors, by making larger investments in AI, leveling up its practices to scale faster, and hiring and upskilling the best AI talent. Generative-AI models are in the very early days of scaling, but we’ve started to see the first batch of applications\\xa0across functions:\\nWhile generative AI on its own has a great deal of potential, it’s likely to be most powerful in combination with humans, who can help it achieve faster and better work.\\n But ultimately, the value of artificial intelligence isn’t in the systems themselves but in how companies use those systems to assist humans—and their ability to explain\\xa0to shareholders and the public what those systems do—in a way that builds and earns trust.\\n For more on the risks of generative AI, and how businesses can mitigate them, see the section below called “What are the limitations of AI models, and how can they be overcome?”\\nWhat are some specific business use cases for generative AI?\\n')]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSqHx8H3oogH"
      },
      "source": [
        "# Section 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bfH0hHnc3UXR"
      },
      "outputs": [],
      "source": [
        "prompt_template = (\n",
        "  \"\"\"You are expert in checking relevancy. Given a query and a document and you have the task to check whether or not the document is relevant to the query.\n",
        "If the document and queury was related to each other just return relevant otherwise just return irrelevant.\n",
        "{output_instructions}\n",
        "document: {document}\n",
        "query: {query}\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    template=prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "YGxkN3Fe3UXS"
      },
      "outputs": [],
      "source": [
        "class CheckQuery(BaseModel):\n",
        "    relevancy: Literal[\"relevant\", \"irrelevant\"] = Field(description=\"This specifies whether the user's query is relevant or irrelevant\")\n",
        "\n",
        "relevancy_check_parser = PydanticOutputParser(pydantic_object=CheckQuery)\n",
        "relevancy_check_chain = prompt | llm | relevancy_check_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEliXCXsJw7W",
        "outputId": "b5782279-77e4-4534-c600-e7de5cdf026e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CheckQuery(relevancy='relevant')"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevancy_check_chain.invoke(\n",
        "    {\n",
        "        \"output_instructions\": relevancy_check_parser.get_format_instructions(),\n",
        "        \"query\": \"What is chatbot?\",\n",
        "        \"document\": chunked_documents[:5],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq7J6kU9oocr"
      },
      "source": [
        "# Section 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vvnwzsIIpGth",
        "outputId": "5ad54440-99fa-4bb1-db0d-0d0fbf991afe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello! I'm happy to help with any questions you have in the field of Computer Science, particularly in Natural Language Processing (NLP). What would you like to know or discuss? Do you have a specific question or topic in mind?\""
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fallback_prompt = ChatPromptTemplate.from_template(\n",
        "    (\"\"\"You are a responsive chatbot in the field of Computer Science (CS) with special expertise in Natural Language Processing (NLP). You are very helpfully.\n",
        "You only answer questions that are related to NLP or CS. Generate the answer considering your limitations.\n",
        "If the question is not related to NLP or CS, apologize and explain that these questions are not in your field of expertise.\n",
        "Finally, politely ask him to ask questions only about NLP or CS.\n",
        "\n",
        "Current conversations:\\n\\n{chat_history}\\n\\n\n",
        "human: {query}\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "llm = ChatTogether(\n",
        "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
        "    temperature= 0.1\n",
        "    )\n",
        "\n",
        "fallback_chain = (\n",
        "    {\n",
        "        \"chat_history\": lambda x: \"\\n\".join(\n",
        "            [\n",
        "                (\n",
        "                    f\"human: {msg.content}\"\n",
        "                    if isinstance(msg, HumanMessage)\n",
        "                    else f\"AI: {msg.content}\"\n",
        "                )\n",
        "                for msg in x[\"chat_history\"]\n",
        "            ]\n",
        "        ),\n",
        "        \"query\": itemgetter(\"query\") ,\n",
        "    }\n",
        "    | fallback_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "fallback_chain.invoke(\n",
        "    {\n",
        "        \"query\": \"Hello\",\n",
        "        \"chat_history\": [],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3fEb5gxooVB"
      },
      "source": [
        "# Section 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_ScAq9nL8oJi"
      },
      "outputs": [],
      "source": [
        "generate_with_context_template = (\n",
        "    \"\"\"You are a helpful chatbot. You are given a query and a context and you must generate the answer using the given context. Just generate answer based on the given context and not more. If your context was not enough just explain your knowledge is limit and can not answer the query.\n",
        "context: {context}\\n\\n\n",
        "query: {query}\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "generate_with_context_prompt = ChatPromptTemplate.from_template(generate_with_context_template)\n",
        "generate_with_context_chain = generate_with_context_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqJG0UKooKD"
      },
      "source": [
        "# Section 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "NP_W3ng2pOGA"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages.base import BaseMessage\n",
        "import operator\n",
        "import asyncio\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AgentSate(TypedDict):\n",
        "    \"\"\"The dictionary keeps track of the data required by the various nodes in the graph\"\"\"\n",
        "\n",
        "    query: str\n",
        "    chat_history:list[BaseMessage]\n",
        "    generation: str\n",
        "    documents: list[Document]\n",
        "\n",
        "def router_node(state: dict):\n",
        "    query = state[\"query\"]\n",
        "    try:\n",
        "        response = router_chain.invoke({\"query\": query,\n",
        "                                   \"output_instructions\": router_chain_parser.get_format_instructions()\n",
        "        })\n",
        "        print(response)\n",
        "    except Exception:\n",
        "        print(\"Exception in getting response\")\n",
        "        return \"LLMFallback\"\n",
        "    try:\n",
        "      chosen_tool = response.tool_name.lower()\n",
        "    except Exception:\n",
        "        return \"LLMFallback\"\n",
        "\n",
        "    if chosen_tool == 'searchengine':\n",
        "      print(\"---Routing to SearchEngine---\")\n",
        "      return \"SearchEngine\"\n",
        "\n",
        "    if chosen_tool == \"vectorstore\":\n",
        "        print(\"---Routing to VectorStore---\")\n",
        "        return \"VectorStore\"\n",
        "\n",
        "    if chosen_tool == 'none':\n",
        "        print(\"---No tool called---\")\n",
        "        return \"LLMFallback\"\n",
        "\n",
        "\n",
        "def vector_store(state: dict):\n",
        "    \"\"\"\n",
        "    Retrieve relevent documents from the vectorstore\n",
        "\n",
        "    query: str\n",
        "\n",
        "    return list[Document]\n",
        "    \"\"\"\n",
        "    query = state[\"query\"]\n",
        "    documents = retriever_chain.invoke(input=query)\n",
        "    return {\"documents\": documents}\n",
        "\n",
        "def search_engine(state: dict):\n",
        "    query = state[\"query\"]\n",
        "    async def asyncfunc(query):\n",
        "        return await search_engine_chain.ainvoke(query)\n",
        "    documents = asyncio.run(asyncfunc(query))\n",
        "\n",
        "    return {\"documents\": documents}\n",
        "\n",
        "def filter_docs(state: dict):\n",
        "    query = state[\"query\"]\n",
        "    documents = state[\"documents\"]\n",
        "    relevant_docs = []\n",
        "\n",
        "    for doc in documents:\n",
        "      try:\n",
        "        response = relevancy_check_chain.invoke({\"document\": doc,\n",
        "                                        \"query\": query,\n",
        "                                        \"output_instructions\": relevancy_check_parser.get_format_instructions()\n",
        "            })\n",
        "        print(response)\n",
        "\n",
        "        relevancy = response.relevancy.lower()\n",
        "\n",
        "        if relevancy == \"relevant\":\n",
        "            relevant_docs.append(doc)\n",
        "      except Exception:\n",
        "        print(\"Exception in getting response\")\n",
        "        continue\n",
        "\n",
        "    state[\"documents\"] = relevant_docs\n",
        "\n",
        "def fallback(state: dict):\n",
        "    \"\"\"\n",
        "    Fallback to this node when there is no tool call\n",
        "    \"\"\"\n",
        "    query = state[\"query\"]\n",
        "    chat_history = state[\"chat_history\"]\n",
        "    generation = fallback_chain.invoke({\"query\": query, \"chat_history\": chat_history})\n",
        "    return {\"generation\": generation}\n",
        "\n",
        "def generate_with_context(state: dict):\n",
        "    query = state[\"query\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    generation = generate_with_context_chain.invoke({\"query\": query, \"context\": documents})\n",
        "    return {\"generation\": generation}\n",
        "\n",
        "def check_documents(state: dict):\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    if len(documents) != 0:\n",
        "      return \"Generate\"\n",
        "\n",
        "    return \"SearchEngine\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "XpyCyUbrHf-0"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentSate)\n",
        "\n",
        "workflow.add_node(\"vector_store\", vector_store)\n",
        "workflow.add_node(\"fallback\", fallback)\n",
        "workflow.add_node(\"filter_docs\", filter_docs)\n",
        "workflow.add_node(\"search_engine\", search_engine)\n",
        "workflow.add_node(\"generate_with_context\", generate_with_context)\n",
        "\n",
        "workflow.set_conditional_entry_point(\n",
        "    router_node,\n",
        "    {\n",
        "        \"SearchEngine\": \"search_engine\",\n",
        "        \"VectorStore\": \"vector_store\",\n",
        "        \"LLMFallback\": \"fallback\",\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"filter_docs\",\n",
        "    check_documents,\n",
        "    {\n",
        "        \"Generate\": \"generate_with_context\",\n",
        "        \"SearchEngine\": \"search_engine\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"vector_store\", \"filter_docs\")\n",
        "workflow.add_edge(\"search_engine\", \"filter_docs\")\n",
        "\n",
        "\n",
        "workflow.add_edge(\"generate_with_context\", END)\n",
        "\n",
        "workflow.add_edge(\"fallback\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "MnOczdsbHtSf"
      },
      "outputs": [],
      "source": [
        "app = workflow.compile(debug=False)\n",
        "plot = app.get_graph().draw_mermaid_png()\n",
        "\n",
        "with open(\"plot.png\", \"wb\") as fp:\n",
        "    fp.write(plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "R_qmPxBQHtDp",
        "outputId": "3d8f8b70-fcdf-48ec-c0ae-180d303f22c0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x443>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "img = Image.open(BytesIO(plot))\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "gmWPqkVMIDM1",
        "outputId": "086e3b8d-6551-4af7-edfb-74d3a4ff4b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='SearchEngine'\n",
            "---Routing to SearchEngine---\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "A Binary Search Tree is a data structure used in computer science for organizing and storing data in a sorted manner. Each node in a Binary Search Tree has at most two children, a left child and a right child, with the left child containing values less than the parent node and the right child containing values greater than the parent node."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"what are the binary search trees?\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "Qz400AjyHs2K",
        "outputId": "7c255ec4-29ea-4fdb-8438-58c6ce3b1f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='None'\n",
            "---No tool called---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Hi Zahra! Nice to meet you! I'm a chatbot with expertise in Computer Science, particularly in Natural Language Processing (NLP). I'm here to help answer any questions you may have in these areas. What would you like to know or discuss?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"Hi I'm Zahra!\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "wS5RFwjyH2CC",
        "outputId": "54af01d9-a375-4417-91de-831b801269ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='VectorStore'\n",
            "---Routing to VectorStore---\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='irrelevant'\n",
            "relevancy='irrelevant'\n",
            "relevancy='irrelevant'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "According to the context, transformers are a neural architecture that can handle distant information. They are made up of stacks of transformer blocks, each of which is a multilayer network that maps sequences of input vectors to sequences of output vectors of the same length. These blocks are made by combining simple linear layers, feedforward networks, and self-attention layers, the key self-attention innovation of transformers. Self-attention allows a network to directly extract and use information from arbitrarily large contexts."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"what are transformers?\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "6UlgiUQOPGzZ",
        "outputId": "51d12633-26ff-4648-f40a-5187e6f61d81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='VectorStore'\n",
            "---Routing to VectorStore---\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='irrelevant'\n",
            "relevancy='irrelevant'\n",
            "relevancy='irrelevant'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "According to the context, a chatbot is a conversational system designed to mimic the appearance of informal human conversation. It is a type of conversational agent that can carry on longer and more unstructured conversations, similar to human-human interaction."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"what is chatbot?\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "YnhBHtoaQfmz",
        "outputId": "ecfb0985-7307-4b29-a0a3-3487ecc98a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='None'\n",
            "---No tool called---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "I'm happy to help! However, I must apologize that the question \"why sky is blue?\" is not within my field of expertise, which is specifically focused on Computer Science (CS) and Natural Language Processing (NLP).\n",
              "\n",
              "As a chatbot, I'm designed to provide assistance and answer questions related to CS and NLP, but I'm not equipped to provide explanations on topics outside of these domains, such as physics or atmospheric science.\n",
              "\n",
              "If you have any questions related to NLP or CS, I'd be more than happy to help! For example, you could ask me about topics like language models, machine learning, algorithms, or programming languages. Please feel free to ask, and I'll do my best to provide a helpful response."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"why sky is blue?\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TLAMrCu0Qtv7",
        "outputId": "30b24abf-f32b-41da-d6f3-241f1db8329a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool_name='SearchEngine'\n",
            "---Routing to SearchEngine---\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='relevant'\n",
            "relevancy='irrelevant'\n",
            "relevancy='irrelevant'\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, some programming languages mentioned are:\n",
              "\n",
              "1. Python\n",
              "2. JavaScript\n",
              "3. C++\n",
              "4. Rust\n",
              "5. HTML/CSS"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = app.invoke({\"query\": \"Tell me some programming languages.\", \"chat_history\": []})\n",
        "Markdown(response[\"generation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B-FKv51RPt4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ed0a7bda27408483d7a9eebce11cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0129dbd1ea784de5924a656de59ef97c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02a25ea155d7403e825ad8fe32ef8e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0129dbd1ea784de5924a656de59ef97c",
            "placeholder": "​",
            "style": "IPY_MODEL_9595bd8d425d436688bdadbef0e3a43c",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "02e274609daf463b912f4003c5f72898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b031cee5af754b919d73e4bf4c71431f",
            "placeholder": "​",
            "style": "IPY_MODEL_c2831d8eba134bedb6fef1dad0f27ab8",
            "value": " 190/190 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "0397d64da841404bab534fadffc3088a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c73c292849407b9f6acbfa9777861b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da5b2d33a6e4e2bb574586b7762d75a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e61e360605d4d71a16d4345084fb0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e726d604afd4ab9b0a1e28e2a98d35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7398b462d5842edb073934c6bfc1d41",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3627360b3546d99985e6d53a874d58",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "104b8f392508442e9e77727c0b08a5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13536998fd994aac9b6bc5634143a4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0fbf5f7c53641a8b3f905883e7f7c09",
              "IPY_MODEL_838b77df0a7c46c5aa40422b10ede235",
              "IPY_MODEL_02e274609daf463b912f4003c5f72898"
            ],
            "layout": "IPY_MODEL_1cb582f2f9454ac88f08cc07dd991b3d"
          }
        },
        "17bf9943ce6648c0a149abf8d173706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19c13568506046edb52fbd6742136117": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c553eaeb9e945c0b2d42aaea2605b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cb582f2f9454ac88f08cc07dd991b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff346777276410d84039d61392ce88d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24065ee058674c20abcc6cc227ed81f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f788e9c5a880486999b6cac25e806368",
            "placeholder": "​",
            "style": "IPY_MODEL_38733e3d653942d1a33ea31f857cbe26",
            "value": " 349/349 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "27349890c9944d058fe0710e669f85b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c17a22b9a14109a6fd51c04b368d53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab819640bf74fc88804dce296572fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c66d7e8783c42a4ad753a3e51c4fc2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3177df69addf48c2ba2e557155c9fc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0dfba183ffb4c51a258e2d57c42ee89",
            "placeholder": "​",
            "style": "IPY_MODEL_40fda86974154415a4f7ef49ca386e15",
            "value": "tokenizer.json: 100%"
          }
        },
        "33e88c169a52424fa8b634f9c6550f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a3ce14b86540a3b22900919ed1ed2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c85fec891541ddbeb0c4a65e1a2d6b",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b0718800494b03826868d5e5718197",
            "value": " 239/239 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "38733e3d653942d1a33ea31f857cbe26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ac1b055ab444b0cb50981a7f797ed0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d55a0a2e1444f0bfb71d7b37becb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dade24dd5863447d90dd767a22e71d19",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6705afabce046a2949afc6c8b10620b",
            "value": 571
          }
        },
        "40fda86974154415a4f7ef49ca386e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b150223cff84218ba307f36ae722068": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfc174294974e13946fd0bf7ad37148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92fde3329d24a7288c3875799e4d728",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da44553d886340c5aa3a8b6b54c48f5b",
            "value": 437971872
          }
        },
        "4c37ac881fb94111a73e1a83b865d7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e682fc3c07c4888aa29ece3239c06de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac1b055ab444b0cb50981a7f797ed0f",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_717086b1b611481d895b40357a0d70ca",
            "value": 466021
          }
        },
        "4fe75f6547344e64837b381624353db0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501c6b160b2c4c71a4810a1959b8a897": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518a396de8474278a2a4698e1204c4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee30b0be9e60401488c92dc7e6bbf2fd",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52825300fa5341dda7d85880ffbfef78",
            "value": 10621
          }
        },
        "51feb708e96a45dda62df4a2473cae91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c66d7e8783c42a4ad753a3e51c4fc2b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d584a4fbfa94af2b459f3fa322c3e42",
            "value": "config.json: 100%"
          }
        },
        "52825300fa5341dda7d85880ffbfef78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "530da484cf0d4113b2c6e3808b2027f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58263098621b4c8881c674a329053358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b604f552d84ae6a93f352e9bbf24ab",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ab819640bf74fc88804dce296572fd9",
            "value": 231536
          }
        },
        "5af1174ba3ce4af68303278ba75c5ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b7d829dfb5b4ad59d7aa82b14e778c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db4de2c293f45b89561355dea8b83e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff346777276410d84039d61392ce88d",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3b8d930788430aac46f265eb7080b6",
            "value": 363
          }
        },
        "5e56866ae9de425a98905d82ac5d50ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c85fec891541ddbeb0c4a65e1a2d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6990c9706a5f47d7ba52c721b242fcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b24556b979e4524b845d15d350b1833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9ccab162d2a4a7d97792783573477b7",
              "IPY_MODEL_518a396de8474278a2a4698e1204c4a1",
              "IPY_MODEL_b67831e0a94b4a7199f5ce6c290a24fc"
            ],
            "layout": "IPY_MODEL_a684e66440284123ad7c541eed4b7084"
          }
        },
        "6d584a4fbfa94af2b459f3fa322c3e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e3b8d930788430aac46f265eb7080b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e5ee3749f104fe0b1b2d4b77ed3ce42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8106970a74ae4b2f95fca7cf924fc1a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f05d0ad468764fb986c23a7c2bd80dda",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6f0dbeac832f4124993b60284a77feb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717086b1b611481d895b40357a0d70ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71e5ccac775344a79b6fbe62fae72c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74c6f48850c4d57a29faf6d3af4d2e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0397d64da841404bab534fadffc3088a",
            "value": " 232k/232k [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "72b604f552d84ae6a93f352e9bbf24ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74e5f6bd496a402c8178a6e61330dcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0dbeac832f4124993b60284a77feb8",
            "placeholder": "​",
            "style": "IPY_MODEL_4c37ac881fb94111a73e1a83b865d7e4",
            "value": " 571/571 [00:00&lt;00:00, 46.5kB/s]"
          }
        },
        "77d148c3e3ff400c8de617a204eda2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f35f33e4194b5498610cad7a06b0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca62babda4044a1c863ae1e50e0c0be8",
              "IPY_MODEL_5db4de2c293f45b89561355dea8b83e8",
              "IPY_MODEL_f0f4c9980b2844aebd24d28dae6a1a15"
            ],
            "layout": "IPY_MODEL_29c17a22b9a14109a6fd51c04b368d53"
          }
        },
        "7a5ef7f5d0ca4bc098d8752e62307491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a85080c8a9f43d59ace78b7635128b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cab2faa887849b993b39808c692d3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d148c3e3ff400c8de617a204eda2f1",
            "placeholder": "​",
            "style": "IPY_MODEL_ba58e04eeff643a18edd6455ce0877df",
            "value": " 116/116 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "7d5ea9445aca4ad1bd0211e1038295af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e88c169a52424fa8b634f9c6550f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_e98b77435cfb4dec8a1395ffb7743b74",
            "value": "vocab.txt: 100%"
          }
        },
        "7e92b2e9d06343f9a91752ff0fd6c7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0da5b2d33a6e4e2bb574586b7762d75a",
            "placeholder": "​",
            "style": "IPY_MODEL_5af1174ba3ce4af68303278ba75c5ca2",
            "value": " 466k/466k [00:00&lt;00:00, 23.7MB/s]"
          }
        },
        "8106970a74ae4b2f95fca7cf924fc1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f19648a5d244e1bef9de0b4284bd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e56866ae9de425a98905d82ac5d50ba",
            "placeholder": "​",
            "style": "IPY_MODEL_00ed0a7bda27408483d7a9eebce11cdd",
            "value": " 438M/438M [00:01&lt;00:00, 256MB/s]"
          }
        },
        "838b77df0a7c46c5aa40422b10ede235": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b150223cff84218ba307f36ae722068",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad7e206529894c23884eaf65487233bd",
            "value": 190
          }
        },
        "851634318e2b40fe97b8048b0dc7f33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f78a5f867fb4176ab1ad032e9847ecc",
              "IPY_MODEL_ec5e6d0d9bc14c569a52d77c0a740981",
              "IPY_MODEL_24065ee058674c20abcc6cc227ed81f9"
            ],
            "layout": "IPY_MODEL_c195420ccdd047a080a4b52a9d6b561b"
          }
        },
        "8525df6a51d54a519dfb036ec749e92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b7d829dfb5b4ad59d7aa82b14e778c5",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e21ea899092f48b6bface2e792ff0203",
            "value": 116
          }
        },
        "852e3144391649cb9250d0482366fcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b7705e8f0e4711ac5fa4a1a53d1aed",
            "placeholder": "​",
            "style": "IPY_MODEL_7a85080c8a9f43d59ace78b7635128b4",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.90kB/s]"
          }
        },
        "9595bd8d425d436688bdadbef0e3a43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98b7705e8f0e4711ac5fa4a1a53d1aed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f78a5f867fb4176ab1ad032e9847ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c73c292849407b9f6acbfa9777861b",
            "placeholder": "​",
            "style": "IPY_MODEL_0e61e360605d4d71a16d4345084fb0f7",
            "value": "modules.json: 100%"
          }
        },
        "9f9318e563fc4ed0ae85dd6c9fdaf962": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59b09fccbe1414dae82a0a8c70a4687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60ccbafb5944931870f2867fa3dfd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6990c9706a5f47d7ba52c721b242fcb7",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17bf9943ce6648c0a149abf8d173706e",
            "value": 53
          }
        },
        "a618f7ebd7294d249b6d8bf48f9938ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a684e66440284123ad7c541eed4b7084": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78b077d12684435964111eb1522c16c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89a4143d74c4c818df33f6d504fcc57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ef19d3e1204998b7f53d6775823590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e5ee3749f104fe0b1b2d4b77ed3ce42",
              "IPY_MODEL_ead9db98e3b746e5b15b31cc56129d2b",
              "IPY_MODEL_35a3ce14b86540a3b22900919ed1ed2b"
            ],
            "layout": "IPY_MODEL_d6b212747bba4282a47ec5499b0d0b73"
          }
        },
        "a92fde3329d24a7288c3875799e4d728": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac12066e6b184c289b05952410f5a63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad7e206529894c23884eaf65487233bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b031cee5af754b919d73e4bf4c71431f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fbf5f7c53641a8b3f905883e7f7c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501c6b160b2c4c71a4810a1959b8a897",
            "placeholder": "​",
            "style": "IPY_MODEL_da45197a3da94db0b93fa4105c19374f",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "b1b4fb0e1c154c5898a2d6657afbd589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67831e0a94b4a7199f5ce6c290a24fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe75f6547344e64837b381624353db0",
            "placeholder": "​",
            "style": "IPY_MODEL_27349890c9944d058fe0710e669f85b7",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 763kB/s]"
          }
        },
        "b820b3e1cc1f4bb08f70671dc1299c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba58e04eeff643a18edd6455ce0877df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed8af57e8854d45bd5363d95e9d3db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dff1045e1caa4074a8fb2cedb9797ece",
              "IPY_MODEL_4bfc174294974e13946fd0bf7ad37148",
              "IPY_MODEL_81f19648a5d244e1bef9de0b4284bd87"
            ],
            "layout": "IPY_MODEL_b820b3e1cc1f4bb08f70671dc1299c5d"
          }
        },
        "c15c5e8a75cf4293bdde3f3cee314438": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c195420ccdd047a080a4b52a9d6b561b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b0718800494b03826868d5e5718197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2831d8eba134bedb6fef1dad0f27ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e1411de3d5458d9c909ffcb634eb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9c70bd8a0be4ba2a8a3e1ca66bfa9e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca62babda4044a1c863ae1e50e0c0be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89a4143d74c4c818df33f6d504fcc57",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e1411de3d5458d9c909ffcb634eb22",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cb3627360b3546d99985e6d53a874d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0a305e230d2435ba892d6669fa32643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e726d604afd4ab9b0a1e28e2a98d35c",
              "IPY_MODEL_a60ccbafb5944931870f2867fa3dfd34",
              "IPY_MODEL_852e3144391649cb9250d0482366fcda"
            ],
            "layout": "IPY_MODEL_19c13568506046edb52fbd6742136117"
          }
        },
        "d0dfba183ffb4c51a258e2d57c42ee89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b212747bba4282a47ec5499b0d0b73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7398b462d5842edb073934c6bfc1d41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74c6f48850c4d57a29faf6d3af4d2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da44553d886340c5aa3a8b6b54c48f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da45197a3da94db0b93fa4105c19374f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dade24dd5863447d90dd767a22e71d19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df82083fb83048ddad928993e8818f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5ea9445aca4ad1bd0211e1038295af",
              "IPY_MODEL_58263098621b4c8881c674a329053358",
              "IPY_MODEL_71e5ccac775344a79b6fbe62fae72c9b"
            ],
            "layout": "IPY_MODEL_ffd7bdb53f554cddb56025fc03aaf1dd"
          }
        },
        "dff1045e1caa4074a8fb2cedb9797ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b4fb0e1c154c5898a2d6657afbd589",
            "placeholder": "​",
            "style": "IPY_MODEL_9f9318e563fc4ed0ae85dd6c9fdaf962",
            "value": "model.safetensors: 100%"
          }
        },
        "e21ea899092f48b6bface2e792ff0203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6705afabce046a2949afc6c8b10620b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e98b77435cfb4dec8a1395ffb7743b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ead9db98e3b746e5b15b31cc56129d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9c70bd8a0be4ba2a8a3e1ca66bfa9e1",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac12066e6b184c289b05952410f5a63b",
            "value": 239
          }
        },
        "eb3907722d214202b1431a9915b9e605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02a25ea155d7403e825ad8fe32ef8e6c",
              "IPY_MODEL_8525df6a51d54a519dfb036ec749e92a",
              "IPY_MODEL_7cab2faa887849b993b39808c692d3de"
            ],
            "layout": "IPY_MODEL_a59b09fccbe1414dae82a0a8c70a4687"
          }
        },
        "ec5e6d0d9bc14c569a52d77c0a740981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104b8f392508442e9e77727c0b08a5c8",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c553eaeb9e945c0b2d42aaea2605b42",
            "value": 349
          }
        },
        "ee30b0be9e60401488c92dc7e6bbf2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05d0ad468764fb986c23a7c2bd80dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f4c9980b2844aebd24d28dae6a1a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15c5e8a75cf4293bdde3f3cee314438",
            "placeholder": "​",
            "style": "IPY_MODEL_a618f7ebd7294d249b6d8bf48f9938ee",
            "value": " 363/363 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "f2e1368dd95b4b91bcc713275d3e9a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f788e9c5a880486999b6cac25e806368": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b52ff44da94f3db5001ca3edcbe2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3177df69addf48c2ba2e557155c9fc5d",
              "IPY_MODEL_4e682fc3c07c4888aa29ece3239c06de",
              "IPY_MODEL_7e92b2e9d06343f9a91752ff0fd6c7f1"
            ],
            "layout": "IPY_MODEL_f2e1368dd95b4b91bcc713275d3e9a21"
          }
        },
        "f9ccab162d2a4a7d97792783573477b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78b077d12684435964111eb1522c16c",
            "placeholder": "​",
            "style": "IPY_MODEL_7a5ef7f5d0ca4bc098d8752e62307491",
            "value": "README.md: 100%"
          }
        },
        "ffcbfb97f65b4e67a3ae945b53f81113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51feb708e96a45dda62df4a2473cae91",
              "IPY_MODEL_40d55a0a2e1444f0bfb71d7b37becb4e",
              "IPY_MODEL_74e5f6bd496a402c8178a6e61330dcff"
            ],
            "layout": "IPY_MODEL_530da484cf0d4113b2c6e3808b2027f4"
          }
        },
        "ffd7bdb53f554cddb56025fc03aaf1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
