{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Section 1: prepare packages and dataset"]},{"cell_type":"markdown","metadata":{},"source":["## install and import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:07:20.612642Z","iopub.status.busy":"2024-05-26T18:07:20.612319Z","iopub.status.idle":"2024-05-26T18:07:20.624326Z","shell.execute_reply":"2024-05-26T18:07:20.623294Z","shell.execute_reply.started":"2024-05-26T18:07:20.612615Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-26T18:07:20.626234Z","iopub.status.busy":"2024-05-26T18:07:20.625959Z","iopub.status.idle":"2024-05-26T18:11:38.845241Z","shell.execute_reply":"2024-05-26T18:11:38.844273Z","shell.execute_reply.started":"2024-05-26T18:07:20.626211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","spacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q trl xformers wandb datasets einops gradio sentencepiece bitsandbytes evaluate"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:11:38.846891Z","iopub.status.busy":"2024-05-26T18:11:38.846587Z","iopub.status.idle":"2024-05-26T18:12:45.419032Z","shell.execute_reply":"2024-05-26T18:12:45.418039Z","shell.execute_reply.started":"2024-05-26T18:11:38.846861Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: torch 2.3.0\n","Uninstalling torch-2.3.0:\n","  Successfully uninstalled torch-2.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip uninstall torch -y\n","!pip install -q torch==2.1"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:12:45.420961Z","iopub.status.busy":"2024-05-26T18:12:45.420598Z","iopub.status.idle":"2024-05-26T18:13:38.670874Z","shell.execute_reply":"2024-05-26T18:13:38.669674Z","shell.execute_reply.started":"2024-05-26T18:12:45.420925Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q --upgrade torch torchvision"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:13:38.674061Z","iopub.status.busy":"2024-05-26T18:13:38.673730Z","iopub.status.idle":"2024-05-26T18:14:00.938363Z","shell.execute_reply":"2024-05-26T18:14:00.937559Z","shell.execute_reply.started":"2024-05-26T18:13:38.674029Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-26 18:13:45.185334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-26 18:13:45.185436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-26 18:13:45.290594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import transformers\n","from transformers import AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, logging, TextStreamer, DataCollatorWithPadding, RobertaForSequenceClassification\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model, PromptEncoderConfig\n","import os,torch, wandb, platform, gradio, warnings\n","from datasets import load_dataset, load_metric, Dataset\n","from trl import SFTTrainer\n","import os\n","import numpy as np\n","import transformers\n","import evaluate\n","\n","from huggingface_hub import notebook_login\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["## define the model and the dataset path"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:00.940217Z","iopub.status.busy":"2024-05-26T18:14:00.939515Z","iopub.status.idle":"2024-05-26T18:14:00.944810Z","shell.execute_reply":"2024-05-26T18:14:00.943908Z","shell.execute_reply.started":"2024-05-26T18:14:00.940190Z"},"trusted":true},"outputs":[],"source":["model_name = \"FacebookAI/roberta-large\"\n","\n","dataset_name = \"nyu-mll/multi_nli\""]},{"cell_type":"markdown","metadata":{},"source":["## login to huggingface"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:00.946329Z","iopub.status.busy":"2024-05-26T18:14:00.946009Z","iopub.status.idle":"2024-05-26T18:14:00.976900Z","shell.execute_reply":"2024-05-26T18:14:00.976073Z","shell.execute_reply.started":"2024-05-26T18:14:00.946299Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce405fd340cb4b5fa5bbe2584a357135","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login()\n","# 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"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:00.978392Z","iopub.status.busy":"2024-05-26T18:14:00.978117Z","iopub.status.idle":"2024-05-26T18:14:00.983900Z","shell.execute_reply":"2024-05-26T18:14:00.982899Z","shell.execute_reply.started":"2024-05-26T18:14:00.978367Z"},"trusted":true},"outputs":[],"source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""]},{"cell_type":"markdown","metadata":{},"source":["## download and prepare model's tokenizer"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:00.985307Z","iopub.status.busy":"2024-05-26T18:14:00.984964Z","iopub.status.idle":"2024-05-26T18:14:01.740345Z","shell.execute_reply":"2024-05-26T18:14:01.739315Z","shell.execute_reply.started":"2024-05-26T18:14:00.985282Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1995c3ac1494723a73df94c1f7f2782","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83dcf0c2f3804d5ea8a045b02ce32c72","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d7b7828a37e45beb97b33fc6c42a5b8","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f61ebd6336f4ae785dc2bbc42b14733","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"490f4314023740d0868fd3fe4fffc3c5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if any(k in model_name for k in (\"gpt\", \"opt\", \"bloom\")):\n","    padding_side = \"left\"\n","else:\n","    padding_side = \"right\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=padding_side, trust_remote_code=True)\n","if getattr(tokenizer, \"pad_token_id\") is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","\n","def tokenize_function(examples):\n","    # max_length=None => use the model max length (it's actually the default)\n","    outputs = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True, max_length=None)\n","    return outputs"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:01.742006Z","iopub.status.busy":"2024-05-26T18:14:01.741653Z","iopub.status.idle":"2024-05-26T18:14:09.694077Z","shell.execute_reply":"2024-05-26T18:14:09.693155Z","shell.execute_reply.started":"2024-05-26T18:14:01.741978Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ee3e113f38548a5b618d44a3b18e3d1","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/8.89k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214M/214M [00:01<00:00, 157MB/s]  \n","Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.94M/4.94M [00:00<00:00, 28.5MB/s]\n","Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.10M/5.10M [00:00<00:00, 49.3MB/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"615d1317b46a4f43a8c68089936cff43","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82eda53a27b249fa9994540c4bcd74d6","version_major":2,"version_minor":0},"text/plain":["Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93df420a76914c2291245308e4e0ff79","version_major":2,"version_minor":0},"text/plain":["Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = load_dataset(dataset_name, split=\"train[:10%]\")\n","val_mismatched_dataset = load_dataset(dataset_name, split=\"validation_mismatched[:10%]\")\n","val_matched_dataset = load_dataset(dataset_name, split=\"validation_matched[:10%]\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:09.695687Z","iopub.status.busy":"2024-05-26T18:14:09.695348Z","iopub.status.idle":"2024-05-26T18:14:09.701132Z","shell.execute_reply":"2024-05-26T18:14:09.699749Z","shell.execute_reply.started":"2024-05-26T18:14:09.695658Z"},"trusted":true},"outputs":[],"source":["remove_columns = ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre']"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:09.702938Z","iopub.status.busy":"2024-05-26T18:14:09.702599Z","iopub.status.idle":"2024-05-26T18:14:40.023148Z","shell.execute_reply":"2024-05-26T18:14:40.022215Z","shell.execute_reply.started":"2024-05-26T18:14:09.702906Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c49bebce0a94281a299b222b5c32c13","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/39270 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 39270\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets = train_dataset.map(tokenize_function, batched=True, remove_columns = remove_columns, batch_size=2)\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n","tokenized_datasets"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:40.024804Z","iopub.status.busy":"2024-05-26T18:14:40.024411Z","iopub.status.idle":"2024-05-26T18:14:41.752521Z","shell.execute_reply":"2024-05-26T18:14:41.751674Z","shell.execute_reply.started":"2024-05-26T18:14:40.024768Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86fbf060525944089493ed9f9d98f722","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/983 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_tokenized_datasets = val_mismatched_dataset.map(tokenize_function, batched=True, remove_columns = remove_columns, batch_size=2)\n","val_tokenized_datasets = val_tokenized_datasets.rename_column(\"label\", \"labels\")"]},{"cell_type":"markdown","metadata":{},"source":["# Section 2"]},{"cell_type":"markdown","metadata":{},"source":["## fine tune all parameters"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:41.756317Z","iopub.status.busy":"2024-05-26T18:14:41.756040Z","iopub.status.idle":"2024-05-26T18:14:42.094284Z","shell.execute_reply":"2024-05-26T18:14:42.093355Z","shell.execute_reply.started":"2024-05-26T18:14:41.756293Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a432a2d000814d969c81d03ef4321466","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["accuracy = evaluate.load(\"accuracy\")\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:42.097481Z","iopub.status.busy":"2024-05-26T18:14:42.097212Z","iopub.status.idle":"2024-05-26T18:14:52.385703Z","shell.execute_reply":"2024-05-26T18:14:52.384679Z","shell.execute_reply.started":"2024-05-26T18:14:42.097457Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"516d3451306f4ec783859ac08e5ed735","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["trainable model parameters: 355363844\n","all model parameters: 355363844\n","percentage of trainable model parameters: 100.00%\n"]}],"source":["base_model = RobertaForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=4\n",")\n","print(print_number_of_trainable_model_parameters(base_model))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:52.387835Z","iopub.status.busy":"2024-05-26T18:14:52.387471Z","iopub.status.idle":"2024-05-26T18:14:52.397214Z","shell.execute_reply":"2024-05-26T18:14:52.396181Z","shell.execute_reply.started":"2024-05-26T18:14:52.387801Z"},"trusted":true},"outputs":[{"data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n","  )\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["base_model"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T07:03:24.518067Z","iopub.status.busy":"2024-05-26T07:03:24.517707Z","iopub.status.idle":"2024-05-26T07:03:24.523873Z","shell.execute_reply":"2024-05-26T07:03:24.522820Z","shell.execute_reply.started":"2024-05-26T07:03:24.518038Z"},"trusted":true},"outputs":[],"source":["# import shutil\n","# shutil.rmtree(\"results\")\n","output_dir = \"results\"\n","os.mkdir(output_dir)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T07:03:26.140581Z","iopub.status.busy":"2024-05-26T07:03:26.139777Z","iopub.status.idle":"2024-05-26T08:19:48.434625Z","shell.execute_reply":"2024-05-26T08:19:48.433661Z","shell.execute_reply.started":"2024-05-26T07:03:26.140548Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='19635' max='19635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19635/19635 1:16:16, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.189100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.144200</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.158800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.171900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>1.165100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>1.170600</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>1.154800</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>1.153100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>1.141900</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>1.135900</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>1.129000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>1.124600</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>1.121000</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>1.117700</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>1.115300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>1.108400</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>1.107400</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>1.097200</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>1.108600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=19635, training_loss=1.1365086100136077, metrics={'train_runtime': 4577.2449, 'train_samples_per_second': 8.579, 'train_steps_per_second': 4.29, 'total_flos': 2927398212049248.0, 'train_loss': 1.1365086100136077, 'epoch': 1.0})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["EPOCHS=1\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    save_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=2,\n","    logging_steps= 1000,\n","    learning_rate= 2e-4,\n","    weight_decay= 0.01,\n","    fp16= False,\n","    bf16= False,\n","    max_grad_norm= 0.3,\n","    warmup_ratio= 0.3,\n","    group_by_length= True,\n","    lr_scheduler_type= \"linear\",\n",")\n","\n","trainer = transformers.Trainer(\n","    model=base_model,\n","    args=training_args,\n","    compute_metrics=compute_metrics, \n","    train_dataset=tokenized_datasets,\n","    eval_dataset=val_tokenized_datasets,\n","    data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",")\n","base_model.train()\n","trainer.train()\n","\n","# 4440f4c955c9751dc1828aaf1da0eaf84473d21e"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T08:19:48.436370Z","iopub.status.busy":"2024-05-26T08:19:48.436086Z","iopub.status.idle":"2024-05-26T08:20:00.384139Z","shell.execute_reply":"2024-05-26T08:20:00.382988Z","shell.execute_reply.started":"2024-05-26T08:19:48.436345Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='492' max='492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [492/492 00:11]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 1.0936452150344849,\n"," 'eval_accuracy': 0.3540183112919634,\n"," 'eval_runtime': 11.9329,\n"," 'eval_samples_per_second': 82.377,\n"," 'eval_steps_per_second': 41.231,\n"," 'epoch': 1.0}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["## fine tune with LORA"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:32:14.256576Z","iopub.status.busy":"2024-05-26T18:32:14.255837Z","iopub.status.idle":"2024-05-26T18:32:15.187726Z","shell.execute_reply":"2024-05-26T18:32:15.186662Z","shell.execute_reply.started":"2024-05-26T18:32:14.256542Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = RobertaForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=4\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### LoRA config"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:32:19.050538Z","iopub.status.busy":"2024-05-26T18:32:19.050133Z","iopub.status.idle":"2024-05-26T18:32:19.388496Z","shell.execute_reply":"2024-05-26T18:32:19.387511Z","shell.execute_reply.started":"2024-05-26T18:32:19.050507Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 2626564\n","all model parameters: 357990408\n","percentage of trainable model parameters: 0.73%\n"]}],"source":["peft_config = LoraConfig(\n","    lora_alpha= 8,\n","    lora_dropout= 0.1,\n","    r= 16,\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\"\n",")\n","\n","model = get_peft_model(model, peft_config)\n","print(print_number_of_trainable_model_parameters(model))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:32:29.966799Z","iopub.status.busy":"2024-05-26T18:32:29.965975Z","iopub.status.idle":"2024-05-26T18:32:29.979451Z","shell.execute_reply":"2024-05-26T18:32:29.978509Z","shell.execute_reply.started":"2024-05-26T18:32:29.966765Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForSequenceClassification(\n","  (base_model): LoraModel(\n","    (model): RobertaForSequenceClassification(\n","      (roberta): RobertaModel(\n","        (embeddings): RobertaEmbeddings(\n","          (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n","          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","          (token_type_embeddings): Embedding(1, 1024)\n","          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder): RobertaEncoder(\n","          (layer): ModuleList(\n","            (0-23): 24 x RobertaLayer(\n","              (attention): RobertaAttention(\n","                (self): RobertaSelfAttention(\n","                  (query): lora.Linear(\n","                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.1, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=1024, out_features=16, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=16, out_features=1024, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                  (value): lora.Linear(\n","                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.1, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=1024, out_features=16, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=16, out_features=1024, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): RobertaSelfOutput(\n","                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): RobertaIntermediate(\n","                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","                (intermediate_act_fn): GELUActivation()\n","              )\n","              (output): RobertaOutput(\n","                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (classifier): ModulesToSaveWrapper(\n","        (original_module): RobertaClassificationHead(\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n","        )\n","        (modules_to_save): ModuleDict(\n","          (default): RobertaClassificationHead(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"markdown","metadata":{},"source":["### training arguments and train"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T06:05:40.903598Z","iopub.status.busy":"2024-05-26T06:05:40.902945Z","iopub.status.idle":"2024-05-26T06:05:40.908273Z","shell.execute_reply":"2024-05-26T06:05:40.907340Z","shell.execute_reply.started":"2024-05-26T06:05:40.903561Z"},"trusted":true},"outputs":[],"source":["output_dir1 = \"results1\"\n","os.mkdir(output_dir1)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T06:05:40.910086Z","iopub.status.busy":"2024-05-26T06:05:40.909351Z","iopub.status.idle":"2024-05-26T06:35:25.965045Z","shell.execute_reply":"2024-05-26T06:35:25.964126Z","shell.execute_reply.started":"2024-05-26T06:05:40.910051Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_060701-j1suh4r3</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/univerityoftehran/huggingface/runs/j1suh4r3' target=\"_blank\">results1</a></strong> to <a href='https://wandb.ai/univerityoftehran/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/univerityoftehran/huggingface' target=\"_blank\">https://wandb.ai/univerityoftehran/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/univerityoftehran/huggingface/runs/j1suh4r3' target=\"_blank\">https://wandb.ai/univerityoftehran/huggingface/runs/j1suh4r3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='19635' max='19635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19635/19635 28:06, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.171700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.125300</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.091100</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.029100</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>1.010900</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.964900</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.967300</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.939100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.910900</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.859100</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.877200</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.820200</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.812600</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.777300</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.845300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.783200</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.749700</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.765900</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.736200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=19635, training_loss=0.9025281283944686, metrics={'train_runtime': 1779.7386, 'train_samples_per_second': 22.065, 'train_steps_per_second': 11.033, 'total_flos': 2952743903261376.0, 'train_loss': 0.9025281283944686, 'epoch': 1.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["EPOCHS=1\n","training_args = TrainingArguments(\n","    output_dir=output_dir1,\n","    save_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=2,\n","    logging_steps= 1000,\n","    learning_rate= 2e-4,\n","    weight_decay= 0.01,\n","    fp16= False,\n","    bf16= False,\n","    max_grad_norm= 0.3,\n","    warmup_ratio= 0.3,\n","    group_by_length= True,\n","    lr_scheduler_type= \"linear\",\n",")\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    args=training_args,\n","    compute_metrics=compute_metrics, \n","    train_dataset=tokenized_datasets,\n","    eval_dataset=val_tokenized_datasets,\n","    data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",")\n","model.train()\n","trainer.train()\n","\n","# 4440f4c955c9751dc1828aaf1da0eaf84473d21e"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T06:35:25.966429Z","iopub.status.busy":"2024-05-26T06:35:25.966157Z","iopub.status.idle":"2024-05-26T06:35:40.340302Z","shell.execute_reply":"2024-05-26T06:35:40.339331Z","shell.execute_reply.started":"2024-05-26T06:35:25.966404Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='492' max='492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [492/492 00:14]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.7070769667625427,\n"," 'eval_accuracy': 0.8677517802644964,\n"," 'eval_runtime': 14.3591,\n"," 'eval_samples_per_second': 68.458,\n"," 'eval_steps_per_second': 34.264,\n"," 'epoch': 1.0}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["## fine tune using P-Tuning"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T07:02:56.727759Z","iopub.status.busy":"2024-05-26T07:02:56.727369Z","iopub.status.idle":"2024-05-26T07:02:56.733350Z","shell.execute_reply":"2024-05-26T07:02:56.732267Z","shell.execute_reply.started":"2024-05-26T07:02:56.727722Z"},"trusted":true},"outputs":[],"source":["output_dir2 = \"results2\"\n","os.mkdir(output_dir2)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:53.363602Z","iopub.status.busy":"2024-05-26T18:14:53.363343Z","iopub.status.idle":"2024-05-26T18:14:54.658498Z","shell.execute_reply":"2024-05-26T18:14:54.657517Z","shell.execute_reply.started":"2024-05-26T18:14:53.363580Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["trainable model parameters: 1353988\n","all model parameters: 356717832\n","percentage of trainable model parameters: 0.38%\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", \n","                                  num_virtual_tokens=20, \n","                                  encoder_hidden_size=128, \n","                                  encoder_dropout=0.1)\n","model_p = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    return_dict=True,\n","    num_labels=4\n",")\n","\n","model_p = get_peft_model(model_p, peft_config)\n","print(print_number_of_trainable_model_parameters(model_p))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T18:14:54.660591Z","iopub.status.busy":"2024-05-26T18:14:54.660205Z","iopub.status.idle":"2024-05-26T18:14:54.670542Z","shell.execute_reply":"2024-05-26T18:14:54.669184Z","shell.execute_reply.started":"2024-05-26T18:14:54.660555Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForSequenceClassification(\n","  (base_model): RobertaForSequenceClassification(\n","    (roberta): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n","        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","        (token_type_embeddings): Embedding(1, 1024)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): RobertaEncoder(\n","        (layer): ModuleList(\n","          (0-23): 24 x RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (classifier): ModulesToSaveWrapper(\n","      (original_module): RobertaClassificationHead(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n","      )\n","      (modules_to_save): ModuleDict(\n","        (default): RobertaClassificationHead(\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n","        )\n","      )\n","    )\n","  )\n","  (prompt_encoder): ModuleDict(\n","    (default): PromptEncoder(\n","      (embedding): Embedding(20, 1024)\n","      (mlp_head): Sequential(\n","        (0): Linear(in_features=1024, out_features=128, bias=True)\n","        (1): ReLU()\n","        (2): Linear(in_features=128, out_features=128, bias=True)\n","        (3): ReLU()\n","        (4): Linear(in_features=128, out_features=1024, bias=True)\n","      )\n","    )\n","  )\n","  (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model_p"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T06:41:41.167019Z","iopub.status.busy":"2024-05-26T06:41:41.166159Z","iopub.status.idle":"2024-05-26T07:02:29.271825Z","shell.execute_reply":"2024-05-26T07:02:29.270880Z","shell.execute_reply.started":"2024-05-26T06:41:41.166984Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='19635' max='19635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19635/19635 20:42, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.184700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.129100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.144800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.148900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>1.159300</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>1.176800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>1.168000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>1.165600</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>1.160600</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>1.143800</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>1.133300</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>1.120800</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>1.124200</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>1.116200</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>1.115800</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>1.121800</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>1.114300</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>1.100900</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>1.110300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=19635, training_loss=1.1377316382874172, metrics={'train_runtime': 1243.0221, 'train_samples_per_second': 31.592, 'train_steps_per_second': 15.796, 'total_flos': 2937566155731648.0, 'train_loss': 1.1377316382874172, 'epoch': 1.0})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["EPOCHS=1\n","training_args = TrainingArguments(\n","    output_dir=output_dir2,\n","    save_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=2,\n","    logging_steps= 1000,\n","    learning_rate= 2e-4,\n","    weight_decay= 0.01,\n","    fp16= False,\n","    bf16= False,\n","    max_grad_norm= 0.3,\n","    warmup_ratio= 0.3,\n","    group_by_length= True,\n","    lr_scheduler_type= \"linear\",\n",")\n","\n","trainer = transformers.Trainer(\n","    model=model_p,\n","    args=training_args,\n","    compute_metrics=compute_metrics, \n","    train_dataset=tokenized_datasets,\n","    eval_dataset=val_tokenized_datasets,\n","    data_collator=transformers.DataCollatorWithPadding(tokenizer,  padding=\"longest\"),\n",")\n","model_p.train()\n","trainer.train()\n","\n","# 4440f4c955c9751dc1828aaf1da0eaf84473d21e"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T07:02:29.274601Z","iopub.status.busy":"2024-05-26T07:02:29.273775Z","iopub.status.idle":"2024-05-26T07:02:43.585365Z","shell.execute_reply":"2024-05-26T07:02:43.584429Z","shell.execute_reply.started":"2024-05-26T07:02:29.274565Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='492' max='492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [492/492 00:14]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 1.1008752584457397,\n"," 'eval_accuracy': 0.3326551373346897,\n"," 'eval_runtime': 14.296,\n"," 'eval_samples_per_second': 68.76,\n"," 'eval_steps_per_second': 34.415,\n"," 'epoch': 1.0}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
