{"cells":[{"cell_type":"markdown","metadata":{"id":"lmcGUiPT5k_J"},"source":["# Section 1: prepare packages and dataset"]},{"cell_type":"markdown","metadata":{"id":"sQ9kejmc5k_O"},"source":["## install and import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-31T08:48:28.217944Z","iopub.status.busy":"2024-05-31T08:48:28.217548Z","iopub.status.idle":"2024-05-31T08:52:53.701382Z","shell.execute_reply":"2024-05-31T08:52:53.700145Z","shell.execute_reply.started":"2024-05-31T08:48:28.217904Z"},"executionInfo":{"elapsed":178515,"status":"ok","timestamp":1716532350376,"user":{"displayName":"Zahra Reyhanian","userId":"14846256199972630626"},"user_tz":-210},"id":"lyZj-pcn5k_P","outputId":"9cf8506f-0319-49c5-cf9d-bc2fd3881d62","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q trl xformers wandb datasets sentencepiece bitsandbytes evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:52:53.704382Z","iopub.status.busy":"2024-05-31T08:52:53.704009Z","iopub.status.idle":"2024-05-31T08:53:49.548190Z","shell.execute_reply":"2024-05-31T08:53:49.547215Z","shell.execute_reply.started":"2024-05-31T08:52:53.704344Z"},"id":"S2b1177O5k_R","outputId":"15f3966c-2795-4480-a48a-a803aac75ad8","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: torch 2.3.0\n","Uninstalling torch-2.3.0:\n","  Successfully uninstalled torch-2.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xformers 0.0.26.post1 requires torch==2.3.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip uninstall torch -y\n","!pip install -q torch==2.1"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:53:49.549798Z","iopub.status.busy":"2024-05-31T08:53:49.549496Z","iopub.status.idle":"2024-05-31T08:54:43.786944Z","shell.execute_reply":"2024-05-31T08:54:43.785839Z","shell.execute_reply.started":"2024-05-31T08:53:49.549770Z"},"id":"XYOu9wuh5k_S","outputId":"e754f963-88e3-4c68-9a75-4b539718a352","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q --upgrade torch torchvision"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:54:43.789820Z","iopub.status.busy":"2024-05-31T08:54:43.789508Z","iopub.status.idle":"2024-05-31T08:55:02.884119Z","shell.execute_reply":"2024-05-31T08:55:02.883331Z","shell.execute_reply.started":"2024-05-31T08:54:43.789791Z"},"id":"N6iEMCEU5k_S","outputId":"9a9956ec-f65d-4919-8667-b74bea77abb2","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-31 08:54:53.003286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-31 08:54:53.003424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-31 08:54:53.130990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n","from transformers import PreTrainedModel, PretrainedConfig\n","from transformers import AutoModel, AutoConfig\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model, PromptEncoderConfig\n","import os,torch, wandb, platform, warnings\n","from datasets import load_dataset, load_metric, Dataset\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","from transformers import AdamW,get_scheduler\n","from tqdm.notebook import tqdm_notebook\n","from trl import SFTTrainer\n","from sklearn.metrics import accuracy_score, classification_report\n","from torch import nn\n","import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import transformers\n","import evaluate\n","import time\n","\n","from huggingface_hub import notebook_login\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","compute_dtype = getattr(torch, \"float16\")"]},{"cell_type":"markdown","metadata":{"id":"kFjvAwPM5k_T"},"source":["## define the model and the dataset path"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:55:02.885637Z","iopub.status.busy":"2024-05-31T08:55:02.885088Z","iopub.status.idle":"2024-05-31T08:55:02.891752Z","shell.execute_reply":"2024-05-31T08:55:02.890875Z","shell.execute_reply.started":"2024-05-31T08:55:02.885612Z"},"id":"RhvCivoQ5k_T","trusted":true},"outputs":[],"source":["model_name = \"meta-llama/Meta-Llama-3-8B\"\n","\n","dataset_name = \"nyu-mll/multi_nli\""]},{"cell_type":"markdown","metadata":{"id":"Ul0c2Dp65k_T"},"source":["## login to huggingface"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"referenced_widgets":["d26a0c5697ca47cd884c04b87413991f"]},"execution":{"iopub.execute_input":"2024-05-31T08:55:02.893128Z","iopub.status.busy":"2024-05-31T08:55:02.892818Z","iopub.status.idle":"2024-05-31T08:55:04.956999Z","shell.execute_reply":"2024-05-31T08:55:04.956074Z","shell.execute_reply.started":"2024-05-31T08:55:02.893104Z"},"id":"Mx4ExXSv5k_U","outputId":"8f8c2d4b-7e3c-47bb-91df-fd1555c2bd16","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9c802c5c4c74da3978e5f66312d25aa","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login()\n","token='YOUR-TOKEN'"]},{"cell_type":"markdown","metadata":{"id":"jMRfmLTF5k_U"},"source":["## download and prepare model's tokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"referenced_widgets":["8bb6761eb7a64b988cfd2a46fb854098","5e18e21c0e2047209049ecf7a02189e0","a53ddefc72c54c9e8cbf33f0e00c0d63","c452ac86126f44c7a5e39eef1dbeca8b","9fcbb88f00554c83b05ab6ff9f0dea9e"]},"execution":{"iopub.execute_input":"2024-05-31T08:55:04.958433Z","iopub.status.busy":"2024-05-31T08:55:04.958149Z","iopub.status.idle":"2024-05-31T08:55:08.257984Z","shell.execute_reply":"2024-05-31T08:55:08.257124Z","shell.execute_reply.started":"2024-05-31T08:55:04.958410Z"},"id":"Z3bbnoTi5k_U","outputId":"161ae3d2-6605-4ac6-8a09-c0f1fa123e99","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc3e321e3686478baa9d8d65bdb0aa72","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f28917134967434e9aa0be053ecece10","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78450c1a096d420c9a1b29164c117366","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["if any(k in model_name for k in (\"gpt\", \"opt\", \"bloom\")):\n","    padding_side = \"left\"\n","else:\n","    padding_side = \"right\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=padding_side, trust_remote_code=True, token=token)\n","if getattr(tokenizer, \"pad_token_id\") is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"markdown","metadata":{},"source":["## download dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"referenced_widgets":["93d98835909948b5b222f09bab2aa0f5","109f3a66536146b4baf4195ed0660ad3","0bf107990bf6465e983c1abf676c5f29","fb1bc694241f49b59f107e04148c42af"]},"execution":{"iopub.execute_input":"2024-05-31T08:55:08.259292Z","iopub.status.busy":"2024-05-31T08:55:08.259041Z","iopub.status.idle":"2024-05-31T08:55:29.124209Z","shell.execute_reply":"2024-05-31T08:55:29.123290Z","shell.execute_reply.started":"2024-05-31T08:55:08.259269Z"},"id":"V2VVdhbx5k_V","outputId":"5f45f861-454a-4e33-f8d3-374a0ddc3e60","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4f62218d6ba4756a3525bda5ff8fbac","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/8.89k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214M/214M [00:04<00:00, 52.5MB/s] \n","Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.94M/4.94M [00:00<00:00, 17.3MB/s]\n","Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.10M/5.10M [00:00<00:00, 14.4MB/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0116cef2fa9427da63534840a50b36c","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5e40d1ed8a447639d197c2efcda3995","version_major":2,"version_minor":0},"text/plain":["Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"618259a388544988ab517fafca288900","version_major":2,"version_minor":0},"text/plain":["Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = load_dataset(dataset_name, split=\"train[:10%]\")\n","val_mismatched_dataset = load_dataset(dataset_name, split=\"validation_mismatched[:40%]\")"]},{"cell_type":"markdown","metadata":{},"source":["# Section 1: prompting"]},{"cell_type":"markdown","metadata":{},"source":["## evaluation function"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate(y_true, y_pred):    \n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy:.3f}')\n","    \n","    report = classification_report(y_true, y_pred)\n","    print('Classification Report:')\n","    print(report)"]},{"cell_type":"markdown","metadata":{},"source":["## generate_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def generate_prompt_for_training(example):\n","    return f'''\n","Classify the following sentence pairs into entailment (0), neutral (1), contradiction (2). \n","{example['premise']} SEP {example['hypothesis']}\n","Label = {example['label']}'''.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def generate_prompt(premise, hypothesis):\n","    return f'''\n","Classify the following sentence pairs into entailment (0), neutral (1), contradiction (2). \n","{premise} SEP {hypothesis}\n","Label ='''.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset[44]\n","#3 10 11 15 16 21 23 44"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def generate_prompt_one_shot(premise, hypothesis):\n","    example = train_dataset[44]\n","    premise0 = example['premise']\n","    hypothesis0 = example['hypothesis']\n","    label0 = example['label']\n","    return f'''\n","Classify the following sentence pairs into entailment (0), neutral (1), contradiction (2):\n","{premise0} SEP {hypothesis0}\n","Label = {label0}\n","Now classify the following pairs:\n","{premise} SEP {hypothesis}\n","Label ='''.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict(model, val_dataset, prompt_generator, tokenizer, i=-1, max_new_tokens=16, temprature=0.1):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    for sample in tqdm_notebook(val_dataset):\n","        with torch.no_grad():\n","            premise = sample['premise']\n","            hypothesis = sample['hypothesis']\n","            real_label = sample['label']\n","            y_true.append(real_label)\n","            prompt = prompt_generator(premise, hypothesis)\n","\n","            inputs = tokenizer(prompt, return_tensors=\"pt\")\n","            tokens = model.generate(\n","                **inputs,\n","                max_new_tokens=max_new_tokens,\n","                temperature=temprature,\n","                do_sample=True,\n","                pad_token_id=tokenizer.eos_token_id\n","            )\n","\n","            answer = tokenizer.decode(tokens[0], skip_special_tokens=True).split('=')[i]\n","            num = re.search(r'\\d', answer)\n","            if num!=None:\n","                num=num.group()\n","                y_pred.append(int(num))\n","            else:\n","                y_pred.append(-1)\n","\n","    return y_true, y_pred"]},{"cell_type":"markdown","metadata":{},"source":["## load model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T15:01:19.158932Z","iopub.status.busy":"2024-05-29T15:01:19.158484Z","iopub.status.idle":"2024-05-29T15:03:04.511975Z","shell.execute_reply":"2024-05-29T15:03:04.510968Z","shell.execute_reply.started":"2024-05-29T15:01:19.158903Z"},"id":"D0sc-UB1g1SC","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a10a78c0e752472eb67051ad19a28f36","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cea91dad92e410eaffad9af2c8fa12c","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0db8788524c41518ae43eb0448b48bc","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b0455eaf1d8413a878cc7a8cfc0a140","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19960189d56541ac8f730da0fd91e930","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38cc449e99bb4ef2a0874c5ae3c7dd8c","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4aa6110bcf10444f9e1fa70f59e43fcf","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85e65599fdca4849b633d4eda9196ed0","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2561c88d7e934db9b5903e29457dfada","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=device,\n","    torch_dtype=compute_dtype,\n","    quantization_config=bnb_config, \n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"markdown","metadata":{"id":"0795FhtVg4XN"},"source":["## zero-shot"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T15:03:04.513644Z","iopub.status.busy":"2024-05-29T15:03:04.513381Z","iopub.status.idle":"2024-05-29T16:10:19.106630Z","shell.execute_reply":"2024-05-29T16:10:19.105666Z","shell.execute_reply.started":"2024-05-29T15:03:04.513622Z"},"id":"7tpH3WeFg9Hs","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a9e662bda8343bd99505f1d48b28a63","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3933 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1725: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","\n","  warnings.warn(\n"]}],"source":["y_true, y_pred = predict(model, val_mismatched_dataset, generate_prompt, tokenizer)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T16:10:19.109547Z","iopub.status.busy":"2024-05-29T16:10:19.109245Z","iopub.status.idle":"2024-05-29T16:10:19.140250Z","shell.execute_reply":"2024-05-29T16:10:19.139258Z","shell.execute_reply.started":"2024-05-29T16:10:19.109522Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.427\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","\n","\n","          -1       0.00      0.00      0.00         0\n","\n","           0       0.41      0.72      0.52      1435\n","\n","           1       0.31      0.09      0.13      1191\n","\n","           2       0.60      0.42      0.49      1307\n","\n","           8       0.00      0.00      0.00         0\n","\n","\n","\n","    accuracy                           0.43      3933\n","\n","   macro avg       0.26      0.24      0.23      3933\n","\n","weighted avg       0.44      0.43      0.39      3933\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["evaluate(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"3s0czW__g9Tl"},"source":["## one-shot"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T16:16:54.806613Z","iopub.status.busy":"2024-05-29T16:16:54.805968Z","iopub.status.idle":"2024-05-29T17:59:49.399348Z","shell.execute_reply":"2024-05-29T17:59:49.398346Z","shell.execute_reply.started":"2024-05-29T16:16:54.806583Z"},"id":"QpjfMaIehAPy","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd12860f3fd74e61a258ddde463e8ca8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3933 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1725: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","\n","  warnings.warn(\n"]}],"source":["y_true, y_pred=predict(model, val_mismatched_dataset, generate_prompt_one_shot, tokenizer, i=2)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T17:59:49.401400Z","iopub.status.busy":"2024-05-29T17:59:49.401053Z","iopub.status.idle":"2024-05-29T17:59:49.423663Z","shell.execute_reply":"2024-05-29T17:59:49.422715Z","shell.execute_reply.started":"2024-05-29T17:59:49.401357Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.457\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","\n","\n","          -1       0.00      0.00      0.00         0\n","\n","           0       0.68      0.03      0.05      1435\n","\n","           1       0.35      0.88      0.50      1191\n","\n","           2       0.78      0.55      0.64      1307\n","\n","\n","\n","    accuracy                           0.46      3933\n","\n","   macro avg       0.45      0.36      0.30      3933\n","\n","weighted avg       0.62      0.46      0.39      3933\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["evaluate(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"EZ372X2y5k_Z"},"source":["# Section2: Fine tune with QLORA"]},{"cell_type":"markdown","metadata":{},"source":["## load model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T14:27:41.666411Z","iopub.status.busy":"2024-05-30T14:27:41.665766Z","iopub.status.idle":"2024-05-30T14:29:28.870008Z","shell.execute_reply":"2024-05-30T14:29:28.869231Z","shell.execute_reply.started":"2024-05-30T14:27:41.666378Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f4e57f8a3074700bd2c8316b600a74d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"054e80f879f647f2917e5b81562fb29e","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56682076430a4c5ea660aef8896304f9","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b3253bd9bb2442bb101a0fcef1da82c","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a5624381daf417583ae905fcb005ddd","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41456ab6ebb141a69af75d8a334bf515","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33432162dd074232985be846e319bdcd","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"940a38e9d02c4de5bf05f12a13b35908","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcb1d73c79a5492486d968c3ea6226f1","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=device,\n","    token=token,\n","    torch_dtype=compute_dtype,\n","    quantization_config=bnb_config, \n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T18:12:44.334100Z","iopub.status.busy":"2024-05-29T18:12:44.333806Z","iopub.status.idle":"2024-05-29T18:12:44.385396Z","shell.execute_reply":"2024-05-29T18:12:44.384523Z","shell.execute_reply.started":"2024-05-29T18:12:44.334075Z"},"trusted":true},"outputs":[{"data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm()\n","        (post_attention_layernorm): LlamaRMSNorm()\n","      )\n","    )\n","    (norm): LlamaRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model = prepare_model_for_kbit_training(model)\n","model"]},{"cell_type":"markdown","metadata":{"id":"_Xe-WawA5k_e"},"source":["## LoRA config"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T18:12:44.386928Z","iopub.status.busy":"2024-05-29T18:12:44.386578Z","iopub.status.idle":"2024-05-29T18:12:46.159990Z","shell.execute_reply":"2024-05-29T18:12:46.159062Z","shell.execute_reply.started":"2024-05-29T18:12:44.386898Z"},"id":"J1M1WQQ45k_e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 130,023,424 || all params: 8,160,284,672 || trainable%: 1.5934\n"]}],"source":["from peft import LoraConfig, get_peft_model\n","\n","peft_config = LoraConfig(\n","    lora_alpha= 16,\n","    lora_dropout= 0.1,\n","    r= 64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",")\n","\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"markdown","metadata":{},"source":["## preprocess data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["temp = pd.DataFrame(train_dataset).apply(generate_prompt_for_training, axis=1)\n","train_data = pd.DataFrame(temp, columns=['text'])\n","\n","train_data = Dataset.from_pandas(train_data)"]},{"cell_type":"markdown","metadata":{"id":"oyPvmOyl5k_f"},"source":["## training arguments and train"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T18:12:52.320146Z","iopub.status.busy":"2024-05-29T18:12:52.319790Z","iopub.status.idle":"2024-05-29T18:12:52.324872Z","shell.execute_reply":"2024-05-29T18:12:52.323896Z","shell.execute_reply.started":"2024-05-29T18:12:52.320115Z"},"trusted":true},"outputs":[],"source":["output_dir = \"results\"\n","os.mkdir(output_dir)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T18:12:52.326301Z","iopub.status.busy":"2024-05-29T18:12:52.325952Z","iopub.status.idle":"2024-05-29T18:12:57.819974Z","shell.execute_reply":"2024-05-29T18:12:57.819039Z","shell.execute_reply.started":"2024-05-29T18:12:52.326276Z"},"id":"F0pbUF415k_f","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1740949ce2c41f9996c1286e919d945","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/39270 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["EPOCHS=1\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    save_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    logging_steps= 30,\n","    max_steps=1000,\n","    warmup_steps=4,\n","    warmup_ratio=0.03,\n","    learning_rate=2e-4,\n","    weight_decay= 0.001,\n","    fp16= False,\n","    bf16= False,\n","    max_grad_norm= 0.3,\n","    group_by_length= False,\n","    optim=\"paged_adamw_8bit\",\n","    lr_scheduler_type= \"constant\",\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    dataset_text_field=\"text\",\n","    packing=False,\n","    dataset_kwargs={\n","        \"add_special_tokens\": False,\n","        \"append_concat_token\": False,\n","    },\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T18:12:57.821902Z","iopub.status.busy":"2024-05-29T18:12:57.821244Z","iopub.status.idle":"2024-05-29T19:52:30.359243Z","shell.execute_reply":"2024-05-29T19:52:30.358302Z","shell.execute_reply.started":"2024-05-29T18:12:57.821865Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240529_181619-h5rh1384</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/univerityoftehran/huggingface/runs/h5rh1384' target=\"_blank\">results</a></strong> to <a href='https://wandb.ai/univerityoftehran/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/univerityoftehran/huggingface' target=\"_blank\">https://wandb.ai/univerityoftehran/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/univerityoftehran/huggingface/runs/h5rh1384' target=\"_blank\">https://wandb.ai/univerityoftehran/huggingface/runs/h5rh1384</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 1:35:46, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>30</td>\n","      <td>2.142200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.678400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.665900</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.678800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.649700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.653400</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.563000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.655700</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.575700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.592400</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.634300</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.565200</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.602300</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.614600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.650100</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.564000</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.608000</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.605200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.571800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.608100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>1.610700</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>1.639700</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>1.624400</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>1.588500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.601700</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>1.575100</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>1.540300</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>1.628800</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>1.638200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.600800</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>1.602300</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>1.601400</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>1.567000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=1000, training_loss=1.6257954626083373, metrics={'train_runtime': 5972.0023, 'train_samples_per_second': 0.67, 'train_steps_per_second': 0.167, 'total_flos': 1.1285629067894784e+16, 'train_loss': 1.6257954626083373, 'epoch': 0.10185892538833716})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model.train()\n","trainer.train()\n","\n","# 4440f4c955c9751dc1828aaf1da0eaf84473d21e"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T19:52:34.047820Z","iopub.status.busy":"2024-05-29T19:52:34.047440Z","iopub.status.idle":"2024-05-29T19:52:56.628610Z","shell.execute_reply":"2024-05-29T19:52:56.627661Z","shell.execute_reply.started":"2024-05-29T19:52:34.047790Z"},"id":"kaVwQVB_5k_f","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n","\n","  warnings.warn(\n"]}],"source":["model = model.merge_and_unload()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T19:53:01.371772Z","iopub.status.busy":"2024-05-29T19:53:01.371409Z","iopub.status.idle":"2024-05-29T20:41:30.978496Z","shell.execute_reply":"2024-05-29T20:41:30.977453Z","shell.execute_reply.started":"2024-05-29T19:53:01.371744Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c70994bfc8914d48a8a7c647ff115bee","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3933 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1725: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","\n","  warnings.warn(\n"]}],"source":["y_true, y_pred = predict(model, val_mismatched_dataset, generate_prompt, tokenizer)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T20:41:30.980835Z","iopub.status.busy":"2024-05-29T20:41:30.980449Z","iopub.status.idle":"2024-05-29T20:41:31.013142Z","shell.execute_reply":"2024-05-29T20:41:31.012085Z","shell.execute_reply.started":"2024-05-29T20:41:30.980798Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.479\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","\n","\n","          -1       0.00      0.00      0.00         0\n","\n","           0       0.73      0.31      0.43      1435\n","\n","           1       0.39      0.17      0.24      1191\n","\n","           2       0.46      0.95      0.62      1307\n","\n","\n","\n","    accuracy                           0.48      3933\n","\n","   macro avg       0.39      0.36      0.32      3933\n","\n","weighted avg       0.54      0.48      0.43      3933\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["evaluate(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["# Section 3: fine tune with QLORA (part II)"]},{"cell_type":"markdown","metadata":{},"source":["## create custom model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:55:29.126075Z","iopub.status.busy":"2024-05-31T08:55:29.125626Z","iopub.status.idle":"2024-05-31T08:55:29.131647Z","shell.execute_reply":"2024-05-31T08:55:29.130582Z","shell.execute_reply.started":"2024-05-31T08:55:29.126036Z"},"trusted":true},"outputs":[],"source":["class MyConfig(PretrainedConfig):\n","    model_type = 'mymodel'\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:55:29.134110Z","iopub.status.busy":"2024-05-31T08:55:29.133837Z","iopub.status.idle":"2024-05-31T08:55:29.167254Z","shell.execute_reply":"2024-05-31T08:55:29.166368Z","shell.execute_reply.started":"2024-05-31T08:55:29.134086Z"},"trusted":true},"outputs":[],"source":["class CustomLLamaModel(PreTrainedModel):\n","    config_class = MyConfig\n","    def __init__(self, config, model, num_labels): \n","        super().__init__(config) \n","        self.config = config\n","        self.num_labels = num_labels \n","\n","        #Load Model \n","        self.model = model = model\n","        self.input_dim = model.config.vocab_size\n","        self.dropout = nn.Dropout(0.1) \n","        self.classifier = nn.Linear(self.input_dim, self.num_labels) # load and initialize weights\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, return_dict=None, **kwargs):\n","        #Extract outputs from the body\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        #Add custom layers\n","        sequence_output = self.dropout(outputs[0]) \n","        \n","        logits = self.classifier(sequence_output[:,0,:]) \n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(labels.shape[0], self.num_labels), labels)\n","\n","        return {\"loss\":loss, \"logits\":logits}"]},{"cell_type":"markdown","metadata":{},"source":["## load model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T08:55:29.168613Z","iopub.status.busy":"2024-05-31T08:55:29.168288Z","iopub.status.idle":"2024-05-31T09:02:25.558053Z","shell.execute_reply":"2024-05-31T09:02:25.557288Z","shell.execute_reply.started":"2024-05-31T08:55:29.168581Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62d89ada09624c7a8137ae9497dc7b80","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4c5bbd27d484a738f8731450323e94f","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"599ed41a203e4d0e89dabac65cadeecf","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"775bc96f867344bc99ecb74c94f9f8ce","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcdcdfeaee3a4e31a52768eabefea063","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbd2d7a373e149ebbeebe18c47f77e20","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb009a6f3f3e472c804d96ae6b47580e","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1f9fc4f74b04df19d4b6ced15ee2b0f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b56018934d7243908fbc868ff56881da","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    token=token,\n","    device_map='auto',\n","    torch_dtype=compute_dtype,\n","    quantization_config=bnb_config, \n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:02:25.560186Z","iopub.status.busy":"2024-05-31T09:02:25.559897Z","iopub.status.idle":"2024-05-31T09:02:25.583996Z","shell.execute_reply":"2024-05-31T09:02:25.583237Z","shell.execute_reply.started":"2024-05-31T09:02:25.560161Z"},"trusted":true},"outputs":[],"source":["config = MyConfig()\n","custom_model = CustomLLamaModel(config,model, num_labels=3)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:02:25.585271Z","iopub.status.busy":"2024-05-31T09:02:25.585001Z","iopub.status.idle":"2024-05-31T09:02:25.665642Z","shell.execute_reply":"2024-05-31T09:02:25.664839Z","shell.execute_reply.started":"2024-05-31T09:02:25.585247Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CustomLLamaModel(\n","  (model): LlamaForCausalLM(\n","    (model): LlamaModel(\n","      (embed_tokens): Embedding(128256, 4096)\n","      (layers): ModuleList(\n","        (0-31): 32 x LlamaDecoderLayer(\n","          (self_attn): LlamaSdpaAttention(\n","            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","            (rotary_emb): LlamaRotaryEmbedding()\n","          )\n","          (mlp): LlamaMLP(\n","            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","            (act_fn): SiLU()\n","          )\n","          (input_layernorm): LlamaRMSNorm()\n","          (post_attention_layernorm): LlamaRMSNorm()\n","        )\n","      )\n","      (norm): LlamaRMSNorm()\n","    )\n","    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=128256, out_features=3, bias=True)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["custom_model = prepare_model_for_kbit_training(custom_model)\n","custom_model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:02:25.666923Z","iopub.status.busy":"2024-05-31T09:02:25.666660Z","iopub.status.idle":"2024-05-31T09:02:27.476557Z","shell.execute_reply":"2024-05-31T09:02:27.475560Z","shell.execute_reply.started":"2024-05-31T09:02:25.666896Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 130,408,195 || all params: 8,161,054,214 || trainable%: 1.5979\n"]}],"source":["peft_config = LoraConfig(\n","    lora_alpha= 16,\n","    lora_dropout= 0.1,\n","    r= 64,\n","    bias=\"none\",\n","    task_type=\"SEQ_CLS\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",")\n","\n","custom_model = get_peft_model(custom_model, peft_config)\n","custom_model.print_trainable_parameters()"]},{"cell_type":"markdown","metadata":{},"source":["## preprocess dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:02:27.478564Z","iopub.status.busy":"2024-05-31T09:02:27.478008Z","iopub.status.idle":"2024-05-31T09:02:27.484336Z","shell.execute_reply":"2024-05-31T09:02:27.483624Z","shell.execute_reply.started":"2024-05-31T09:02:27.478531Z"},"trusted":true},"outputs":[],"source":["def tokenize_function(examples):\n","    # max_length=None => use the model max length (it's actually the default)\n","    outputs = tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True, max_length=None)\n","    return outputs\n","\n","remove_columns = ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre']"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:02:27.487116Z","iopub.status.busy":"2024-05-31T09:02:27.486799Z","iopub.status.idle":"2024-05-31T09:03:14.166258Z","shell.execute_reply":"2024-05-31T09:03:14.165258Z","shell.execute_reply.started":"2024-05-31T09:02:27.487092Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fef9d5da78d44e819c10b16b422ffd93","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/39270 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['labels', 'input_ids', 'attention_mask'],\n","    num_rows: 39270\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets = train_dataset.map(tokenize_function, batched=True, remove_columns = remove_columns, batch_size=1)\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n","tokenized_datasets"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:03:14.167720Z","iopub.status.busy":"2024-05-31T09:03:14.167422Z","iopub.status.idle":"2024-05-31T09:03:19.217290Z","shell.execute_reply":"2024-05-31T09:03:19.216380Z","shell.execute_reply.started":"2024-05-31T09:03:14.167694Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db98bb036907406aa00d36f70d6d967c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3933 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_tokenized_datasets = val_mismatched_dataset.map(tokenize_function, batched=True, remove_columns = remove_columns, batch_size=1)\n","val_tokenized_datasets = val_tokenized_datasets.rename_column(\"label\", \"labels\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:03:19.219705Z","iopub.status.busy":"2024-05-31T09:03:19.219354Z","iopub.status.idle":"2024-05-31T09:03:19.226803Z","shell.execute_reply":"2024-05-31T09:03:19.226043Z","shell.execute_reply.started":"2024-05-31T09:03:19.219672Z"},"trusted":true},"outputs":[],"source":["data_collator=transformers.DataCollatorWithPadding(tokenizer, padding=True, max_length=120)\n","train_dataloader = DataLoader(\n","    tokenized_datasets, shuffle=True, batch_size=1, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    val_tokenized_datasets, batch_size=2, collate_fn=data_collator\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## train model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T10:31:07.294162Z","iopub.status.busy":"2024-05-31T10:31:07.293752Z","iopub.status.idle":"2024-05-31T10:31:08.249480Z","shell.execute_reply":"2024-05-31T10:31:08.248711Z","shell.execute_reply.started":"2024-05-31T10:31:07.294130Z"},"trusted":true},"outputs":[],"source":["metric = load_metric(\"accuracy\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:03:21.593397Z","iopub.status.busy":"2024-05-31T09:03:21.593144Z","iopub.status.idle":"2024-05-31T09:03:21.611334Z","shell.execute_reply":"2024-05-31T09:03:21.610499Z","shell.execute_reply.started":"2024-05-31T09:03:21.593374Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(custom_model.parameters(), lr=2e-5)\n","num_epochs=1\n","num_training_steps=5000\n","log_step=100\n","\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=1000,\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:03:21.613313Z","iopub.status.busy":"2024-05-31T09:03:21.612623Z","iopub.status.idle":"2024-05-31T09:03:21.639404Z","shell.execute_reply":"2024-05-31T09:03:21.638557Z","shell.execute_reply.started":"2024-05-31T09:03:21.613279Z"},"trusted":true},"outputs":[],"source":["custom_model = custom_model.to(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T09:03:21.641360Z","iopub.status.busy":"2024-05-31T09:03:21.640471Z","iopub.status.idle":"2024-05-31T10:11:33.177650Z","shell.execute_reply":"2024-05-31T10:11:33.176718Z","shell.execute_reply.started":"2024-05-31T09:03:21.641327Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70c862c07f2f4cfeb933626dcde6d429","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2724: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["step 100 loss= 1.1972627639770508\n","step 200 loss= 4.992378234863281\n","step 300 loss= 4.608397960662842\n","step 400 loss= 2.3926708698272705\n","step 500 loss= 0.3174169659614563\n","step 600 loss= 1.5125761032104492\n","step 700 loss= 1.8707401752471924\n","step 800 loss= 1.789634346961975\n","step 900 loss= 1.0456010103225708\n","step 1000 loss= 1.2383553981781006\n","step 1100 loss= 1.6074318885803223\n","step 1200 loss= 0.9824433922767639\n","step 1300 loss= 1.1715129613876343\n","step 1400 loss= 0.7716953754425049\n","step 1500 loss= 1.0802257061004639\n","step 1600 loss= 0.8927186131477356\n","step 1700 loss= 1.3111153841018677\n","step 1800 loss= 1.0205429792404175\n","step 1900 loss= 1.2436267137527466\n","step 2000 loss= 0.9533219337463379\n","step 2100 loss= 1.3187408447265625\n","step 2200 loss= 1.4149916172027588\n","step 2300 loss= 1.2637218236923218\n","step 2400 loss= 0.9347504377365112\n","step 2500 loss= 1.399399995803833\n","step 2600 loss= 1.217358946800232\n","step 2700 loss= 1.5362646579742432\n","step 2800 loss= 1.4145417213439941\n","step 2900 loss= 1.5519506931304932\n","step 3000 loss= 0.9945833086967468\n","step 3100 loss= 0.9655798673629761\n","step 3200 loss= 0.891904354095459\n","step 3300 loss= 1.0290911197662354\n","step 3400 loss= 1.2251578569412231\n","step 3500 loss= 1.1084139347076416\n","step 3600 loss= 0.996017575263977\n","step 3700 loss= 1.2005343437194824\n","step 3800 loss= 1.0516501665115356\n","step 3900 loss= 0.9690894484519958\n","step 4000 loss= 1.110788345336914\n","step 4100 loss= 0.8604851365089417\n","step 4200 loss= 1.1647483110427856\n","step 4300 loss= 1.0584148168563843\n","step 4400 loss= 0.9611567854881287\n","step 4500 loss= 0.9032073020935059\n","step 4600 loss= 1.3168141841888428\n","step 4700 loss= 0.8629046082496643\n","step 4800 loss= 1.2517249584197998\n","step 4900 loss= 0.9648616313934326\n","step 5000 loss= 0.7210728526115417\n"]}],"source":["for epoch in range(num_epochs):\n","    custom_model.train()\n","    i=0\n","    for batch in tqdm_notebook(train_dataloader, total=num_training_steps):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        \n","        outputs = custom_model(**batch)\n","        loss = outputs['loss']\n","        loss.backward()\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        i+=1\n","        if i%log_step==0:\n","            print(f'step {i} loss= {loss.item()}')\n","            time.sleep(1)\n","        if i>num_training_steps:\n","            break"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-31T10:38:13.137833Z","iopub.status.busy":"2024-05-31T10:38:13.137431Z","iopub.status.idle":"2024-05-31T10:56:52.305175Z","shell.execute_reply":"2024-05-31T10:56:52.304180Z","shell.execute_reply.started":"2024-05-31T10:38:13.137802Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3615e46518f94f1ca1178cc1c6035057","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1967 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'accuracy': 0.33438556933483654}\n"]}],"source":["custom_model.eval()\n","for batch in tqdm_notebook(eval_dataloader):\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","    with torch.no_grad():\n","        outputs = custom_model(**batch)\n","\n","    logits = outputs['logits']\n","    predictions = torch.argmax(logits, dim=-1)\n","    metric.add_batch(predictions=predictions, references=batch[\"labels\"])  \n","\n","\n","print(metric.compute())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
